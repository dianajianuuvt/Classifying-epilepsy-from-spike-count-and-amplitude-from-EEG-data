{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ik2MBSFjhtD",
        "outputId": "a980a42a-db86-46a0-8879-dc545f42d3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to: ML_dataset\n",
            "ML_dataset/ML_dataset/desktop.ini\n",
            "ML_dataset/ML_dataset/Z/Z072.txt\n",
            "ML_dataset/ML_dataset/Z/Z022.txt\n",
            "ML_dataset/ML_dataset/Z/Z040.txt\n",
            "ML_dataset/ML_dataset/Z/Z073.txt\n",
            "ML_dataset/ML_dataset/Z/Z016.txt\n",
            "ML_dataset/ML_dataset/Z/Z034.txt\n",
            "ML_dataset/ML_dataset/Z/Z097.txt\n",
            "ML_dataset/ML_dataset/Z/Z041.txt\n",
            "ML_dataset/ML_dataset/Z/Z082.txt\n",
            "ML_dataset/ML_dataset/Z/Z056.txt\n",
            "ML_dataset/ML_dataset/Z/Z077.txt\n",
            "ML_dataset/ML_dataset/Z/Z060.txt\n",
            "ML_dataset/ML_dataset/Z/Z050.txt\n",
            "ML_dataset/ML_dataset/Z/Z006.txt\n",
            "ML_dataset/ML_dataset/Z/Z010.txt\n",
            "ML_dataset/ML_dataset/Z/Z044.txt\n",
            "ML_dataset/ML_dataset/Z/Z057.txt\n",
            "ML_dataset/ML_dataset/Z/Z012.txt\n",
            "ML_dataset/ML_dataset/Z/Z031.txt\n",
            "ML_dataset/ML_dataset/Z/Z036.txt\n",
            "ML_dataset/ML_dataset/Z/Z075.txt\n",
            "ML_dataset/ML_dataset/Z/Z080.txt\n",
            "ML_dataset/ML_dataset/Z/Z009.txt\n",
            "ML_dataset/ML_dataset/Z/Z001.txt\n",
            "ML_dataset/ML_dataset/Z/Z064.txt\n",
            "ML_dataset/ML_dataset/Z/Z023.txt\n",
            "ML_dataset/ML_dataset/Z/Z085.txt\n",
            "ML_dataset/ML_dataset/Z/Z025.txt\n",
            "ML_dataset/ML_dataset/Z/Z029.txt\n",
            "ML_dataset/ML_dataset/Z/Z067.txt\n",
            "ML_dataset/ML_dataset/Z/Z002.txt\n",
            "ML_dataset/ML_dataset/Z/Z043.txt\n",
            "ML_dataset/ML_dataset/Z/Z074.txt\n",
            "ML_dataset/ML_dataset/Z/Z026.txt\n",
            "ML_dataset/ML_dataset/Z/Z091.txt\n",
            "ML_dataset/ML_dataset/Z/Z065.txt\n",
            "ML_dataset/ML_dataset/Z/Z066.txt\n",
            "ML_dataset/ML_dataset/Z/Z048.txt\n",
            "ML_dataset/ML_dataset/Z/Z038.txt\n",
            "ML_dataset/ML_dataset/Z/Z027.txt\n",
            "ML_dataset/ML_dataset/Z/Z081.txt\n",
            "ML_dataset/ML_dataset/Z/Z076.txt\n",
            "ML_dataset/ML_dataset/Z/Z069.txt\n",
            "ML_dataset/ML_dataset/Z/Z030.txt\n",
            "ML_dataset/ML_dataset/Z/Z095.txt\n",
            "ML_dataset/ML_dataset/Z/Z015.txt\n",
            "ML_dataset/ML_dataset/Z/Z096.txt\n",
            "ML_dataset/ML_dataset/Z/Z021.txt\n",
            "ML_dataset/ML_dataset/Z/Z055.txt\n",
            "ML_dataset/ML_dataset/Z/Z019.txt\n",
            "ML_dataset/ML_dataset/Z/Z024.txt\n",
            "ML_dataset/ML_dataset/Z/Z008.txt\n",
            "ML_dataset/ML_dataset/Z/Z013.txt\n",
            "ML_dataset/ML_dataset/Z/Z088.txt\n",
            "ML_dataset/ML_dataset/Z/Z068.txt\n",
            "ML_dataset/ML_dataset/Z/Z033.txt\n",
            "ML_dataset/ML_dataset/Z/Z014.txt\n",
            "ML_dataset/ML_dataset/Z/Z083.txt\n",
            "ML_dataset/ML_dataset/Z/Z078.txt\n",
            "ML_dataset/ML_dataset/Z/Z011.txt\n",
            "ML_dataset/ML_dataset/Z/Z035.txt\n",
            "ML_dataset/ML_dataset/Z/Z020.txt\n",
            "ML_dataset/ML_dataset/Z/Z003.txt\n",
            "ML_dataset/ML_dataset/Z/Z042.txt\n",
            "ML_dataset/ML_dataset/Z/Z045.txt\n",
            "ML_dataset/ML_dataset/Z/Z004.txt\n",
            "ML_dataset/ML_dataset/Z/Z086.txt\n",
            "ML_dataset/ML_dataset/Z/Z062.txt\n",
            "ML_dataset/ML_dataset/Z/Z087.txt\n",
            "ML_dataset/ML_dataset/Z/Z005.txt\n",
            "ML_dataset/ML_dataset/Z/Z052.txt\n",
            "ML_dataset/ML_dataset/Z/Z051.txt\n",
            "ML_dataset/ML_dataset/Z/Z070.txt\n",
            "ML_dataset/ML_dataset/Z/Z053.txt\n",
            "ML_dataset/ML_dataset/Z/Z084.txt\n",
            "ML_dataset/ML_dataset/Z/Z059.txt\n",
            "ML_dataset/ML_dataset/Z/Z054.txt\n",
            "ML_dataset/ML_dataset/Z/Z032.txt\n",
            "ML_dataset/ML_dataset/Z/Z017.txt\n",
            "ML_dataset/ML_dataset/Z/Z071.txt\n",
            "ML_dataset/ML_dataset/Z/Z018.txt\n",
            "ML_dataset/ML_dataset/Z/Z047.txt\n",
            "ML_dataset/ML_dataset/Z/Z094.txt\n",
            "ML_dataset/ML_dataset/Z/Z061.txt\n",
            "ML_dataset/ML_dataset/Z/Z028.txt\n",
            "ML_dataset/ML_dataset/Z/Z100.txt\n",
            "ML_dataset/ML_dataset/Z/Z089.txt\n",
            "ML_dataset/ML_dataset/Z/Z063.txt\n",
            "ML_dataset/ML_dataset/Z/Z037.txt\n",
            "ML_dataset/ML_dataset/Z/Z007.txt\n",
            "ML_dataset/ML_dataset/Z/Z049.txt\n",
            "ML_dataset/ML_dataset/Z/Z090.txt\n",
            "ML_dataset/ML_dataset/Z/Z046.txt\n",
            "ML_dataset/ML_dataset/Z/Z039.txt\n",
            "ML_dataset/ML_dataset/Z/Z092.txt\n",
            "ML_dataset/ML_dataset/Z/Z098.txt\n",
            "ML_dataset/ML_dataset/Z/Z058.txt\n",
            "ML_dataset/ML_dataset/Z/Z093.txt\n",
            "ML_dataset/ML_dataset/Z/Z079.txt\n",
            "ML_dataset/ML_dataset/Z/Z099.txt\n",
            "ML_dataset/ML_dataset/S/S093.txt\n",
            "ML_dataset/ML_dataset/S/S066.txt\n",
            "ML_dataset/ML_dataset/S/S021.txt\n",
            "ML_dataset/ML_dataset/S/S032.txt\n",
            "ML_dataset/ML_dataset/S/S009.txt\n",
            "ML_dataset/ML_dataset/S/S010.txt\n",
            "ML_dataset/ML_dataset/S/S018.txt\n",
            "ML_dataset/ML_dataset/S/S020.txt\n",
            "ML_dataset/ML_dataset/S/S072.txt\n",
            "ML_dataset/ML_dataset/S/S004.txt\n",
            "ML_dataset/ML_dataset/S/S028.txt\n",
            "ML_dataset/ML_dataset/S/S084.txt\n",
            "ML_dataset/ML_dataset/S/S094.txt\n",
            "ML_dataset/ML_dataset/S/S050.txt\n",
            "ML_dataset/ML_dataset/S/S065.txt\n",
            "ML_dataset/ML_dataset/S/S077.txt\n",
            "ML_dataset/ML_dataset/S/S082.txt\n",
            "ML_dataset/ML_dataset/S/S036.txt\n",
            "ML_dataset/ML_dataset/S/S048.txt\n",
            "ML_dataset/ML_dataset/S/S012.txt\n",
            "ML_dataset/ML_dataset/S/S058.txt\n",
            "ML_dataset/ML_dataset/S/S043.txt\n",
            "ML_dataset/ML_dataset/S/S096.txt\n",
            "ML_dataset/ML_dataset/S/S067.txt\n",
            "ML_dataset/ML_dataset/S/S016.txt\n",
            "ML_dataset/ML_dataset/S/S090.txt\n",
            "ML_dataset/ML_dataset/S/S086.txt\n",
            "ML_dataset/ML_dataset/S/S051.txt\n",
            "ML_dataset/ML_dataset/S/S037.txt\n",
            "ML_dataset/ML_dataset/S/S092.txt\n",
            "ML_dataset/ML_dataset/S/S099.txt\n",
            "ML_dataset/ML_dataset/S/S041.txt\n",
            "ML_dataset/ML_dataset/S/S074.txt\n",
            "ML_dataset/ML_dataset/S/S073.txt\n",
            "ML_dataset/ML_dataset/S/S056.txt\n",
            "ML_dataset/ML_dataset/S/S026.txt\n",
            "ML_dataset/ML_dataset/S/S064.txt\n",
            "ML_dataset/ML_dataset/S/S014.txt\n",
            "ML_dataset/ML_dataset/S/S088.txt\n",
            "ML_dataset/ML_dataset/S/S087.txt\n",
            "ML_dataset/ML_dataset/S/S023.txt\n",
            "ML_dataset/ML_dataset/S/S076.txt\n",
            "ML_dataset/ML_dataset/S/S071.txt\n",
            "ML_dataset/ML_dataset/S/S013.txt\n",
            "ML_dataset/ML_dataset/S/S025.txt\n",
            "ML_dataset/ML_dataset/S/S033.txt\n",
            "ML_dataset/ML_dataset/S/S070.txt\n",
            "ML_dataset/ML_dataset/S/S089.txt\n",
            "ML_dataset/ML_dataset/S/S052.txt\n",
            "ML_dataset/ML_dataset/S/S022.txt\n",
            "ML_dataset/ML_dataset/S/S015.txt\n",
            "ML_dataset/ML_dataset/S/S069.txt\n",
            "ML_dataset/ML_dataset/S/S027.txt\n",
            "ML_dataset/ML_dataset/S/S042.txt\n",
            "ML_dataset/ML_dataset/S/S053.txt\n",
            "ML_dataset/ML_dataset/S/S031.txt\n",
            "ML_dataset/ML_dataset/S/S080.txt\n",
            "ML_dataset/ML_dataset/S/S081.txt\n",
            "ML_dataset/ML_dataset/S/S091.txt\n",
            "ML_dataset/ML_dataset/S/S011.txt\n",
            "ML_dataset/ML_dataset/S/S046.txt\n",
            "ML_dataset/ML_dataset/S/S063.txt\n",
            "ML_dataset/ML_dataset/S/S061.txt\n",
            "ML_dataset/ML_dataset/S/S017.txt\n",
            "ML_dataset/ML_dataset/S/S034.txt\n",
            "ML_dataset/ML_dataset/S/S060.txt\n",
            "ML_dataset/ML_dataset/S/S085.txt\n",
            "ML_dataset/ML_dataset/S/S059.txt\n",
            "ML_dataset/ML_dataset/S/S001.txt\n",
            "ML_dataset/ML_dataset/S/S047.txt\n",
            "ML_dataset/ML_dataset/S/S035.txt\n",
            "ML_dataset/ML_dataset/S/S006.txt\n",
            "ML_dataset/ML_dataset/S/S002.txt\n",
            "ML_dataset/ML_dataset/S/S098.txt\n",
            "ML_dataset/ML_dataset/S/S039.txt\n",
            "ML_dataset/ML_dataset/S/S007.txt\n",
            "ML_dataset/ML_dataset/S/S044.txt\n",
            "ML_dataset/ML_dataset/S/S019.txt\n",
            "ML_dataset/ML_dataset/S/S049.txt\n",
            "ML_dataset/ML_dataset/S/S030.txt\n",
            "ML_dataset/ML_dataset/S/S057.txt\n",
            "ML_dataset/ML_dataset/S/S003.txt\n",
            "ML_dataset/ML_dataset/S/S097.txt\n",
            "ML_dataset/ML_dataset/S/S024.txt\n",
            "ML_dataset/ML_dataset/S/S005.txt\n",
            "ML_dataset/ML_dataset/S/S062.txt\n",
            "ML_dataset/ML_dataset/S/S008.txt\n",
            "ML_dataset/ML_dataset/S/S100.txt\n",
            "ML_dataset/ML_dataset/S/S083.txt\n",
            "ML_dataset/ML_dataset/S/S095.txt\n",
            "ML_dataset/ML_dataset/S/S040.txt\n",
            "ML_dataset/ML_dataset/S/S054.txt\n",
            "ML_dataset/ML_dataset/S/S079.txt\n",
            "ML_dataset/ML_dataset/S/S038.txt\n",
            "ML_dataset/ML_dataset/S/S078.txt\n",
            "ML_dataset/ML_dataset/S/S029.txt\n",
            "ML_dataset/ML_dataset/S/S045.txt\n",
            "ML_dataset/ML_dataset/S/S075.txt\n",
            "ML_dataset/ML_dataset/S/S068.txt\n",
            "ML_dataset/ML_dataset/S/S055.txt\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "uploaded_file_path = \"ML_dataset.zip\"\n",
        "extraction_dir = \"ML_dataset\"\n",
        "\n",
        "with zipfile.ZipFile(uploaded_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_dir)\n",
        "\n",
        "print(f\"Files extracted to: {extraction_dir}\")\n",
        "for root, dirs, files in os.walk(extraction_dir):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svw3n2y7vlbw"
      },
      "outputs": [],
      "source": [
        "directories = ['S', 'Z']\n",
        "labels_map = {'S': 'epileptic', 'Z': 'healthy'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS6Pmuu736A3",
        "outputId": "3186444d-fe0c-4673-c17e-e24feb58dd43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD8-NUiG38VN",
        "outputId": "e3684bd0-a3fd-4af1-98fe-7990de6124cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files: 200\n",
            "Training set: 160 files\n",
            "Testing set: 40 files\n",
            "\n",
            "Sample Training Data:\n",
            "ML_dataset/ML_dataset/S/S053.txt -> epileptic\n",
            "ML_dataset/ML_dataset/Z/Z059.txt -> healthy\n",
            "ML_dataset/ML_dataset/S/S049.txt -> epileptic\n",
            "ML_dataset/ML_dataset/Z/Z072.txt -> healthy\n",
            "ML_dataset/ML_dataset/Z/Z078.txt -> healthy\n",
            "\n",
            "Sample Testing Data:\n",
            "ML_dataset/ML_dataset/S/S014.txt -> epileptic\n",
            "ML_dataset/ML_dataset/Z/Z081.txt -> healthy\n",
            "ML_dataset/ML_dataset/Z/Z098.txt -> healthy\n",
            "ML_dataset/ML_dataset/Z/Z058.txt -> healthy\n",
            "ML_dataset/ML_dataset/S/S067.txt -> epileptic\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "base_dir = \"ML_dataset/ML_dataset\"\n",
        "directories = ['S', 'Z']\n",
        "labels_map = {'S': 'epileptic', 'Z': 'healthy'}\n",
        "\n",
        "data = []\n",
        "for directory in directories:\n",
        "    dir_path = os.path.join(base_dir, directory)\n",
        "    if os.path.exists(dir_path):\n",
        "        for file_name in os.listdir(dir_path):\n",
        "            file_path = os.path.join(dir_path, file_name)\n",
        "            if os.path.isfile(file_path):\n",
        "                label = labels_map[directory]\n",
        "                data.append((file_path, label))\n",
        "#80% train, 20% test\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42, stratify=[label for _, label in data])\n",
        "\n",
        "print(f\"Total files: {len(data)}\")\n",
        "print(f\"Training set: {len(train_data)} files\")\n",
        "print(f\"Testing set: {len(test_data)} files\")\n",
        "\n",
        "print(\"\\nSample Training Data:\")\n",
        "for path, label in train_data[:5]:\n",
        "    print(f\"{path} -> {label}\")\n",
        "\n",
        "print(\"\\nSample Testing Data:\")\n",
        "for path, label in test_data[:5]:\n",
        "    print(f\"{path} -> {label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GesxO_kn4G_c",
        "outputId": "ae7764e0-0427-48cb-c4a3-cb3cde6d8579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed ML_dataset/ML_dataset/S/S093.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S066.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S021.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S032.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S009.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S010.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S018.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S020.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S072.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S004.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S028.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S084.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S094.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S050.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S065.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S077.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S082.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S036.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S048.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S012.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S058.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S043.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S096.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S067.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S016.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S090.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S086.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S051.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S037.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S092.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S099.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S041.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S074.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S073.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S056.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S026.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S064.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S014.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S088.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S087.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S023.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S076.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S071.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S013.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S025.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S033.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S070.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S089.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S052.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S022.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S015.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S069.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S027.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S042.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S053.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S031.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S080.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S081.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S091.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S011.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S046.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S063.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S061.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S017.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S034.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S060.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S085.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S059.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S001.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S047.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S035.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S006.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S002.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S098.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S039.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S007.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S044.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S019.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S049.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S030.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S057.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S003.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S097.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S024.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S005.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S062.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S008.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S100.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S083.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S095.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S040.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S054.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S079.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S038.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S078.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S029.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S045.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S075.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S068.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/S/S055.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z072.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z022.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z040.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z073.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z016.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z034.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z097.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z041.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z082.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z056.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z077.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z060.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z050.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z006.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z010.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z044.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z057.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z012.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z031.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z036.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z075.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z080.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z009.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z001.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z064.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z023.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z085.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z025.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z029.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z067.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z002.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z043.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z074.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z026.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z091.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z065.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z066.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z048.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z038.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z027.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z081.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z076.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z069.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z030.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z095.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z015.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z096.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z021.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z055.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z019.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z024.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z008.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z013.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z088.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z068.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z033.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z014.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z083.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z078.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z011.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z035.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z020.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z003.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z042.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z045.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z004.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z086.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z062.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z087.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z005.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z052.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z051.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z070.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z053.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z084.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z059.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z054.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z032.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z017.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z071.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z018.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z047.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z094.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z061.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z028.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z100.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z089.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z063.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z037.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z007.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z049.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z090.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z046.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z039.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z092.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z098.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z058.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z093.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z079.txt: 23 segments created.\n",
            "Processed ML_dataset/ML_dataset/Z/Z099.txt: 23 segments created.\n",
            "All segments saved to: Segmented_EEG\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# frequency 173 Hz for EEG data;\n",
        "sampling_frequency = 173  #samples per second\n",
        "segment_duration = 1  #in seconds\n",
        "samples_per_segment = sampling_frequency * segment_duration\n",
        "\n",
        "base_dir = \"ML_dataset/ML_dataset\"\n",
        "output_dir = \"Segmented_EEG\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#processing each file and dividing into 1-second segments\n",
        "for directory in ['S', 'Z']:\n",
        "    dir_path = os.path.join(base_dir, directory)\n",
        "    output_subdir = os.path.join(output_dir, directory)\n",
        "    os.makedirs(output_subdir, exist_ok=True)\n",
        "\n",
        "    if os.path.exists(dir_path):\n",
        "        for file_name in os.listdir(dir_path):\n",
        "            file_path = os.path.join(dir_path, file_name)\n",
        "\n",
        "            with open(file_path, 'r') as file:\n",
        "                data = np.array([float(line.strip()) for line in file])\n",
        "\n",
        "            num_segments = len(data) // samples_per_segment\n",
        "            for i in range(num_segments):\n",
        "                segment = data[i * samples_per_segment:(i + 1) * samples_per_segment]\n",
        "\n",
        "                segment_filename = f\"{os.path.splitext(file_name)[0]}_segment_{i + 1}.txt\"\n",
        "                segment_path = os.path.join(output_subdir, segment_filename)\n",
        "                np.savetxt(segment_path, segment, fmt='%.6f')\n",
        "\n",
        "            print(f\"Processed {file_path}: {num_segments} segments created.\")\n",
        "\n",
        "print(f\"All segments saved to: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSEa6NTjVPno",
        "outputId": "42cae555-3a2c-4f5c-c335-993c3723ed7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed ML_dataset/ML_dataset/S/S093.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S066.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S021.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S032.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S009.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S010.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S018.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S020.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S072.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S004.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S028.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S084.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S094.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S050.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S065.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S077.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S082.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S036.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S048.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S012.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S058.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S043.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S096.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S067.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S016.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S090.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S086.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S051.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S037.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S092.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S099.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S041.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S074.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S073.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S056.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S026.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S064.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S014.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S088.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S087.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S023.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S076.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S071.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S013.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S025.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S033.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S070.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S089.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S052.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S022.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S015.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S069.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S027.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S042.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S053.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S031.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S080.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S081.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S091.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S011.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S046.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S063.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S061.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S017.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S034.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S060.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S085.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S059.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S001.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S047.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S035.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S006.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S002.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S098.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S039.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S007.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S044.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S019.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S049.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S030.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S057.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S003.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S097.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S024.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S005.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S062.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S008.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S100.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S083.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S095.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S040.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S054.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S079.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S038.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S078.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S029.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S045.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S075.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S068.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/S/S055.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z072.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z022.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z040.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z073.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z016.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z034.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z097.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z041.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z082.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z056.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z077.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z060.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z050.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z006.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z010.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z044.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z057.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z012.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z031.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z036.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z075.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z080.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z009.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z001.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z064.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z023.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z085.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z025.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z029.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z067.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z002.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z043.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z074.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z026.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z091.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z065.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z066.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z048.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z038.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z027.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z081.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z076.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z069.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z030.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z095.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z015.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z096.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z021.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z055.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z019.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z024.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z008.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z013.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z088.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z068.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z033.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z014.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z083.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z078.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z011.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z035.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z020.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z003.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z042.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z045.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z004.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z086.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z062.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z087.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z005.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z052.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z051.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z070.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z053.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z084.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z059.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z054.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z032.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z017.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z071.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z018.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z047.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z094.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z061.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z028.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z100.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z089.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z063.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z037.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z007.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z049.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z090.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z046.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z039.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z092.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z098.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z058.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z093.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z079.txt: 23 segments with median filtering.\n",
            "Processed ML_dataset/ML_dataset/Z/Z099.txt: 23 segments with median filtering.\n",
            "Filtered and difference signals saved to: Filtered_EEG\n"
          ]
        }
      ],
      "source": [
        "# Median Filtering:\n",
        "# A median filter with a kernel size of 15 ms is applied to smooth out the epileptic spikes.\n",
        "# The kernel size in samples is calculated using the formula:\n",
        "# kernel_size = (spike_duration_in_ms * sampling_frequency) / 1000\n",
        "# This translates to approximately 3 samples for 15 ms at 173 Hz.\n",
        "\n",
        "# Difference Signal:\n",
        "# After applying the median filter to the segment, the difference signal is computed by\n",
        "# subtracting the filtered signal from the original segment:\n",
        "# difference_signal = original_segment - filtered_segment\n",
        "# This step helps highlight the epileptic spikes by reducing the smooth, normal activity in the EEG.\n",
        "\n",
        "# Saving Results:\n",
        "# Both the filtered signal and difference signal are saved into separate files for each segment,\n",
        "# with names like segment_1_filtered.txt and segment_1_difference.txt.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from scipy.signal import medfilt\n",
        "\n",
        "\n",
        "#duration of epileptic spikes in ms and median filter length in samples\n",
        "spike_duration_ms = 15\n",
        "filter_length = int(spike_duration_ms * sampling_frequency / 1000)  #convert ms to samples\n",
        "\n",
        "#filter length is odd\n",
        "if filter_length % 2 == 0:\n",
        "    filter_length += 1\n",
        "\n",
        "base_dir = \"ML_dataset/ML_dataset\"\n",
        "output_dir = \"Filtered_EEG\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "def preprocess_segment(segment):\n",
        "    filtered_segment = medfilt(segment, kernel_size=filter_length)\n",
        "    difference_signal = segment - filtered_segment\n",
        "\n",
        "    return filtered_segment, difference_signal\n",
        "\n",
        "#processing each EEG segment\n",
        "for directory in ['S', 'Z']:\n",
        "    dir_path = os.path.join(base_dir, directory)\n",
        "    output_subdir = os.path.join(output_dir, directory)\n",
        "    os.makedirs(output_subdir, exist_ok=True)\n",
        "\n",
        "    if os.path.exists(dir_path):\n",
        "        for file_name in os.listdir(dir_path):\n",
        "            file_path = os.path.join(dir_path, file_name)\n",
        "\n",
        "            with open(file_path, 'r') as file:\n",
        "                data = np.array([float(line.strip()) for line in file])\n",
        "\n",
        "            num_segments = len(data) // (sampling_frequency * 1)\n",
        "            for i in range(num_segments):\n",
        "                segment = data[i * sampling_frequency: (i + 1) * sampling_frequency]\n",
        "                filtered_segment, difference_signal = preprocess_segment(segment)\n",
        "                segment_filename = f\"{os.path.splitext(file_name)[0]}_segment_{i + 1}\"\n",
        "                filtered_segment_path = os.path.join(output_subdir, f\"{segment_filename}_filtered.txt\")\n",
        "                np.savetxt(filtered_segment_path, filtered_segment, fmt='%.6f')\n",
        "                difference_signal_path = os.path.join(output_subdir, f\"{segment_filename}_difference.txt\")\n",
        "                np.savetxt(difference_signal_path, difference_signal, fmt='%.6f')\n",
        "\n",
        "            print(f\"Processed {file_path}: {num_segments} segments with median filtering.\")\n",
        "\n",
        "print(f\"Filtered and difference signals saved to: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ8sYdfk2APZ",
        "outputId": "aed6eafa-3343-4d2e-c4f0-5d578f4d0656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced signals have been processed and saved.\n"
          ]
        }
      ],
      "source": [
        "#step c\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.signal import medfilt\n",
        "\n",
        "sampling_frequency = 173  #Hz\n",
        "spike_duration_ms = 15  #ms\n",
        "kernel_size = max(3, int((spike_duration_ms * sampling_frequency) / 1000))\n",
        "if kernel_size % 2 == 0:\n",
        "    kernel_size += 1\n",
        "\n",
        "def preprocess_segment(segment):\n",
        "    filtered_segment = medfilt(segment, kernel_size=kernel_size)\n",
        "    difference_signal = segment - filtered_segment\n",
        "    return filtered_segment, difference_signal\n",
        "\n",
        "def enhance_spikes(difference_signal, power=3):\n",
        "    \"\"\"\n",
        "    Enhances epileptic spikes in the difference signal by raising the signal to an odd power.\n",
        "\n",
        "    Parameters:\n",
        "        difference_signal (numpy.ndarray): The difference signal obtained from preprocessing.\n",
        "        power (int): The odd power to raise the signal to (default is 3).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The enhanced difference signal.\n",
        "    \"\"\"\n",
        "    if power % 2 == 0:\n",
        "        raise ValueError(\"Power must be an odd number to preserve the polarity of the spikes.\")\n",
        "    return np.sign(difference_signal) * (np.abs(difference_signal) ** power)\n",
        "\n",
        "base_dir = \"ML_dataset/ML_dataset\"\n",
        "directories = ['S', 'Z']\n",
        "output_dir = \"enhanced_segments\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for directory in directories:\n",
        "    dir_path = os.path.join(base_dir, directory)\n",
        "    output_subdir = os.path.join(output_dir, directory)\n",
        "    os.makedirs(output_subdir, exist_ok=True)\n",
        "\n",
        "    for file_name in os.listdir(dir_path):\n",
        "        file_path = os.path.join(dir_path, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            eeg_data = np.loadtxt(file_path)\n",
        "\n",
        "            num_samples = sampling_frequency\n",
        "            num_segments = len(eeg_data) // num_samples\n",
        "\n",
        "            for i in range(num_segments):\n",
        "                segment = eeg_data[i * num_samples:(i + 1) * num_samples]\n",
        "                _, difference_signal = preprocess_segment(segment)\n",
        "                #enhancing spikes\n",
        "                enhanced_signal = enhance_spikes(difference_signal, power=3)\n",
        "                #saving the enhanced signal to a file\n",
        "                enhanced_file_name = f\"{file_name.split('.')[0]}_segment_{i + 1}_enhanced.txt\"\n",
        "                enhanced_file_path = os.path.join(output_subdir, enhanced_file_name)\n",
        "                np.savetxt(enhanced_file_path, enhanced_signal)\n",
        "\n",
        "print(\"Enhanced signals have been processed and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "b7ux8wyB2oT8",
        "outputId": "39b75399-08eb-4938-b079-d34108bdcb55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#step c visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample_file = os.path.join(base_dir, 'S', 'S001.txt')\n",
        "if os.path.isfile(sample_file):\n",
        "    eeg_data = np.loadtxt(sample_file)\n",
        "\n",
        "    num_samples = sampling_frequency\n",
        "    num_segments = len(eeg_data) // num_samples\n",
        "    segment = eeg_data[0:num_samples]\n",
        "    _, difference_signal = preprocess_segment(segment)\n",
        "    enhanced_signal = enhance_spikes(difference_signal, power=3)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(segment, label=\"Original Segment\", alpha=0.7)\n",
        "    plt.plot(difference_signal, label=\"Difference Signal\", alpha=0.7)\n",
        "    plt.plot(enhanced_signal, label=\"Enhanced Signal\", alpha=0.7, linestyle='--')\n",
        "    plt.title(\"Visualization of EEG Signals\")\n",
        "    plt.xlabel(\"Samples\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Sample file not found. Please update the path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuXxpWaj5y_d",
        "outputId": "95e15560-704c-4171-aef7-a9204466415e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholded signals have been processed and saved.\n"
          ]
        }
      ],
      "source": [
        "#step d\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Function to apply thresholding to enhanced spikes\n",
        "def apply_threshold(enhanced_signal, threshold_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Applies thresholding to the enhanced signal based on a specified ratio of the maximum spike amplitude.\n",
        "\n",
        "    Parameters:\n",
        "        enhanced_signal (numpy.ndarray): The enhanced difference signal.\n",
        "        threshold_ratio (float): The ratio of the maximum amplitude to use as the threshold (default is 0.5).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The thresholded signal.\n",
        "    \"\"\"\n",
        "    max_amplitude = np.max(np.abs(enhanced_signal))\n",
        "    threshold = threshold_ratio * max_amplitude\n",
        "    return np.where(np.abs(enhanced_signal) >= threshold, enhanced_signal, 0)\n",
        "\n",
        "input_dir = \"enhanced_segments\"\n",
        "output_dir = \"thresholded_segments\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for root, _, files in os.walk(input_dir):\n",
        "    for file_name in files:\n",
        "        file_path = os.path.join(root, file_name)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            enhanced_signal = np.loadtxt(file_path)\n",
        "            #thresholding\n",
        "            thresholded_signal = apply_threshold(enhanced_signal, threshold_ratio=0.5)\n",
        "            relative_path = os.path.relpath(root, input_dir)\n",
        "            output_subdir = os.path.join(output_dir, relative_path)\n",
        "            os.makedirs(output_subdir, exist_ok=True)\n",
        "            thresholded_file_name = f\"{os.path.splitext(file_name)[0]}_thresholded.txt\"\n",
        "            thresholded_file_path = os.path.join(output_subdir, thresholded_file_name)\n",
        "            np.savetxt(thresholded_file_path, thresholded_signal)\n",
        "\n",
        "print(\"Thresholded signals have been processed and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "Yw_oQ_Qc6ZLj",
        "outputId": "10a9b139-049a-4a42-cd06-3bfb7eb9ebe2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#step d visualization\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def apply_threshold(enhanced_signal, threshold_ratio=0.5):\n",
        "    max_amplitude = np.max(np.abs(enhanced_signal))\n",
        "    threshold = threshold_ratio * max_amplitude\n",
        "    return np.where(np.abs(enhanced_signal) >= threshold, enhanced_signal, 0)\n",
        "\n",
        "def plot_thresholded_signal(original_signal, thresholded_signal, title=\"Thresholded EEG Segment\"):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(original_signal, label=\"Enhanced Signal\", alpha=0.7)\n",
        "    plt.plot(thresholded_signal, label=\"Thresholded Signal\", linestyle='--', color='red')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Samples\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "input_dir = \"enhanced_segments\"\n",
        "if not os.path.exists(input_dir):\n",
        "    print(f\"Input directory '{input_dir}' does not exist!\")\n",
        "else:\n",
        "    file_found = False\n",
        "    for root, _, files in os.walk(input_dir):\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(root, file_name)\n",
        "\n",
        "            if os.path.isfile(file_path):\n",
        "                try:\n",
        "                    enhanced_signal = np.loadtxt(file_path)\n",
        "                    thresholded_signal = apply_threshold(enhanced_signal, threshold_ratio=0.5)\n",
        "                    plot_thresholded_signal(enhanced_signal, thresholded_signal, title=f\"File: {file_name}\")\n",
        "                    file_found = True\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing file '{file_path}': {e}\")\n",
        "        if file_found:\n",
        "            break\n",
        "\n",
        "    if not file_found:\n",
        "        print(\"No valid files found for visualization!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37kgtUYD61_2",
        "outputId": "7dfd94f0-6470-4662-9f2a-3ed0d568a279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis complete. Results saved to 'segment_analysis.txt'.\n"
          ]
        }
      ],
      "source": [
        "#step e\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Function to calculate maximum spike amplitude and count the spikes\n",
        "def analyze_segment(signal, threshold_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Analyze a signal to find the maximum spike amplitude and count the spikes.\n",
        "\n",
        "    Parameters:\n",
        "        signal (numpy.ndarray): The enhanced EEG signal.\n",
        "        threshold_ratio (float): Ratio to determine the threshold for spike detection.\n",
        "\n",
        "    Returns:\n",
        "        float: Maximum spike amplitude in the signal.\n",
        "        int: Number of spikes in the signal.\n",
        "    \"\"\"\n",
        "    #calculating threshold\n",
        "    max_amplitude = np.max(np.abs(signal))\n",
        "    threshold = threshold_ratio * max_amplitude\n",
        "    #identifying spikes (signal values above the threshold)\n",
        "    spikes = np.abs(signal) >= threshold\n",
        "    #counting the number of spikes\n",
        "    num_spikes = np.sum(spikes)\n",
        "\n",
        "    return max_amplitude, num_spikes\n",
        "\n",
        "#input and output directories\n",
        "input_dir = \"thresholded_segments\"  #directory containing thresholded signals\n",
        "output_file = \"segment_analysis.txt\"\n",
        "\n",
        "if not os.path.exists(input_dir):\n",
        "    print(f\"Input directory '{input_dir}' does not exist!\")\n",
        "else:\n",
        "    results = []\n",
        "    #process each segment file\n",
        "    for root, _, files in os.walk(input_dir):\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            if os.path.isfile(file_path):\n",
        "                try:\n",
        "                    #thresholded signal\n",
        "                    thresholded_signal = np.loadtxt(file_path)\n",
        "                    #analyzing the segment\n",
        "                    max_amplitude, num_spikes = analyze_segment(thresholded_signal, threshold_ratio=0.5)\n",
        "                    results.append((file_name, max_amplitude, num_spikes))\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing file '{file_path}': {e}\")\n",
        "\n",
        "    #saving results to a file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(\"File Name\\tMax Amplitude\\tNumber of Spikes\\n\")\n",
        "        for file_name, max_amplitude, num_spikes in results:\n",
        "            f.write(f\"{file_name}\\t{max_amplitude:.4f}\\t{num_spikes}\\n\")\n",
        "\n",
        "    print(f\"Analysis complete. Results saved to '{output_file}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "tne6oIoXJhXi",
        "outputId": "5a8bca6a-3d81-46ea-b269-6a2e39ab1ef8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJsAAAJOCAYAAAAQ1Aa7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA57RJREFUeJzs3Xd8E/X/B/DXJW3T3TJKW9qy9ywisqWKUJGlZQiCLAcqyHLi94cgKssFMhVlKYKCRVEUlCVVVLYoCAoyS4GyOih0JPf745o0O5f0Mtq+no9HHu2N3L3vckl773w+748giqIIIiIiIiIiIiIiBai8HQAREREREREREZUfTDYREREREREREZFimGwiIiIiIiIiIiLFMNlERERERERERESKYbKJiIiIiIiIiIgUw2QTEREREREREREphskmIiIiIiIiIiJSDJNNRERERERERESkGCabiIiIiIiIiIhIMUw2ERFRmbZixQoIgoDTp08rvu3Tp09DEASsWLFC8W3bs3fvXnTo0AEhISEQBAGHDh3y6P7JO5KSkpCUlGSY3rlzJwRBwPr1670XlAfpj3fnzp3eDsUl1uIfMWIEatWq5ZH9e+vzioiIyBomm4iISDGLFi2CIAho27att0MpswoLCzFgwABcu3YN7733Hj755BPUrFnT5vqnT5/GyJEjUbduXQQGBiImJgZ33303pk6d6sGofUNeXh6mTZvmkWSFTqfDqlWr0LZtW1SuXBlhYWFo0KABhg0bht9++83t+ydJWfvM8eQ1SkRE5E1+3g6AiIjKj9WrV6NWrVrYs2cPTpw4gXr16nk7pFKpWbMmbt26BX9/f4/t8+TJkzhz5gyWLl2Kxx9/3O66J06cQJs2bRAUFIRRo0ahVq1ayMjIwIEDBzB79my89tprHoraN+Tl5RmO2biFkDuMGzcOCxcuRN++fTFkyBD4+fnh+PHj+P7771GnTh20a9fO6W3+8MMPboi0fPP1z5ylS5dCp9MZpj15jRIREXkTk01ERKSIU6dOYffu3UhNTcXo0aOxevXqMt+6RhAEBAYGenSfly9fBgBERkY6XPe9995Dbm4uDh06ZNH6Sb8dUt6lS5ewaNEiPPHEE/jwww9Nls2dOxeZmZkubTcgIECJ8CqMsvCZ48lENRERkS9hNzoiIlLE6tWrUalSJfTs2RP9+/fH6tWrLdbR1xR5++238eGHH6Ju3brQaDRo06YN9u7da7Lu4cOHMWLECNSpU8fQPWzUqFG4evWq3TiGDx+OqlWrorCw0GJZ9+7d0bBhQ8P0jz/+iE6dOiEyMhKhoaFo2LAhXnnlFYt4jWugXLx4ESNHjkR8fDw0Gg1iY2PRt29fWTWjtm/fjs6dOyMkJASRkZHo27cv/v77b8PyESNGoEuXLgCAAQMGQBAEu60fTp48ifj4eKvd7KpVq2Yx7/vvvzfsPywsDD179sSRI0cs1lu3bh2aNGmCwMBANGvWDBs2bLCoPWP8Wi5cuBB16tRBcHAwunfvjnPnzkEURbz++uuIj49HUFAQ+vbti2vXrrkU04gRIxAaGor09HQ8+OCDCA0NRVRUFJ5//nlotVpDPFFRUQCA1157DYIgQBAETJs2DYC81y0rKwvHjh1DVlaWzXMOSEkOURTRsWNHi2WCIJice31NsV27dmH06NGoUqUKwsPDMWzYMFy/ft3kueY1m6zJz89Hr169EBERgd27dwOQuvTNnTsXTZs2RWBgIKKjozF69GiL7e/btw/JycmoWrUqgoKCULt2bYwaNcru/gDg66+/Rs+ePVG9enVoNBrUrVsXr7/+uuHcG8ffrFkzHD16FPfccw+Cg4MRFxeHOXPmWGzz/PnzePDBBxESEoJq1aph4sSJyM/PdxiLMWc/c1y9TmvVqoVevXrhhx9+QGJiIgIDA9GkSROkpqY6jNH4fePoGrX1+lur+3Tjxg2MGDECERERiIyMxPDhw3Hjxg2rMRw7dgz9+/dH5cqVERgYiDvvvBMbN240WaewsBCvvfYa6tevj8DAQFSpUgWdOnXCjz/+6PAYiYiIrGHLJiIiUsTq1auRkpKCgIAADB48GIsXL8bevXvRpk0bi3U/++wz5OTkYPTo0RAEAXPmzEFKSgr+++8/Q0uAH3/8Ef/99x9GjhyJmJgYHDlyBB9++CGOHDmC3377DYIgWI3j0UcfxapVq7Blyxb06tXLMP/ixYvYvn27oeXDkSNH0KtXL7Ro0QLTp0+HRqPBiRMn8Msvv9g9zn79+uHIkSN49tlnUatWLVy+fBk//vgjzp49a7cQ8NatW9GjRw/UqVMH06ZNw61btzB//nx07NgRBw4cQK1atTB69GjExcVhxowZGDduHNq0aYPo6Gib26xZsya2bt2K7du3495777Ub9yeffILhw4cjOTkZs2fPRl5eHhYvXoxOnTrh4MGDhtg3bdqEhx9+GM2bN8fMmTNx/fp1PPbYY4iLi7O63dWrV6OgoADPPvssrl27hjlz5mDgwIG49957sXPnTrz00ks4ceIE5s+fj+effx7Lli1zOiYA0Gq1SE5ORtu2bfH2229j69ateOedd1C3bl08/fTTiIqKwuLFi/H000/joYceQkpKCgCgRYsWsl+3DRs2YOTIkVi+fDlGjBhh97wDUlJuwIABCA4OtnvuAWDs2LGIjIzEtGnTcPz4cSxevBhnzpwxFJWW49atW+jbty/27duHrVu3Gt5bo0ePxooVKzBy5EiMGzcOp06dwoIFC3Dw4EH88ssv8Pf3x+XLl9G9e3dERUXh5ZdfRmRkJE6fPi0rYbJixQqEhoZi0qRJCA0Nxfbt2/Hqq68iOzsbb731lsm6169fx/3334+UlBQMHDgQ69evx0svvYTmzZujR48ehuPo2rUrzp49i3HjxqF69er45JNPsH37dlnnQc+Zz5zSXKcA8O+//+Lhhx/GU089heHDh2P58uUYMGAANm/ejG7dusmK19E1Kpcoiujbty9+/vlnPPXUU2jcuDE2bNiA4cOHW6x75MgRdOzYEXFxcXj55ZcREhKCL774Ag8++CC+/PJLPPTQQwCAadOmYebMmXj88cdx1113ITs7G/v27cOBAwdkHx8REZEJkYiIqJT27dsnAhB//PFHURRFUafTifHx8eL48eNN1jt16pQIQKxSpYp47do1w/yvv/5aBCB+8803hnl5eXkW+1mzZo0IQNy1a5dh3vLly0UA4qlTp0RRFEWtVivGx8eLDz/8sMlz3333XVEQBPG///4TRVEU33vvPRGAmJmZafO49PEuX75cFEVRvH79ughAfOuttxyfFDOJiYlitWrVxKtXrxrm/fHHH6JKpRKHDRtmmLdjxw4RgLhu3TqH2/zrr7/EoKAgEYCYmJgojh8/Xvzqq6/EmzdvmqyXk5MjRkZGik888YTJ/IsXL4oREREm85s3by7Gx8eLOTk5hnk7d+4UAYg1a9Y0zNOfm6ioKPHGjRuG+ZMnTxYBiC1bthQLCwsN8wcPHiwGBASIt2/fdjqm4cOHiwDE6dOnm6zbqlUrsXXr1obpzMxMEYA4depUk/Xkvm76a0n/etszbNgwEYBYqVIl8aGHHhLffvtt8e+//7a5zdatW4sFBQWG+XPmzBEBiF9//bVhXpcuXcQuXboYpo2vhZycHLFLly5i1apVxYMHDxrWSUtLEwGIq1evNtnv5s2bTeZv2LBBBCDu3bvX4bGZs/ZeHD16tBgcHGx4PfXxAxBXrVplmJefny/GxMSI/fr1M8ybO3euCED84osvDPNu3rwp1qtXTwQg7tixw2FMzn7muHqdiqIo1qxZUwQgfvnll4Z5WVlZYmxsrNiqVSvDPP3rZRz/8OHDTd43tq5RUbR8/W1t46uvvhIBiHPmzDHMKyoqEjt37mxx/Xbt2lVs3ry5yfHodDqxQ4cOYv369Q3zWrZsKfbs2dNi30RERK5iNzoiIiq11atXIzo6Gvfccw8AqSvRww8/jLVr11p0tQGAhx9+GJUqVTJMd+7cGQDw33//GeYFBQUZfr99+zauXLliKLp84MABm7GoVCoMGTIEGzduRE5OjkmMHTp0QO3atQGU1ET6+uuvTQr42hMUFISAgADs3LnToouSPRkZGTh06BBGjBiBypUrG+a3aNEC3bp1w3fffSd7W8aaNm2KQ4cOYejQoTh9+jTmzZuHBx98ENHR0Vi6dKlhvR9//BE3btzA4MGDceXKFcNDrVajbdu22LFjBwDgwoUL+PPPPzFs2DCEhoYant+lSxc0b97cagwDBgxARESEYVo/KtjQoUPh5+dnMr+goADp6elOxWTsqaeeMpnu3LmzyTVji9zXbcSIERBF0W6rJr3ly5djwYIFqF27NjZs2IDnn38ejRs3RteuXQ3HaOzJJ580qd/z9NNPw8/PT9Zrn5WVhe7du+PYsWPYuXMnEhMTDcvWrVuHiIgIdOvWzeQ8tm7dGqGhoYbzqL/ev/32W6tdTO0xfi/m5OTgypUr6Ny5M/Ly8nDs2DGTdUNDQzF06FDDdEBAAO666y6T1+m7775DbGws+vfvb5gXHByMJ598UnZMzn7muHqd6lWvXt3QCgiAoSvkwYMHcfHiRdlxK+G7776Dn58fnn76acM8tVqNZ5991mS9a9euYfv27Rg4cKDhdbty5QquXr2K5ORk/Pvvv4bjjIyMxJEjR/Dvv/969FiIiKj8YrKJiIhKRavVYu3atbjnnntw6tQpnDhxAidOnEDbtm1x6dIlbNu2zeI5NWrUMJnWJ56MEwHXrl3D+PHjER0djaCgIERFRRkSRY5q6gwbNgy3bt3Chg0bAADHjx/H/v378eijjxrWefjhh9GxY0c8/vjjiI6OxqBBg/DFF1/YTTxpNBrMnj0b33//PaKjo3H33Xdjzpw5Dm82z5w5AwAm9aL0GjdujCtXruDmzZt2t2FLgwYN8Mknn+DKlSs4fPgwZsyYAT8/Pzz55JPYunUrABhuIO+9915ERUWZPH744QdDMXF9nNZG9LI1ypf5a6m/oU9ISLA6X/8ay41JLzAw0FDvRq9SpUqykn6uvm72qFQqjBkzBvv378eVK1fw9ddfo0ePHti+fTsGDRpksX79+vVNpkNDQxEbGyur1teECROwd+9ebN26FU2bNjVZ9u+//yIrKwvVqlWzOI+5ubmG89ilSxf069cPr732GqpWrYq+ffti+fLlsuokHTlyBA899BAiIiIQHh6OqKgoQ0LJ/L0YHx9v0S3Q/HU6c+YM6tWrZ7GetfeHNUp85si9TvWsxdugQQMAkPUaKunMmTOIjY01SQgDlufvxIkTEEURU6ZMsbg29N2J9dfH9OnTcePGDTRo0ADNmzfHCy+8gMOHD3vmgIiIfNmuXUDv3kD16oAgAF995fw2tmwB2rUDwsKAqCigXz/Aw387vIE1m4iIqFS2b9+OjIwMrF27FmvXrrVYvnr1anTv3t1knlqttrotURQNvw8cOBC7d+/GCy+8gMTERISGhkKn0+H+++932BKpSZMmaN26NT799FMMGzYMn376KQICAjBw4EDDOkFBQdi1axd27NiBTZs2YfPmzfj8889x77334ocffrAZ44QJE9C7d2989dVX2LJlC6ZMmYKZM2di+/btaNWqld243EmtVqN58+Zo3rw52rdvj3vuuQerV6/GfffdZzhfn3zyCWJiYiyea9yyw5X9OjNf/xo7G5Ot7cnlztetSpUq6NOnD/r06YOkpCT89NNPOHPmjNXC7a7o27cv1q5di1mzZmHVqlVQqUq+K9TpdKhWrZrV4tgADAk6QRCwfv16/Pbbb/jmm2+wZcsWjBo1Cu+88w5+++03i8SF3o0bN9ClSxeEh4dj+vTpqFu3LgIDA3HgwAG89NJLFu9FOe/t0lLyM8cT8colCILV/VprqSWH/rV5/vnnkZycbHUdfRL57rvvxsmTJ/H111/jhx9+wEcffYT33nsPS5YsweOPP+7S/omIyoWbN4GWLYFRo4DiWntOOXUK6NsXmDQJWL0ayMoCJk6UtmWnpX55wGQTERGVyurVq1GtWjUsXLjQYllqaio2bNiAJUuWmHTFceT69evYtm0bXnvtNbz66quG+c508Rg2bBgmTZqEjIwMfPbZZ+jZs6dJ1z1Aap3StWtXdO3aFe+++y5mzJiB//3vf9ixYwfuu+8+m9uuW7cunnvuOTz33HP4999/kZiYiHfeeQeffvqp1fX1SYfjx49bLDt27BiqVq2KkJAQ2cfmyJ133glA6r6njxeQRqizd1z6OE+cOGGxzNq80pAbkzMcFdp29nVzxZ133omffvoJGRkZJsmmf//919DlCwByc3ORkZGBBx54wOE2H3zwQXTv3h0jRoxAWFgYFi9ebHJMW7duRceOHWW9x9q1a4d27drhzTffxGeffYYhQ4Zg7dq1NhMKO3fuxNWrV5Gamoq7777bMP/UqVMO92VLzZo18ddff0EURZPXzNr7wxp3fOY4om8lZBzvP//8AwB2BwYwZ+8arVSpktVuofoWh3o1a9bEtm3bkJuba5IkND9/derUAQD4+/vLeo9VrlwZI0eOxMiRI5Gbm4u7774b06ZNY7KJiCq2Hj2khy35+cD//gesWQPcuAE0awbMng3oRxfdvx/QaoE33gD0XxY9/7yUgCosBIy62Jc37EZHREQuu3XrFlJTU9GrVy/079/f4jF27Fjk5ORYDLPtiL61gfm3/HPnzpW9jcGDB0MQBIwfPx7//fefSR0ZABbDmwMw1MKx1bUoLy8Pt2/fNplXt25dhIWF2e2OFBsbi8TERKxcudJkePK//voLP/zwg6yEgzVpaWlW6+/o6wDpu9UkJycjPDwcM2bMsLp+ZmYmAKkuTbNmzbBq1Srk5uYalv/000/4888/XYrRFrkxOUM/Kpz5EPByX7esrCwcO3bMYTfNixcv4ujRoxbzCwoKsG3bNqhUKotuhx9++KHJcS5evBhFRUWGEdocGTZsGN5//30sWbIEL730kmH+wIEDodVq8frrr1s8p6ioyHAurl+/bvF+cnS9A9bfiwUFBVi0aJGsuK154IEHcOHCBaxfv94wLy8vDx9++KHD57rrM8eRCxcuGLrlAkB2djZWrVqFxMREqy3zbLF1jQLSNXns2DGTa/+PP/6wGCHzgQceQFFRkUnSUavVYv78+SbrVatWDUlJSfjggw8MiWdjxvu5evWqybLQ0FDUq1dPVjdLIqIKbexY4NdfgbVrgcOHgQEDgPvvB/RfkLZuLSWZli+Xkk5ZWcAnnwD33VeuE00AWzYREVEp6Itw9+nTx+rydu3aISoqCqtXr8bDDz8se7vh4eGGujqFhYWIi4vDDz/84FRriqioKNx///1Yt24dIiMj0bNnT5Pl06dPx65du9CzZ0/UrFkTly9fxqJFixAfH49OnTpZ3eY///yDrl27YuDAgWjSpAn8/PywYcMGXLp0yWqdHmNvvfUWevTogfbt2+Oxxx7DrVu3MH/+fERERGDatGmyj8vY7NmzsX//fqSkpBiGTz9w4ABWrVqFypUrY8KECQCk87l48WI8+uijuOOOOzBo0CBERUXh7Nmz2LRpEzp27IgFCxYAAGbMmIG+ffuiY8eOGDlyJK5fv44FCxagWbNmJgmo0nImJrmCgoLQpEkTfP7552jQoAEqV66MZs2aoaioSNbrtmHDBowcORLLly+3WyT8/PnzuOuuu3Dvvfeia9euiImJweXLl7FmzRr88ccfmDBhAqpWrWrynIKCAkMMx48fx6JFi9CpUyeb7x1rxo4di+zsbPzvf/9DREQEXnnlFXTp0gWjR4/GzJkzcejQIXTv3h3+/v74999/sW7dOsybNw/9+/fHypUrsWjRIjz00EOoW7cucnJysHTpUoSHh9tNdnbo0AGVKlXC8OHDMW7cOAiCgE8++aRU3cyeeOIJLFiwAMOGDcP+/fsRGxuLTz75xJCIscddnzmONGjQAI899hj27t2L6OhoLFu2DJcuXcLy5cud2o6ta7RZs2YYNWoU3n33XSQnJ+Oxxx7D5cuXsWTJEjRt2hTZ2dmGbfTu3RsdO3bEyy+/jNOnT6NJkyZITU21miRduHAhOnXqhObNm+OJJ55AnTp1cOnSJfz66684f/48/vjjDwBS1+OkpCS0bt0alStXxr59+7B+/XqMHTu2dCeOiKg8O3tWSiKdPSvVdAKkVkubN0vzZ8wAatcGfvgBGDgQGD1aSji1bw+4ODhMmeKVMfCIiKhc6N27txgYGCjevHnT5jojRowQ/f39xStXrhiGIbc2BD3MhgM/f/68+NBDD4mRkZFiRESEOGDAAPHChQsW6+mHlj916pTFNr/44gsRgPjkk09aLNu2bZvYt29fsXr16mJAQIBYvXp1cfDgweI///xjWEcfr34o8StXrohjxowRGzVqJIaEhIgRERFi27ZtTYZwt2fr1q1ix44dxaCgIDE8PFzs3bu3ePToUZN1jIe7d+SXX34Rx4wZIzZr1kyMiIgQ/f39xRo1aogjRowQT548abH+jh07xOTkZDEiIkIMDAwU69atK44YMULct2+fyXpr164VGzVqJGo0GrFZs2bixo0bxX79+omNGjWyODfmr6Wt+PWv0969e52Oafjw4WJISIjF8UydOlU0/1dm9+7dYuvWrcWAgADDtSL3ddPHaDx0vDXZ2dnivHnzxOTkZDE+Pl709/cXw8LCxPbt24tLly4VdTqdxTZ/+ukn8cknnxQrVaokhoaGikOGDBGvXr1qst0uXbqIXbp0cXguX3zxRRGAuGDBAsO8Dz/8UGzdurUYFBQkhoWFic2bNxdffPFF8cKFC6IoiuKBAwfEwYMHizVq1BA1Go1YrVo1sVevXhavvTW//PKL2K5dOzEoKEisXr26+OKLL4pbtmwRAYg7duwwib9p06YWzx8+fLhYs2ZNk3lnzpwR+/TpIwYHB4tVq1YVx48fL27evNlim+aU+sxx5jqtWbOm2LNnT3HLli1iixYtRI1GIzZq1MjiufptGsdv7ditXaN6n376qVinTh0xICBATExMFLds2WJ1G1evXhUfffRRMTw8XIyIiBAfffRR8eDBg1av35MnT4rDhg0TY2JiRH9/fzEuLk7s1auXuH79esM6b7zxhnjXXXeJkZGRYlBQkNioUSPxzTffFAsKCmyeZyKiCgcQxQ0bSqa//VaaFxJi+vDzE8WBA6V1MjJEsX59UXzhBVE8cEAUf/pJFLt0EcWuXUXR6P+F8kgQRS9UQCQiIvKAr7/+Gg8++CB27dqFzp07ezucMi0xMRFRUVH48ccfvR1KmbJixQqMHDkSe/fuNdTSorKlVq1aaNasGb799ltvh0JERN4kCMCGDcCDD0rTn38ODBkCHDkCmA84ERoKxMQAU6ZILZ327i1Zdv48kJAgdb9r185j4Xsau9EREVG5tXTpUtSpU8dmtziyVFhYCEEQTEaD27lzJ/744w+88cYbXoyMiIiIyIe0aiV1i7t8GbD1pWZeXklhcD19YsrB6MplHZNNRERU7qxduxaHDx/Gpk2bMG/ePIejlFGJ9PR03HfffRg6dCiqV6+OY8eOYcmSJYiJicFTTz3l7fCIiIiIPCc3FzAekffUKeDQIaByZaBBA6ll07BhwDvvSMmnzExg2zagRQugZ0/p8d57wPTpwODBQE4O8MorQM2a0vrlGJNNRERU7gwePBihoaF47LHH8Mwzz3g7nDKlUqVKaN26NT766CNkZmYiJCQEPXv2xKxZs1ClShVvh0dERETkOfv2AffcUzI9aZL0c/hwYMUKqRD4G28Azz0HpKcDVatKXeN69ZLWu/de4LPPgDlzpEdwsFQgfPNmICjI44fjSazZREREREREREREilE5XoWIiIiIiIiIiEgeJpuIiIiIiIiIiEgx5b5mU1FREQ4ePIjo6GiozKvAExERERERERF5mE6nw6VLl9CqVSuTUYDLi/J3RGYOHjyIu+66y9thEBERERERERGZ2LNnD9q0aePtMBRX7pNN0dHRAKQXMDY21svREBEREREREVFFl5GRgbvuusuQsyhvyn2ySd91LjY2FvHx8V6OhoiIiIiIiIhIUl7L/ZTPoyIiIiIiIiIiIq9gsomIiIiIiIiIiBTDZBMRERERERERESmm3Ndskkur1aKwsNDbYRDZ5O/vD7Va7e0wiIiIiIjKFd4LkrsEBASU25pMjlT4ZJMoirh48SJu3Ljh7VCIHIqMjERMTAwEQfB2KEREREREZRrvBcndVCoVateujYCAAG+H4nEVPtmk/3CpVq0agoODeRNPPkkUReTl5eHy5csApNEViYiIiIjIdbwXJHfS6XS4cOECMjIyUKNGjQp3fVXoZJNWqzV8uFSpUsXb4RDZFRQUBAC4fPkyqlWrxi51REREREQu4r0geUJUVBQuXLiAoqIi+Pv7ezscj6rQySZ9v9zg4GAvR0Ikj/5aLSwsZLKJiIiotLRaIC0NyMgAYmOBzp0B/n0lqhB4L0ieoO8+p9VqmWyqiCpaczYqu3itEhERKSQ1FRg/Hjh/vmRefDwwbx6QkuK9uIjIo/j/NblTRb6+vFoWfdcuoHdvoHp1QBCAr74yXS6KwKuvSl80BQUB990H/PuvV0IlIiIiovIiNRXo39800QQA6enS/NRU78RFRERUTng12XTzJtCyJbBwofXlc+YA778PLFkC/P47EBICJCcDt297Nk4ydfr0aQiCgEOHDnk7FINjx46hXbt2CAwMRGJiotv2Y37sO3fuhCAIHMGCiIiorNBqpRZNomi5TD9vwgRpPSIi8jkjRozAgw8+aJhOSkrChAkTPLIvks+r3eh69JAe1ogiMHcu8H//B/TtK81btQqIjpZaQA0a5L641p3Mct/GrRhQN8Kp9UeMGIGVK1di5syZePnllw3zv/rqKzz00EMQrf3zVM5NnToVISEhOH78OEJDQ62uk5mZiVdffRWbNm3CpUuXUKlSJbRs2RKvvvoqOnbsKGs/CQkJyMjIQNWqVZUMn4iIiDwlLc2yRZMxUQTOnZPWS0ryWFhEVEZ5uPab/l5w9OjRWLJkicmyMWPGYNGiRRg+fDhWrFjhthj0bt26hbi4OKhUKqSnp0Oj0bh9n9akpqaa1EOqVasWJkyY4LYEFMnj1ZZN9pw6BVy8KHWd04uIANq2BX791fbz8vPzkZ2dbXjk5OS4P1gvCAwMxOzZs3H9+nVvh6KYgoICl5978uRJdOrUCTVr1rQ5mkS/fv1w8OBBrFy5Ev/88w82btyIpKQkXL16VfZ+1Go1YmJi4OfHcmdERERlUkaGsusRUcWVmgrUqgXccw/wyCPSz1q13N4VNyEhAWvXrsWtW7cM827fvo3PPvsMNWrUcOu+jX355Zdo2rQpGjVqhK/Ma+J4UOXKlREWFua1/ZN1PptsunhR+hkdbTo/OrpkmTUzZ85ERESE4dGkSRP3BelF9913H2JiYjBz5kyb60ybNs2iS9ncuXNRq1Ytw7S+WeCMGTMQHR2NyMhITJ8+HUVFRXjhhRdQuXJlxMfHY/ny5RbbP3bsGDp06IDAwEA0a9YMP/30k8nyv/76Cz169EBoaCiio6Px6KOP4sqVK4blSUlJGDt2LCZMmICqVasiOTnZ6nHodDpMnz4d8fHx0Gg0SExMxObNmw3LBUHA/v37MX36dAiCgGnTplls48aNG0hLS8Ps2bNxzz33oGbNmrjrrrswefJk9OnTx2RbixcvRo8ePRAUFIQ6depg/fr1huWOuhDm5eWhR48e6Nixo6Fr3UcffYTGjRsjMDAQjRo1wqJFiwzrFxQUYOzYsYiNjUVgYCBq1qxp9zUlIiKiUoqNVXY9IqqYvFj77Y477kBCQgJSjfaRmpqKGjVqoFWrVibrbt68GZ06dUJkZCSqVKmCXr164eTJk4blq1atQmhoKP41Ko78zDPPoFGjRsjLy7Mbx8cff4yhQ4di6NCh+Pjjjy2WC4KADz74AL169UJwcDAaN26MX3/9FSdOnEBSUhJCQkLQoUMHk3j097AffPABEhISEBwcjIEDByIry3bvI+NudElJSThz5gwmTpwIQRAMBbrl3BtrtVpMmjTJcK5efPFFi15DOp0OM2fORO3atREUFISWLVua3C9SCZ9NNrlq8uTJyMrKMjyOHj3q7ZDcQq1WY8aMGZg/fz7O22sKLsP27dtx4cIF7Nq1C++++y6mTp2KXr16oVKlSvj999/x1FNPYfTo0Rb7eeGFF/Dcc8/h4MGDaN++PXr37m1oJXTjxg3ce++9aNWqFfbt24fNmzfj0qVLGDhwoMk2Vq5ciYCAAPzyyy8WzUD15s2bh3feeQdvv/02Dh8+jOTkZPTp08fwgZiRkYGmTZviueeeQ0ZGBp5//nmLbYSGhiI0NBRfffUV8vPz7Z6PKVOmoF+/fvjjjz8wZMgQDBo0CH///bfD83jjxg1069YNOp0OP/74IyIjI7F69Wq8+uqrePPNN/H3339jxowZmDJlClauXAkAeP/997Fx40Z88cUXOH78OFavXm3ygUdEREQK69xZGnXO1ghBggAkJEjrEVHFIopSYWFHj+xsYNw4+7Xfxo+X1pOzPRfKoIwaNcqkQcCyZcswcuRIi/Vu3ryJSZMmYd++fdi2bRtUKhUeeugh6HQ6AMCwYcPwwAMPYMiQISgqKsKmTZvw0UcfYfXq1QgODra5/5MnT+LXX3/FwIEDMXDgQKSlpeHMmTMW673++usYNmwYDh06hEaNGuGRRx7B6NGjMXnyZOzbtw+iKGLs2LEmzzlx4gS++OILfPPNN9i8eTMOHjyIZ555RtZ5SU1NRXx8PKZPn46MjAxkONFK9Z133sGKFSuwbNky/Pzzz7h27Ro2bNhgss7MmTOxatUqLFmyBEeOHMHEiRMxdOhQi4YX5MPJppgY6eelS6bzL10qWWaNRqNBeHi44VGem9M99NBDSExMxNSpU0u1ncqVK+P9999Hw4YNMWrUKDRs2BB5eXl45ZVXUL9+fUyePBkBAQH4+eefTZ43duxY9OvXD40bN8bixYsRERFhyGgvWLAArVq1wowZM9CoUSO0atUKy5Ytw44dO/DPP/8YtlG/fn3MmTMHDRs2RMOGDa3G9/bbb+Oll17CoEGD0LBhQ8yePRuJiYmYO3cuABi6tYWGhiImJsZqzSY/Pz+sWLECK1euRGRkJDp27IhXXnkFhw8ftlh3wIABePzxx9GgQQO8/vrruPPOOzF//ny75/DixYvo0qULYmNj8c033xg+mKdOnYp33nkHKSkpqF27NlJSUjBx4kR88MEHAICzZ8+ifv36hi6AnTp1wuDBg+3ui4iIiEpBrQbmzZN+N0846afnznVrzRUi8lF5eUBoqONHRITUgskWUZRaPEVEyNuegxZE1gwdOhQ///wzzpw5gzNnzuCXX37B0KFDLdbr168fUlJSUK9ePSQmJmLZsmX4888/TRplfPDBB8jIyMC4cePw2GOPYdq0aWjdurXd/S9btgw9evRApUqVULlyZSQnJ1vtDTNy5EgMHDgQDRo0wEsvvYTTp09jyJAhSE5ORuPGjTF+/Hjs3LnT5Dm3b9/GqlWrkJiYiLvvvhvz58/H2rVrcdFeF6dilStXhlqtRlhYGGJiYhBjL3lgZu7cuZg8eTJSUlLQuHFjLFmyBBERJfWV8/PzMWPGDCxbtgzJycmoU6cORowYgaFDhxru76iEzyabateWkkrbtpXMy86WRqVr3957cfma2bNnY+XKlbJa3tjStGlTqFQll0J0dDSaN29umFar1ahSpQouX75s8rz2Ri+En58f7rzzTkMcf/zxB3bs2GFoURQaGopGjRoBgEkzSUcfYtnZ2bhw4YJFAe+OHTs6fcz9+vXDhQsXsHHjRtx///3YuXMn7rjjDoviee3NLrD27ds73Fe3bt1Qr149fP755wgICAAgfYtw8uRJPPbYYybn4Y033jCcgxEjRuDQoUNo2LAhxo0bhx9++MGpYyIiIiIXpKQA69cDcXGm8+PjpfkpKd6Ji4hIpqioKPTs2RMrVqzA8uXL0bNnT6uDGP37778YPHgw6tSpg/DwcEMvirNnzxrWqVSpEj7++GMsXrwYdevWNRmEyhqtVouVK1eaJLeGDh2KFStWGFpM6bVo0cLwe3RxjRzje83o6Gjcvn0b2dnZhnk1atRAnNHnc/v27aHT6XD8+HG7cZVGVlYWMjIy0LZtW8M8/T2u3okTJ5CXl4du3bqZ3N+tWrXK5B6XJF6tcpybC5w4UTJ96hRw6BBQuTJQo4Y06uwbbwD160vJpylTgOrVAY48WOLuu+9GcnIyJk+ejBEjRpgsU6lUFn1MCwsLLbZhXLkfkPrWWptn/sFhT25uLnr37o3Zs2dbLIs1qoEQEhIie5tKCAwMRLdu3dCtWzdMmTIFjz/+OKZOnWpx7pzVs2dPfPnllzh69KjhwzM3NxcAsHTpUpMPLUBK4AFSf+tTp07h+++/x9atWzFw4EDcd9997PdLRETkbikp0pDH+kE/PvwQGDWKLZqIKrLgYOkm1ZFdu4AHHnC83nffAXffLW+/Lhg1apShC9rChQutrtO7d2/UrFkTS5cuRfXq1aHT6dCsWTOLwZl27doFtVqNjIwM3Lx5024PoS1btiA9PR0PP/ywyXytVott27ahW7duhnnG95X6+knW5jlzr+kKuffG9ujv7zZt2mSSDAPgtZH4fJlXWzbt2we0aiU9AGDSJOn3V1+Vpl98EXj2WeDJJ4E2baT3/ebNQGCg92L2RbNmzcI333yDX82G6YuKisLFixdN3lS2Clu74rfffjP8XlRUhP3796Nx48YApCTKkSNHUKtWLdSrV8/k4UyCKTw8HNWrV8cvv/xiMv+XX35RpPh7kyZNcPPmTZN5xseln9Yfly2zZs3C8OHD0bVrV0OT1OjoaFSvXh3//fefxTmoXbu24bnh4eF4+OGHsXTpUnz++ef48ssvce3atVIfGxERETlgnFi6804mmogqOkEAQkIcP7p3l1f7rXt3eduztR0H7r//fhQUFKCwsNDqYEtXr17F8ePH8X//93/o2rUrGjdubHU08927d2P27Nn45ptvEBoaalFDydzHH3+MQYMG4dChQyaPQYMGWS0U7qyzZ8/iwoULhunffvsNKpXKZtkVcwEBAdBqtSbzHN0bR0REIDY2Fr///rthnv4eV69JkybQaDQ4e/asxf1dQkKCs4dZ7nm1ZVNSkv1aaIIATJ8uPci25s2bY8iQIXj//fdN5iclJSEzMxNz5sxB//79sXnzZnz//fcIDw9XZL8LFy5E/fr10bhxY7z33nu4fv06Ro0aBQAYM2YMli5disGDB+PFF19E5cqVceLECaxduxYfffSRoWWPHC+88AKmTp2KunXrIjExEcuXL8ehQ4ewevVq2du4evUqBgwYgFGjRqFFixYICwvDvn37MGfOHPTt29dk3XXr1uHOO+9Ep06dsHr1auzZs0fWh+bbb78NrVaLe++9Fzt37kSjRo3w2muvYdy4cYiIiMD999+P/Px87Nu3D9evX8ekSZPw7rvvIjY2Fq1atYJKpcK6desQExODyMhI2cdGREREREQepK/91r+/dNNqfFPrwdpvarXaUO7D2v1VpUqVUKVKFXz44YeIjY3F2bNnLbrI5eTk4NFHH8W4cePQo0cPxMfHo02bNujduzf69+9vsc3MzEx888032LhxI5o1a2aybNiwYXjooYdw7do1VK5c2eXjCgwMxPDhw/H2228jOzsb48aNw8CBA2XXX6pVqxZ27dqFQYMGQaPRoGrVqrLujcePH49Zs2ahfv36aNSoEd59913DCOMAEBYWhueffx4TJ06ETqdDp06dkJWVhV9++QXh4eEYPny4y8dcHvlszSZyzvTp0y2aHjZu3BiLFi3CwoUL0bJlS+zZs8fqSG2umjVrFmbNmoWWLVvi559/xsaNGw39hPWtkbRaLbp3747mzZtjwoQJiIyMNKkPJce4ceMwadIkPPfcc2jevDk2b96MjRs3on79+rK3ERoairZt2+K9997D3XffjWbNmmHKlCl44oknsGDBApN1X3vtNaxduxYtWrTAqlWrsGbNGtmtqN577z0MHDgQ9957L/755x88/vjj+Oijj7B8+XI0b94cXbp0wYoVKwwtm8LCwjBnzhzceeedaNOmDU6fPo3vvvvO6XNEREREREQe5CO13/QDY1mjUqmwdu1a7N+/H82aNcPEiRPx1ltvmawzfvx4hISEYMaMGQCkhgwzZszA6NGjkW6lCPqqVasQEhKCrl27Wizr2rUrgoKC8Omnn5bqmOrVq4eUlBQ88MAD6N69O1q0aIFFixbJfv706dNx+vRp1K1bF1FRUQDk3Rs/99xzePTRRzF8+HC0b98eYWFheOihh0zWef311zFlyhTMnDkTjRs3xv33349NmzaZ9Fxxm2nTpGSm8aO4LrIvEkTzjovlzPnz55GQkIBz584hPj7eZNnt27dx6tQp1K5dG4Hsm0eQ+gxv2LABD/poYTBes0RERArTt0I4cKCktgMRlXuK/V+t1QJpaUBGBhAbC3TuzC65pTBt2jR89dVXipZ/8SZ715m9XIVV06ZJicytW0vm+fkBVgrD+wKvdqMjIiIiIiIiKrPUaqk+DJEn+PkBMrsTehv76hARERERERER+bp//wWqVwfq1AGGDAHOnvV2RDaxZRORkXLeq5SIiIiIiMhnTZs2DdOmTfN2GB6Vk5OD7Oxsw7RGo4FGo7FcsW1bYMUKoGFDqdvma69J3Tb/+gsIC/NcwDKxZRMRERERERERkRc0adIEERERhsfMmTOtr9ijBzBgANCiBZCcDHz3HXDjBvDFFx6NVy62bCIiIiIiIiIi8oKjR48izmhUQ6utmqyJjAQaNABOnHBPYKXElk0AdDqdt0MgkoXXKhERERGRcvj/NbmTnDItYWFhCA8PNzxkJ5tyc4GTJ6VREH1QhW7ZFBAQAJVKhQsXLiAqKgoBAQEQ9MPfEvkQURRRUFCAzMxMqFQqBAQEeDskIiKi8oV1G4kqFN4LkruJoojMzEwIggB/f//Sb/D554HevYGaNYELF4CpU6XREAcPLv223aBCJ5tUKhVq166NjIwMXLhwwdvhEDkUHByMGjVqQKVio0QiIiIiIlfxXpA8QRAExMfHQ61Wl35j589LiaWrV4GoKKBTJ+C336TffVCFTjYBUka7Ro0aKCoqglar9XY4RDap1Wr4+fnxGxciIiJ34N9XogqH94Lkbv7+/sokmgBg7VpltuMhFT7ZBMDQrE2Rpm1ERERERERUJvBekMg92BeHiIiIiIiIiIgUw2QTEREREREREREphskmIiIiIqqYOAIdERGRWzDZREREREREREREimGyiYiIiIiIiIiIFMNkExERERERERERKYbJJiIiIiIiIiIiUgyTTUREREREREREpBgmm4iIiIioYuJodERERG7BZBMRERERERERESmGySYiIiIiIiIiIlIMk01ERERERERERKQYJpvKgXUns7wdApHb8PomIiIiIiIqW5hsIiIiIqKKiQXCiYiI3ILJJiIiIiIiIiIiUgyTTUREREREREREpBgmm4iIiIiIiIiISDFMNhERERERERERkWKYbCIiIiIiIiIiIsUw2UREREREFRNHoyMiInILJpuIiIiIiIiIiEgxTDYREREREREREZFimGwiIiIiIiIiIiLFMNlERERERERERESKYbKJiIiIiComFggnIiJyCz9vB0BEREREREQVnFYLpKUBGRlAbCzQuTOgVns7KiJyEZNNRERERERE5D2pqcD48cD58yXz4uOBefOAlBTvxUVELmM3OiIiIiIiIvKO1FSgf3/TRBMApKdL81NTvRMXEZUKk01ERERERETkeVqt1KLJWv00/bwJE6T1iKhMYbKJiIiIiIiIPC8tzbJFkzFRBM6dk9YjojKFySYiIiIiqpg4Gh2Rd2VkKLseEfkMJpuIiIiIiIjI82JjlV2PiHwGk01ERERERETkeZ07S6POCYL15YIAJCRI6xFRmcJkExEREREREXmeWg3Mmyf9bp5w0k/PnSutR0RlCpNNRERERERE5B0pKcD69UBcnOn8+HhpfkqKd+IiolLx83YARERERERewQLhRL4hJQXo2xfwK749bdkS2L+fLZqIyjC2bCIiIiIiIiLvMk4sVarERBNRGcdkExERERERERERKYbJJiIiIiIiIiIiUoxPJ5u0WmDKFKB2bSAoCKhbF3j9dXavJyIiIiIiIiLyVT5dIHz2bGDxYmDlSqBpU2DfPmDkSCAiAhg3ztvRERERERERERGROZ9ONu3eLQ1K0LOnNF2rFrBmDbBnj1fDIiIiIqLygM3liYiI3MKnu9F16ABs2wb88480/ccfwM8/Az16eDcuIiIiIiIiIiKyzqdbNr38MpCdDTRqJI18qdUCb74JDBli+zn5+fnIz883TOfk5HggUiIiIiIiIiIiAny8ZdMXXwCrVwOffQYcOCDVbnr7bemnLTNnzkRERITh0aRJE88FXM6tO5nl7RCIiIiIiIiIyMf5dLLphRek1k2DBgHNmwOPPgpMnAjMnGn7OZMnT0ZWVpbhcfToUc8FTERERERERERUwfl0sikvD1CZRahWAzqd7edoNBqEh4cbHmFhYe4NkoiIiIjKPhYLJyKismTWLEAQgAkTvB2JVT5ds6l3b6lGU40aQNOmwMGDwLvvAqNGeTsyIiIiIirzmGAiIqKyaO9e4IMPgBYtvB2JTT7dsmn+fKB/f+CZZ4DGjYHnnwdGjwZef93bkRERERFRuSII3o6AiIjIsdxcadS0pUuBSpW8HY1NPt2yKSwMmDtXehARERERERERlSc5OTnIzs42TGs0Gmg0GttPGDMG6NkTuO8+4I03PBCha3y6ZRMREREREVGFp9UCO3cCa9ZIP7Vab0dERApp0qQJIiIiDI+Z9kZEW7sWOHDA/qhpPsKnWzYRERERERFVaKmpwPjxwPnzJfPi44F584CUFO/FRUSKOHr0KOLi4gzTNls1nTsnfRb8+CMQGOih6FzHZBMRERERVUwsEE6+LjVVKmJrfq2mp0vz169nwomojAsLC0N4eLjjFffvBy5fBu64o2SeVgvs2gUsWADk5wNqtfsCdRK70REREREREfkarVZqxWAtKaqfN2ECu9QRVRRduwJ//gkcOlTyuPNOqVj4oUM+lWgC2LKJiIiIiIjI96SlmXadMyeKUreatDQgKcljYRGRl4SFAc2amc4LCQGqVLGc7wPYsomIiIiIiMjXZGQoux4RkQexZRMREREREZGviY1Vdj0iKn927vR2BDaxZRMREREREZGv6dxZGnVOEKwvFwQgIUFaj4jIxzDZREREREQVE0ejI1+mVgPz5llfpk9AzZ3rc0WBiYgAJpuIiIiIiIh8U0oKsH695fz4eGl+SornYyIikoE1m4iIiIiIiHyVeUJpxw6p6xxbNBGRD2OyiYiIiIiIqKxISvJ2BEREDrEbHRERERERERERKYbJJiIiIiKqmFggnIiIyC2YbCIiIiIiIiIiIsUw2URERERERERERIphsomIiIiIiIiIiBTDZBMRERERERERESmGySYiIiIiIiIiIlIMk01EREREVDFxNDoiIiK38FNiIzduAJGRSmyJiIiIiIg8QqsF0tKAjAwgNhbo3BlQq70dFRERlQNOt2yaPRv4/POS6YEDgSpVgLg44I8/lAyNiIiIiIjcIjUVqFULuOce4JFHpJ+1aknziYiISsnpZNOSJUBCgvT7jz9Kj++/B3r0AF54QenwiIiIiIhIUampQP/+wPnzpvPT06X5TDgREVEpOd2N7uLFkmTTt99KLZu6d5e+CGnbVuHoiIiIiIiUYt5tLDHR2xF5nlYLjB9vvV6VKAKCAEyYAPTtyy51RETkMqdbNlWqBJw7J/2+eTNw333S76Io/e0iIiIiIvI51rqNNW3q7ag8Ly3NskWTMVGU/tlPS/NcTEREVO44nWxKSZH+PnfrBly9KnWfA4CDB4F69ZQOj8ytO5nl1ed7kjtjLUvngRzTv558Xaks4HVK5AW2uo1lZHgnHm+Se8wV8dwQEZFinO5G99570pdC584Bc+YAoaHS/IwM4JlnFI6OiIiIiKg0HHUbM16vIoiNVXY9IiIiK5xONvn7A88/bzl/4kQlwiEiIiIiUpCjbmN6Bw8Cd97p/ni8rXNnID5eKgZuLQEnCNLyzp09HxsREZUbTnejA4BPPgE6dQKqVwfOnJHmzZ0LfP21gpEREREREZWW3O5gV664Nw5foVYD8+ZJvwuC6TL99Ny5LA5ORESl4nSyafFiYNIkqVbTjRslLY4jI6W/S0REREREPkNud7CqVd0bhy9JSQHWrwfi4kznx8dL81NSvBMXERGVG04nm+bPB5YuBf73P9MvPO68E/jzTyVDIyIiIiIqJX23MfNWPOZatfJMPL4iJQU4fbpk+okngFOnmGgiIirP0tKAoUOB9u2l7tSA1HXt558V35XTyaZTp6z/LdZogJs3lQiJiIiIiEghcrqN6deraIyPuW7dinkOiIgqii+/BJKTgaAgqU5hfr40PysLmDFD8d05nWyqXRs4dMhy/ubNQOPGCkRERERERKQkW93Gqlf3TjxERESe9sYbwJIlUlc1f/+S+R07AgcOKL47p0ejmzQJGDMGuH1bGsBizx5gzRpg5kzgo48Uj4+IiIiIqPRSUoC+fQG/4n9/e/YEVq0CqlTxblxERESecPw4cPfdlvMjIqSC3ApzOtn0+ONSq6v/+z8gLw945BHpS6F584BBgxSPj4iIiIhIGcbdxKpXZ7cxIiKqOGJigBMngFq1TOf//DNQp47iu3O6G112NjBkCPDvv0BuLnDxInD+PPDYY1LcRERERERlgih6OwIiIiLPeOIJYPx44PffpZqFFy4Aq1cDzz8PPP204rtzumVTz57A1q1SQfDgYOkBSC2yunaVEk9EREREREREROQjXn4Z0OmkxE1entSlTqORkk3PPqv47pxu2RQaCjz0EFBUVDLv77+BpCSgXz8FIyMiIiIiIiIiotITBOB//wOuXQP++gv47TcgMxN4/XW37M7pZFNqqjQy3pAhUsvjv/6SEk2DB5eMKktERERERERERD4mIABo0gS46y6pNZGbON2NLigI2LRJSjANHAjs2gUMGwa89ZYboiMiIiIiIiIiIuelpMhfNzVV0V3LSjZlZ5tOq1TA558D3bpJXeemTClZJzxc0fiIiIiIiIiIqLS0WiAtDcjIAGJjgc6dOSpneRcRUfK7KAIbNkjz7rxTmrd/P3DjhnNJKZlkJZsiI6XufeZEEViyBPjgA+l3QZCuXyIiIiIin8fR6IiookhNlUYiMx7RKz5eqoXjhkQD+Yjly0t+f+klqXvakiUlSUatFnjmGbe0GpKVbNqxQ/H9EhEREREREZG7paYC/ftbJtjT06X569cz4VQRLFsG/PyzaWs2tRqYNAno0EHx2kiykk1duii6TyIiIiIiIiJyN61WatFkrSWnvnvShAlA377sUlfeFRUBx44BDRuazj92DNDpFN+drGTT4cNAs2ZSrabDh+2v26KFEmEREREREbkRu9ARUUWQlmbadc6cKALnzknrJSV5LCzygpEjgcceA06elEaiA4DffwdmzZKWKUxWsikxEbh4EahWTfpdEKz/fWbNJiIiIiIiIiIfkZGh7HpUdr39NhATA7zzTsnrHRsLvPAC8Nxziu9OVrLp1CkgKqrkdyIiIiKicoUtnYioPIqNVXY9KrtUKuDFF6VHdrY0zw2FwfVkJZtq1rT+OxERERFRmcUEExGVd507S6POpafb7p4UHy+tRxWHG5NMerKSTeaOHwfmzwf+/luabtwYePZZyzpTRERERERlgiB4OwIiIuWp1cC8edKoc+b1cPSfe3Pnsjh4RVC7tv2/df/9p+junE42ffklMGgQcOedQPv20rzffpMKiK9dC/Trp2h8REREREREROSqlBRg/XppVDrjYuHx8VKiKSXFa6GRB02YYDpdWAgcPAhs3izVbVKY08mmF18EJk8Gpk83nT91qrSMySYiIiIiIiIiH5KSAvTtC/gVpwCef14ahYwtmiqO8eOtz1+4ENi3T/HdqZx9QkYGMGyY5fyhQ1nAnoiIiIiIiMgnGSeWGjViookkPXpIXdgU5nSyKSkJSEuznP/zz+6pKZaeLiWyqlQBgoKA5s3dknQjIiIiooqGBcKJiKiiW78eqFxZ8c063Y2uTx/gpZeA/fuBdu2keb/9BqxbB7z2GrBxo+m6pXH9OtCxI3DPPcD33wNRUcC//wKVKpVuu0RERERUwTHRREREZcnixdLj9GlpumlT4NVXpZZJcrRqZVogXBSBixeBzExg0SLFw3U62fTMM9LPRYss49EvA6Rj0GpLExowezaQkAAsX14yr3bt0m2TiIiIiIiIiKhMiY+X6mzVry8lilaulOpwHTwoJZ4c6dvXNNmkUkktepKSpG6VCnM62aTTKR6DTRs3AsnJwIABwE8/AXFxUkLriSc8FwMRERERlUP2hn8mIiLyNb17m06/+abU0um33+Qlm6ZNc0tYtjhds8mT/vtPOnf16wNbtgBPPw2MGycl8GzJz89Hdna24ZGTk+O5gImIiIiobGA3OtdotcDOncCaNdLP0nZlICIi52m1wNq1wM2bQPv28p6jVgOXL1vOv3rVLcXiZSebfv0V+PZb03mrVknd2qpVA558EsjPVzY4nQ644w5gxgype+GTT0qtmpYssf2cmTNnIiIiwvBo0qSJskERlVHrTmZ5OwSfxvPjeyrqayL3uCvq+SEiL0pNBWrVkgqqPvKI9LNWLWk+8XOZZOF1QuZycnJMGszk20us/PknEBoKaDTAU08BGzYAcnMetr5kyc8HAgKcD9wB2d3opk+XuvL16iVN//kn8NhjwIgRQOPGwFtvAdWrK9syKzbW8rw1bmx/VL7Jkydj0qRJhun09HQmnIiIiIjIlCCwdZMzUlOB/v0tz1l6ujR//XogJcU7sRERlWHm+YqpU6dimq3ESsOGwKFDQFaW9Lk7fLhUc8hezuP996WfggB89JGUrNLTaoFdu7xbs+nQIeD110um164F2rYFli6VphMSgKlTlU02dewIHD9uOu+ff4CaNW0/R6PRQKPRGKazs7OVC4iIiIiIygcmmuTTaoHx462fM1GUbmAmTJCKz7qhKwYRUXl29OhRxMXFGaaN8xkWAgKAevWk31u3BvbuBebNAz74wPZz3ntP+imKUjcx48/pgACphaq97mMukp1sun4diI4umf7pJ9MR9tq0Ac6dUzI0YOJEoEMHqRvdwIHAnj3Ahx9KDyIiIiIi8oC0NOD8edvLRVG6EUhLk7pCEBGRbGFhYQgPD3ftyTqd43pGp05JP++5R2qlWqmSa/tykuyaTdHRJTEWFAAHDgDt2pUsz8kB/P2VDa5NG6kL4po1QLNmUsuquXOBIUOU3Q8REREREdmQkaHsekRE5LzJk6Uub6dPS3WNJk+WBmqQmyDZscNjiSbAiZZNDzwAvPwyMHs28NVXQHAw0LlzyfLDh4G6dZUPsFevkjpRRERERETkYbGxyq5HRETOu3wZGDZMSuxHRAAtWgBbtgDdutl+zqRJUqudkBDpd3vefVfRcGUnm15/Xar516WLVE9q5UrTguXLlgHduysaGxERERGR+7BukzydOwPx8VIxcGvnTBCk5cbfRBMRkbI+/tj55xw8CBQWlvxuiyC4FpMdspNNVatKLbaysqRkk3ntv3XrTIuaExERERH5LCaa5FOrpQK0/ftbLtPfoMydy+LgRES+ZscO6797gOyaTXoREdb/jlSubNrSiYiIiIiIyomUFGmYbfN6H/Hx0vyUFO/ERUREPkl2yyYiIiIionLDDV0Gyr2UFODqVeDJJ6XpHTukrnNs0URE5Juc+SIgNVXRXTPZREREREQVD7vRuUZl1DEiKclrYRARkQwREV7bNZNNRERERERERETlzfLlXtu1rJpNd9wBXL8u/T59OpCX586QiIiIiIg8wLh1E1s6ERFRRXD5MpCWJj0uX3bbbmQlm/7+G7h5U/r9tdeA3Fy3xUNERERERERERErKzgYefRSIiwO6dJEecXHA0KFAVpbiu5PVjS4xERg5EujUSfrS5+23gdBQ6+u++qqC0RERERERERERUek88QRw8CDw7bdA+/bSvF9/BcaPB0aPBtauVXR3spJNK1YAU6dKMQkC8P33gJ+VZwoCk01ERERERERERD7l22+BLVukVkR6ycnA0qXA/fcrvjtZyaaGDUuSXCoVsG0bUK2a4rEQEREREREREZHSqlSxPjpdRARQqZLiu5NVs8mYTsdEExERERGVAywQTkREFcX//R8waRJw8WLJvIsXgRdeAKZMUXx3slo2mTt5Epg7VyocDgBNmkjd/OrWVTAyIiIiIiJ3YXKJiIgqksWLgRMngBo1pAcAnD0LaDRAZibwwQcl6x44UOrdOZ1s2rIF6NNHKhresaM075dfgKZNgW++Abp1K3VMRERERERERESklAcf9OjunE42vfwyMHEiMGuW5fyXXmKyiYiIiIjKAEHwdgRERESeM3WqR3fndM2mv/8GHnvMcv6oUcDRo0qERERERETkZuxGR0REFVVuLpCdbfpQmNPJpqgo4NAhy/mHDrFwOBERERERERGRzzl1CujZEwgJKRmBrlIlIDLSLaPROd2N7okngCefBP77D+jQQZr3yy/A7NlSYXMiIiIiojKBo9EREVFFMXSo9Ldu2TIgOtrt3cmdTjZNmQKEhQHvvANMnizNq14dmDYNGDdO4eiIiIiIiIiIiKh0/vgD2L8faNjQI7tzOtkkCFKB8IkTgZwcaV5YmNJhERERERERERGRItq0Ac6d891kkzEmmYiIiIiIiIiIfNxHHwFPPQWkpwPNmgH+/qbLW7RQdHelSjYREREREREREZGPy8wETp4ERo4smScIUh0nQQC0WkV3x2QTEREREVVMLBBOREQVxahRQKtWwJo1vlkgnIiIiIiIiIiIypAzZ4CNG4F69TyyO5UzKxcWAl27Av/+665wiIiIiIiIiIhIUffeK41I5yFOJZv8/YHDh90VCpV3605mYd3JLLdt21cpGZutbbn7+N35uhlv25X9OHtO7O3Dl68jPfMYHU2XZlskj7s/13zhdfKla8NRLL4UK5Gn8Lona0pzXZTm/wkiZ/Ea8pDevYGJE4Fp04Avv5RaORk/FOZ0N7qhQ4GPPwZmzVI8FiIiIiIiIiIiUtpTT0k/p0+3XOYLBcKLioBly4CtW4HWrYGQENPl776rVGhERERERG7CguBERFSR6HQe3Z3Tyaa//gLuuEP6/Z9/TJe5uZg5EREREZFyOBodERFVdDduAJ9+Cowdq+hmnU427dih6P6JiIiIiIiIiMiTtm2TaiRt2AAEByuebHKqQLixEyeALVuAW7ekaX4ZRERERERERETko86dk2o21a4NdO8udU/bsAG4eFHxXTmdbLp6FejaFWjQAHjgASAjQ5r/2GPAc88pHR4REREREREREbmksBBYtw5ITgYaNgQOHQLeegtQqYD//Q+4/37A31/x3TqdbJo4UYrj7FmppZXeww8DmzcrGRoREREREREREbksLg6YPx/o1w9ITwdSU4H+/d2+W6drNv3wg9R9Lj7edH79+sCZM0qFRURERETkQawJQURE5VFRkdRdThAAtdpju3W6ZdPNm6YtmvSuXQM0GiVCIiIiIiLyACaYiIiovLtwAXjySWDNGiAmRmrhtGGDlHxyI6eTTZ07A6tWlUwLAqDTAXPmAPfco2RoRERERERuwkQTERFVBIGBwJAhwPbtwJ9/Ao0bA+PGSS2e3nwT+PFHQKtVfLdOJ5vmzAE+/BDo0QMoKABefBFo1gzYtQuYPVvx+IiIiIiIiIiIqLTq1gXeeEOqgbRpE5CfD/TqBURHK74rp2s2NWsG/PMPsGABEBYG5OYCKSnAmDFAbKzi8RERERERKc/N3QeIiIh8lkoltSDq0QPIzAQ++UTxXTidbAKAiAhphDwiIiIiojKJ3eiIiIiAqChg0iTFN+tSsun6deDjj4G//5ammzQBRo4EKldWMjQiIiIiIjcyTjgx+URERKQYp2s27doF1KoFvP++lHS6fl36vXZtaRkRERERkc9jNzoiIiK3cbpl05gxwMMPA4sXA2q1NE+rBZ55Rlr2559Kh0hEREREpDC2ZCIiInIbp1s2nTgBPPdcSaIJkH6fNElaRkREREREREREPuT2bdvLMjIU353TyaY77iip1WTs77+Bli2VCImIiIiIiIiIiBRzxx3AoUOW87/8EmjRQvHdyepGd/hwye/jxgHjx0utmNq1k+b99huwcCEwa5bi8RERERERERERUWkkJUlJnNdeA156Cbh5U6qF9MUXwJtvKr47WcmmxESphqJx1/YXX7Rc75FHpHpOREREREQ+j6PRERFRRbFoEdCzJ/D448C330pd50JDgT17gGbNFN+drGTTqVOK75eIiIiIyHuYXCIiooqmRw8gJUUa8c3PD/jmG7ckmgCZyaaaNd2ybyIiIiJyJ60WSEuTvr2MjQU6dzYd5YWIiIgqhpMnpe5oFy8CW7YAP/0E9Okj1Ul6803A31/R3clKNpm7cAH4+Wfg8mVApzNdNm6cEmERERERUamkpkr/QJ4/XzIvPh6YN0/6VrOiEwRvR0BERCTfzJnS3/Zjx4CgIKBDB2D2bKBhQ3nPT0yUutFt2QJERgLdugEPPAAMGwb8+CNw8KCi4TqdbFqxAhg9GggIAKpUMf07LQhMNhERERF5XWoq0L+/ZVex9HRp/vr1TDixGx0REZUlP/0kFfRu0wYoKgJeeQXo3h04ehQICXH8/EWLgEcfNZ3XoYOUZJowQfFwnU42TZkCvPoqMHkyoFIpHg8RERERlYZWK7VospZMEUXp28EJE4C+fdmljgXCiYiorNi82XR6xQqgWjVg/37g7rsdP9880aQXFgZ8/HGpwzPndLIpLw8YNIiJJiIiIiKflJZm2nXOnCgC585J6yUleSwsKieYlCMiUlROTg6ys7MN0xqNBhqNxvETs7Kkn5UrO7fDo0eBs2eBgoKSeYIA9O7t3HYccDpl9NhjwLp1isYg26xZJV/GEREREZEVGRnKrkdERERu06RJE0RERBgeM2fOdPwknU5KjHTsKH80uf/+A1q2lNbv2RN48EHp8dBD0k+FOd2yaeZMoFcvqQVX8+aWBcvffVep0Ezt3Qt88AHQooV7tk9ERERULsTGKrsekTEWViciUtTRo0cRFxdnmJbVqmnMGOCvv6SR2+QaPx6oXRvYtk36uWcPcPUq8NxzwNtvuxC5fS4lm7ZsKSl4bl4g3B1yc4EhQ4ClS4E33nDPPoiIiIjKhc6dpVHn0tOtd3kSBGl5586ej43KPnajIyJSVFhYGMLDw+U/YexY4NtvgV27pL/ncv36K7B9O1C1qlQXSaUCOnWSkjzjxnl/NLp33gGWLQNGjFA0DrvGjJFaed13H5NNRERERHap1cC8edKoc4JgmhzQfzM4dy6Lg5PztFrg+HHTaV5HRESeIYrAs88CGzYAO3dKrZOcodVKxcABKeF04YLUiqhmTdPPdoU4XbNJo5G6BXrK2rXAgQNSsk2O/Px8ZGdnGx45OTnuDZCIiIjI16SkAOvXA0bN8gFI34CuXy8tJ45G54zUVKBWLdOuFrVqSfOJiMj9xowBPv0U+OwzKWl08aL0uHVL3vObNQP++EP6vW1bYM4c4JdfgOnTgTp1FA/X6WTT+PHA/PmKx2HVuXPS/lavBgID5T1n5syZJsW1mjRp4t4gPWDdySyX1nP0PDnb1a9j/tMd7G1bif1a24Yz58DZONadzCpV3Lae787XwFYc7n6et64rJbbp7DXkDe58DX3hGnV2v65em6V9T8uJwdntl/Yzxh3k/L1w5rrx9vunTEtJAU6fLpm+4w7g1CmfTTTxtfZhqalSSznzUQ7T06X5FSjh5I2/e85+PpY2Hnf/70S+y5P/h5ALFi+WRqBLSpLqLuofn38u7/n/939SYXFASjCdOiV1qf/uO+D99xUP1+ludHv2SN38vv0WaNrUskC4kn9r9u8HLl+W/jfS02qlrokLFgD5+ZYtdydPnoxJkyYZptPT08tFwomIiIjIacb/KFWuzC5P5DytVvr211rLL1EsGSq6b19eX3paLZCWJo34GBsr3czx3BBRaZW2BW5ycsnv9eoBx44B164BlSq5pQC308mmyEjPfSHWtSvw55+m80aOBBo1Al56yfpntkajManenp2d7eYoiYiIiIjKqbQ0yxZNxkRR6o6QliZ9217RpaZKyTnjcxYfL9VR89FWhURUgVWu7LZNO51sWr7cHWFYFxYmdSs0FhICVKliOZ+IiIiISDbWaJInI0PZ9cqxuC0bgbHDLa8tfXdD1ksjIm8YNUreesuWKbpbp5NNRERERETlAguEOxYbq+x65ZVWi8TXX2Z3QyLyPStWSCPOtWrl0b91Tiebate2353vv/9KE45jO3e6d/tERERERFSsc2epG1h6uvWbFEGQlnfu7PnYfElaGoIvXrC9nN0Nichbnn4aWLNGKgg+ciQwdKhbu8/pOZ1smjDBdLqwEDh4ENi8GXjhBYWiIiIiIiIi71OrpXpD/ftbLtN/Az13LlvrsLshEfmqhQuBd9+VasotWwZMngz07Ak89hjQvbtbioMDLiSbxo+3Pn/hQmDfvtKGQ0REREREPiUlRao3NGBAybDZgNSiae5c1iEC2N2QiHybRgMMHiw9zpyRutY98wxQVAQcOQKEhiq+S5VSG+rRA/jyS6W2RkREREREPiMlRRoe29ipU0w06XXujLyY6rZbCAgCkJDA7oZE5H0qlfSZJIqAVuu+3Si1ofXrPdLtj4iIiIiIvME8kVLRu84ZU6txaMos6Xfz88TuhkTkbfn5Ut2mbt2ABg2AP/8EFiwAzp51S6smwIVudK1amX5+iiJw8SKQmQksWqRkaEREREREbsTR6EhB6cl9pG/gx48Hzp8vWcDuhkTkTc88A6xdK7WuHDVKSjpVrer23TqdbHrwQdNplQqIipIGVWjUSJmgiIiIiIiIypyUFKBvX8Cv+DZryRLg8cfZoomIvGfJEqBGDaBOHeCnn6SHNampiu7W6WTT1KmK7p+IiIiIiKj8ME4s3XknE01E5F3DhrltxDl7nE42ERERERERERFRGbBihVd2KzvZpC9Ybo8gSCPnEREREZEXabVAWhqQkeHtSKg80F9P+fnejoSIiMoI2cmmDRtsL/v1V+D99wGdTomQiIiIiMhlqamWBYoB4PJl78Tjq0SRBcLlsHU9kW28loiI5Ceb+va1nHf8OPDyy8A33wBDhgDTpysZGhERERE5JTUV6N/f+s3u4cPSco6IRXLZu570y3k9ERGRFSpXnnThAvDEE0Dz5lK3uUOHgJUrgZo1FY6OiIiIiOTRaqUWKPZaVUyYIK1HXimWWqbwenIdWzYRETmXbMrKAl56CahXDzhyBNi2TWrV1KyZu8IjIiIiIlnS0hx3dTp3TlqPmBBwhNcTERGVguxudHPmALNnAzExwJo11rvVEREREZGXyC0GzqLhJAevJ9cxkUlEJD/Z9PLLQFCQ1Kpp5UrpYU1qqlKhEREREZFssbHKrkcVG68novKNXYnJzWQnm4YN4/VIRERE5LM6dwbi44H0dNstKxISpPVIwtHobOP15DpeS1QW8DolN5OdbFqxwo1REBEREVHpqNXAvHnS6GG2zJ0rrUfkiPH1JAjWb0x5PRERkQ0ujUZHRERERD4oJQVYvx4ID7dc1qIFh6k3xm/1HdNfT3FxtpeTJV5b5Kt4bZIHMdlEREREVJ6kpADPPms5v1o1z8dCZV9KCnD6tLejICKiMobJJiIiIqLyRsV/8RxiMVL52FXOOWw9QkTEZBMRERERVUDmCQEmCEgpvJbIV/HaJA9isomIiIiIKibeeJUOzx9R2cXWneRmTDYRERERUcXDGy1yFybhqCzgdUpuxmQTEREREVU8vNEiooqGn3vkQUw2ERERERGR83jjah3PC5UFbN1JbsZkUxm37mSWrHn25iu5f3fsQ24Mcvbt7Llx5XjsPcfT58vW/uScs9LE5unjcsfzrJ2jdSezFDk2R9ebfj/OXNty9+Hq9kq7T6X34e73WWmuMVeuMzn7LO35dcf73pn45e7L3jl05jPM3TG4um1XePLvemkp9TnpKd+dybE6X+lj8IXPXV/4u27rM8Pe57aS7/eydG06UprX3hv/I/jK/pQg9zPZF+6T7O7bKCnq8P2o1QI7dwJr1kg/tVrZ+yyLrzEpw8/bARAREREReYMAoxYobI1CSuG1ROVI3JaNwMxXgPPnS2bGxwPz5gEtu3ovMPJ5bNlEREREVN740s2uC9+IUxnhS9cZETnm7Hs2NRXtxw43TTQBQHo60L+/lIgisoHJJiIiIiJyj9RUoFYt4J57gEcekX7WqiXN9zYmSshdeG1ReaDVAuPHW7+ei+clvjGZXyCQTUw2EREREZU3vlD4NTUV6N/f5jfiPpFwIiIi69LSgPPnYfOviSgiOCNdWo/ICiabiIiIiMobb7eskPGNOCZM8O434r6QkCvrSnOdGXWvjPotrXy1jvD2+4/IFmeuzYwMZdejCofJJiIiIiJSVvE34jaJInDunHe/EWdCwHtSU9GzS3ND98qkob19p3sluYa12coeRwn32Fh525G7HlU4TDYRERERkbLKyjfiIkej87ji7pVBFy+Yzi9P3Ssr2LUUt2Wj79ZmI9scXaedOwPx8RBtJaUEAXmxcdJ6RFYw2UREREREyuI34hWDs0kVo+6VFrevvtK9kpzjYLQyJpzKMLUamDdP+t084VQ8fej/ZkrrEVnBZBMRERERKav4G3Gb3TQEAUhI4DfiFUzU3t2yuldG7d3t3kDc3eWrorRsKgu12ciUs9dmSgp+XbASiIsznR8fD6xfj/TkPsrFRuUOk01EREREpCwZ34hj7lx534izFky5EZh5SdH1XJKayi5fSpExWlmpa7Px/e916cl9gNOnS2YkJQGnTgEpKd4KicoIJpuIiIiISHkpKcD69Ta/EZd1o8LEgG9zspXE7ahoRddzVtyWjVLXLnd3+aooLZvcXZuN73/fYfzFQLVq7DpHsjDZRERERETukZJi+o34gAHyvxEvLiTt1sQAC4R7VGabDrK6V2a26aD8zrVaJL7+Mrt8KcmdtdkyMz2TGKxolPic42clycRkExERERG5j/E34AkJ8rvOsRZM+WPUvdJihCtnu1c6KWrvbgSbj4BnTIkuX8bbqghkjFbmcm22Eyf4/nc3W68bkUKYbCIiIiIi31JcC8YmJRMD5DpXkirF3StvRZu1dnGme6ULZNeBcrXLl7GKkmwyrs1mrrTJw/x828v4/leGq9cpk1QkE5NNREREROQZcm9u3F0LhrwrJQWbfvrTMFkQGu72gsOy60C50uWrItOPVhYRYTrfzclDAHz/u6KiJELJJ/h5OwAiIiIiIhPurAVDznPHDapRaxfR39/tBYcz23RAXkx1BF/KsH48giAlSFzp8mWugt3Qpyf3AW5dBp5/XpqxY4d0Ht1dRJrv/9JxtYVSBbu+yXVs2URERERU3vjqzYDcm5viWjCOCkkrkhigikGtxqEps6TfPVwvShatFti5E1izRvpZ1uoRqYxuK5OSSn8eNRq+/93NV/9OkH27dgG9ewPVq0vvha++8nZENjHZRERERES+xZ21YPREEQJHo5PH1rlR6pyJokcSLenJfaSuXXFxpguU7vLl7HlJTQVq1QLuuQd45BHpZ61ajkdcK+sJKnvq1bM+3xcSgxUdazZ5182bQMuWwMKF3o7EIXajIyIiIipvysPNQHEhaQwaBBQWlsyPj5duNN1ZC4ZMuTkRF5B1Q0qwFOsZUx1YON89r3FKCtC3L+BXfBsUHCzVi/JW4iI1Fejf3/Icp6dL89evB1p2tXha3JaNSHz9ZcB4hL34eClJa2X9MicqSjr2fv1M5/P9XzpKvJeZmPeuHj2kRxnAlk1ERERE5U15uRlISQGaNCmZ3rHD7YWkyQtEnclk0KUMKdHiqGWPq4wTS35+yiea5L7/tFpg/Hjr6+vnTZhg2WIpNRXtxw5HkHGiCTAkqOK2bHQ6ZJ+UkmL62vD9T1SmMNlERERERL7LuJWWErVgyGmCO7rRGSVQzNvhCfYSLeVJWhpw/rzt5aIInDuHqL27TecXJ6gs2i8Wn7fENyaXn/PmS+//4m6LCd+sL3/dFsmrcnJykJ2dbXjk5+d7OyRFMNlERERERFQRebEFnEUCxZytREtZIPe8ZmTIWi0w85LpjPPnLRNNRvsOzkiXElmkHKO6Wu0mPi6/rpavKS+tXsuZJk2aICIiwvCYOXOmt0NSBGs2EREREZHvcufNEQuEy+OGc2ORQCnlemVSbKys1W5HRTu/7YwMIKGV888jS3LqapXFrn3lobZfOXH06FHEGQ1coNFovBiNctiyiYiIiIgqBuNuL5cusRuMXG7oRic3geJSosUZ7kgyyt1m585SwWtbN/2CACQkILNNB+djkJnIIgdcratVFjDB7jPCwsIQHh5ueDDZRERERETkbkp9+67vBqO3fTu6DH9QmW2XVe6+2SyucYM1ayxq3DhMoJQm0eJL7J1jtVoaPc4a/XU/d65lnaL4eIh2ElR5sXFSIotKT2ZdrTLTbZEJprIvNxc4dEh6AFLR/EOHgLNnvRiUdUw2EREREVH5pu8GY3bTGHjlsuW6Wi2ifkuzmiCpqGwWCLfHqMYNHnkEuOce9OzSvKTGjZ1Cz6K9RIvS3NGVyJnzlZIidcMKCjKdHx9vu3tWcYLKYi/Fx3Lo/2aykL5SZNbVkr2eL2E3urJp3z6gVSvpAQCTJkm/v/qqd+OywqeTTTNnAm3aAGFhQLVqwIMPAsePezsqIiIiIioz7HSDEczXK06QJA3tbUiQlMkiwJ5iK6liI7kXdClDmu/gfN6KqV526+CYk5N4SkkBevcumd6xQ2qtYOv4U1Lw64KVKAwNM51fnKBKT+7jerxkSm53xLLYbZGtnMqmpCTptTN/rFjh7cgs+HSy6aefgDFjgN9+A378ESgsBLp3B27e9HZkRERERFQmOOoGo7dmjdUEiaEIcIVOODlxU2ovuSenxs2OHdi083DZTjS5chOvMrotS0py2DIpPbkP/hn5TMkMRwkqco3MulrstkhkyaeTTZs3AyNGAE2bAi1bSsm6s2eB/fu9HRkRERGRDytP31iX9ljkdm/ZsKF8FgG2R+65deY1kFnjJmrvbuvLZSRayhR3vhedTFCRC4zrapknnDzZ3VMp5elvA/k8n042mcvKkn5Wrmx7nfz8fGRnZxseOTk5ngmOiIiIiHyP3O4t9v5nLGtFgD3F2o2rzOReYOYlhYPxIbyhL1/0dbViYkzn26urVRawZhO5WZlJNul00hdKHTsCzZrZXm/mzJmIiIgwPJo0aeKxGN1p3cksi9+N58l5nqN11p3MMjxcjcmV/buyvjPbNV/X3nNdOafWzptSr435PuQ+19nzbv4ca8939vjsPc/Ra+BK/Lb26Wi90lwP5sfj6L1kfi6cfX+Whq3tyHl/uPqZI+d1trW+tX068zlj633qKB5HcduLrzTbdsdnqLOf546eK2d7rh6HnNewNPu19dPZbbnyt9jWe8z8upBz/h3GqdVi5+pvgTVrcPrICbvxlOYzXc5nnNxtyYlP7jZsfqYUd4OxOXqXMzIyZF3nznwW2pt29Hzj5XLff/Zis3U+nSoQLjO5dzsqWv427XDm8914nr31zX8vzf8KpUk8lfZvvxL7cfT/gxIx2tuGzsmYzD+fHH3+y/4MT0nBN2t/KFmwcSNw6hTWtexa6r9hjp4j5z3s6JxYs/fSTVnvH3Pncgtt7tud/+e4+neLvKfMJJvGjAH++gtYu9b+epMnT0ZWVpbhcfToUc8ESEREROQtZoWta339hbcjUk5pk0R2usE4nQbw5SLAWq00ep63R9FzlNwrrnGT2aaDZ+PyJOMEE1s5lR/GXeU6dSo7XeeM8XokDyoTyaaxY4Fvv5Xq3sXH219Xo9EgPDzc8AgLC7P/BCIiIiJ38UQCwMbIX2SkePQuxMWZzDZuXZNfqUqZLQIct2UjenZpLo2e58QoerJbLNlaz9p84+Se+eplscaNK3hDX/6Vh9eY3ejIzXw62SSKUqJpwwZg+3agdm1vR0REREQkU2qqRQKgZ5fmyo5qZmfkL4fPK06CRf2WVv4KX1uRntwHOH26ZMbdd2PXsi8NkyceGWX9iT6eIInbshHtxw5H0MULpguKR9GL27Kx9Dtx9vrSJ/fMztetmOplu8aNK9yYlHCqeyOVmlDeWqyVh2Mgn+bTyaYxY4BPPwU++wwICwMuXpQet255OzIiIiIi2+K2bAT697dIAARdylAuAQA4HvnLGrMkWNLQ3rJawXiNkjdExsmPqCiT6aut20mJkKpVTZ/jy0WAtVokvv4yIIqwaKNQfN4S35jslWRienIfoEaNkhk7dmDTzsO+eR6Vxpt4z/Bm19Gy+hqX1bipTPLpZNPixdIIdElJUhd5/ePzz70dGREREZENdhIAgtIJAJkjf+nZSoLpW8H4bMLJHazddKWkACtXlkzv2AGcOuWzCZKovbsRfPGCZaJJTxQRnJFe6lH0bLagcXTjatxNJynJJ1uGuaw40ZHwzXr7rQN97eZeq5XitZegMVrHZ1s+2mg5qlgi3xFfe12JfJBPJ5tE0fpjxAhvR0ZERERkQ1oags2TOcaKEwBRe3eXfl/OFKwWRYetYDBhgm/eWLqDrZtF44SIjydIAjMvyVvRVlLSV2+Yfb2bZ3FBftxzD9pNfNzQOtCQ6PDV82o2kIC+tpdxgkZf/0u/jsWx+QB7LUfbjx3uvljLWzc61mwiN/PzdgBERERE5YrM1kayEwX2FI/8hfR0xzc/1687TILh3DmpFUxSUuljK6vK0E2kcYFzu/RJSX2LlT050ryoxvKer9Q50SeRMjIQpbMxiE9qKnqOeRYovlaTAODleMRNngE886gycZRC3JaNwNjhluckPR3txw4HYkKANm1K5vvK9aQfSMBe3ID0u711vN3Kz0HLUVEQkPjGZKTf19Pqc02u/w4dTKc7d3aQXC5nyabycAzk05hsIiIiIlKSzNZGshMF9uhH/urf3/G6BQXytulk1zy3c9e37+XgRiuzTQfkxVRH0KUM613dBAF5MdUR3Lkz4j74DJj5CpKManw9EFNd5p5c7EZnzFoSyZr+/RHkq8kOo0SHBVGUrtUJE4CffvJ4aHbZG0hAH/f48YZpqy0f9cfWt693W/s5aDkqGLccbdDLMD9uy0aL6x9qNZKMW83Fx0ufpzausXJRILysxk1lkk93oyMiIiIqczp3Rl5MddtJEkFAXmwcMtt0UGZ/KSlSAWs/B98hBgTI254zXfPKMlGEx1sqKF3QWK3GoSmzAFhJBxVff4f+bybw9ddSssasmHzQJQ8mFq3VCrPGl7t5ykh04Nw5YM+ekpk+cHMftXe33YEEBFGUlp8/b7P+l2Dc8tGbXGk5mppq9fq3uJYc1a4rD8kmYy4m8jVXM323iyv5FCabiIiIiJSkVuNs735Wb0b0cw7930xlWwekpAD16xsmz/QeYLlOpUoOk2BISJC6kviS8nBTB5jU+TEuaFzaouzpyX3w64KVKKhUxXRB8Sh66ff1tNmqxaSlhk5ncx82C4Q7w1oSyQk+keyQ2+rvkgJdZBWkSJddPW+3fHS25ai9Vl3mHCU1y1uyycVjqLbnF0M9L48WZacyh8kmIiIiIiWlpqLhRwtsL3/+eWlYeKUZJZHy4hKsLnfUCgZz5/p0QWxFefBmUV/Q2GrLIjmjADpoEZWe3Ae/z1lUMsNoFD19qxaHiZ5Tp+QeTglv3HB7M9kht9VftWolv/tAUkKRLrt63m756KDlqGjWclT29W/YgO2kpqArB8kmV+O28RmlL8peoUYyJdmYbCIiIiJSipxv0deudX/XAxs3YunJfYD161EYGm66oLgVjNeL/3qSrddI6dYLdur8CDK6h8Vt2WjRIgq1alne3Kmsj6Inu1VLTo7tZb50X+3NZIeMRAcSEkwLhPuAzDYdpPe4vbjj44H4eOl3W+uUpuWjUl1IjbuOmsUqGncddfb6N2ctqVneWjbJ7Uan/7tmbRO+0sWVfBKTTURERERKSUuzX/cEAM6dk75tdyd7N0IpKTg2eoJhcuen3xhawVQoznSrKYWovbvljwJozlatmeLaMnK6r8hu1RJmY3Q4fYxeJgJSQsSb3TyNEh0WN+q2Wgf6wLkzDCQA2I573jzDOlYTTqII9OsnXafmSQWtFjhxwnTaWGqq1GXUUcJUJn3S/Fa0aeLxVkx1/LpgpUnLUZdbdVlJagoVdDQ6WTW/PPF3jcocJpuIiIiIlOJK8VpvUJX8C5jZztFw30aKhw5P+GZ9uSsOa7iRVLj1guzX2vzacTSCGIDENyY7fA30rVpstVgxqF1bXpxW4pCllKMKCgBw6xbw9del2k5p6RMdiIszXRAfj18XrJSStr6YiNAPJGAv7pQU/LpgpUUSB2q1dP7nzjUkivSJzrgtG6VE0iKjbpzGiaTUVOvF4Z1ImNo6nk0//Vky3aABNu08bNFFWfb1r2evBZdxXTNffI3dRO5nmNf/rpHPYbKJiIiISCnOFq/1tOKuLJF//+l4XXPFrROShvZGu4mPI2lob+dbJ7hyg1bKJIVNoug4HgVuKGW/1ubXjoNWcjAe4t0eO61aTG7AVbZvCxQpEG6+P1dcuyavxpW7paQAp08bJq8ktgFOnbJei82dSQlnt20WNzp2tIg7PbmPSRJHBKyO2tZ+7HDgxRfRfuxwm4kkrFtnSJjaGmFQTsLUJuMkeViY9aS5vVZd5hzUrhPKQzc6F+KW+xnmtb9r5LOYbCIiIiJSSufOsuqe6IvXetTly4auLDW+/dIwW1bLAgetE9x68++umzpbo68pfEOZ2aaDa6MAlqaVnHncxS1WEG16M2jRgsWdrHR7cpov1YcxSkYUVKrsna5zruzHOM6qVW0naBztVxSBd9+1m0jCmDF2u1/JTpiWlv76N2/VZf6edFS7rjwkm4zJTP4aan7ZoD8TAdevKhAUlSdMNhEREREpRc636N4a8e3wYctkEeB4JCGj7lw2byrl3vy7q5WSKzxUs8lenR/RXksKZ1vJGW/bSiItPbkP8NNPJTO++w7f/7BX1j5kFVN3xLzbk6vs1bjyRWU8KWG3/pxWa7flHTIzZe3DE92v0pP7mLbqevZZ4OmnS6aNRnC0RfBmNzqjAuuKdWGWewxqtZRYtEF/DSTO+J/3k8DkU5hsIiIiIlKSrW/RgZLaKF5i88bQXrKouDuXTeWtOKyDpI0rbNX5uRVT3XZLCget5GA2xLsJWzeRxgmtTp3kJz2VurFWMskqs+WXV5TxBJOneaz7lfH1V78+4OdXMm00gqNt3mnZZD4ipUtdmPVcjTsqyuEqHmmlRmUKk01ERERECrP4Ft14vo8RHLUUUbLouS/dhMtpraNkvOb1cu64A5t2HradfJQxgpjxEO8m5CTJfOm1cIXMll9eUd66W5VGVJTdLqR5sXHIvKOtodWOT/PG66rAiJQ2OdPStKwMfkE+hckmIiIiInfwRlc5PVduhGzdTChZ9PzYMemm0he6Woii44K/St9QGl8TlStLP/U32dbOi76VXPXqpvOLa8vYTF7KidtRQqp45EGsWYOq+39zfT9KszdaGCnO1issAoBKZXO54XUqHqXOYr3iRMfZXinoeW+iodWOgcwueC5z4dp1qkC40fvH5c88hUaktEm/XaNYbXbR8/XBL8gn+TlehYiIiIgUV1yDI+HQSekf9Fo9vJugsnUzUdydC+np1m96BAGIj7dd9Ny4q8f330uP+HjETZ4BPPNo6ePWaoG0NOfPo6dbNpnTF2w3qqPVM6Y6sHC+SWun9OQ+wKMPAuHh0oyPPwaGD5eO8WSW9W3LrUdla73UVPQc8yyCi2PrKOd4lLJlC5CcbH2Zg9HCfEZFadmk01nvmmv8OqWkAOvXo3DkKARkG12v8fHAoEFo+Pbb1s/RkSPeH3XQnNyaTWbvHwCufebJHJESaWlAQit52zSLO27LRiS+/rIh1iRAGtDA7HPIYXJXEJAXU907g1+Qz2LLJiIiIiIPi9uy0TAyXLuJj5euBoc1TnSPEB21FDHqzmVRP8jRzX/xKHYW9EOnOypMvnMncP26zVWMa5k4fR5FEZUOHyiZttbSpzSJAn0y8Zv11lsLWCnYHnQpw/rofsbnvU0b6+fa2VpTttaxNfKgp9x9t+1ljkYLU4I7CjHL4aNJqf8GjQRCQpx7kvnrlJKCPyf+X8nyHTuAEyekVj/WBh7QmzDBp86LrJZNdkbudPiZZ05uXTIX65dVOvIH2o8dLu9zyE5yV3TUrZcqLCabiIiIiDypuAaHtZsR9OuHxvNnI+Gb9aXrbmbjRsjmbZujliLFrRMshq63d/MvowuIrcLkJgVxz54tWWB881PaWiZpaWjzyjjD5F0vjZG2r0CrFLlJMPObbMHWeXE2DldH2rM38mBp6bvqOGIvUWZrtDCjBFGp3jepqYYksHEhZqfr4pSjlk03mrYA2rWzmG/3+jhxwvJ1UhnddiYlAbt322+1A0i15OSeP0+cZ0evq5IjdwLy65K5WL8s4dsvrcZq83PIBv1AB75Yk5C8i8kmIiIiIk+RcTPSbN5MtJv4uHTD68qNri0tWkCrCbSYLXuEPLOh63MTatkfKtzBKHY2C5PbSiIBJd+2K1HLJD/fZDLg+lVp+7uNRlNy5QbWQRLMIWvnxdlR8Wytb3w8VtaJ2rvb/siD9rbnSK1aUvLGEXvHaiUhatxKEI88YnjfON1K0FGLlHXrDC3VfKbumFLstOaKPHIY2LbNue3tljEimS+PJmiDo5ZNjt4/+s882SO2yRyR0tX6ZZqsG3a76MmJ9fe3P7A/0AFVaKzZREREROQh+psR2a1Gim90f12wsvT1japVw6WoOMRt+950F858G210s18UEmK/NZQrXUDsJZH0JkwAIiLk1TKZPx+Ijpa++a/ewm6CwLCtjz4y2Y5THCXBXB39SW6tGEfrmCWbBLP13DqSlNwkljOJNX1iz/x49Ym99euBll0db0dOi5TBgwGtFoY2PvHxtrdnHE9RkZTIyciQrsPOnX2rq1FxfSGY1+wplvCdC117L8jogqn0aILOvLdc5SDZJPf9I/t9pu/C3L+/dHzG+zTqutbBmevJyc80R7FeS7zTt65n8ilMNhERERF5iNM388UJisQ3JgOjHyn9P/WeuCHTc6ELiMNknL7Vz86d8rY9caLh196VqgD3JtlfXxSBK1dKpp1tUSSjoK9sxufP2W5ZtuJ2kLRSfCQpV1qG2XtOcTF4ZGQA1ao5ThCNHw9s+8Px+8ZRKzz9vo2lp9vfpt7QoabXVHy8lEBQoCWIYLtjrDzFSbkgs3MedKkk0WlS1FuumBjH6+hb7aSnWyQ9DRIS5CWuAJ/oRif3/ePU+6x4RMoOb75sei7i44G5c5EuJ5laChxdjkqD3eiIiIiIPMSVf9wF4xGH5HI2SeIKRzd3+lHsbCS4rBUmd2fLmsDrV4Evv3TuSRttdGG0VSNIia5B1gq2O/t6ymzZZC6zTQe7r5mFoiL7y2/flrcdY/aOVV/H65FHgPvuc9xK8Px5NF70tuN9uvK62Us8GE8bJ5qKY0K/flIi1FF3PKMi827x11/2a/a4qlMnx+vYG3hAb+5czybIHXDUjc7R+0f/mZfZpoNTdcbSk/sABw8apncvWGm/C7NM+eGRdrvoGWK1w3D1FNdkK5fdTMllTDYREREReUhmmw5AXJxr7RGcuCGu99nHljMvX3Zlr64zupm0YGMUO9nJuKQk+7VMlDJypEXtH5Pi5UY1guK2bJRa2zjB/DoQbY3up1Q3OkfbkZMAMNa6teMRBZ1lL9nkTD2pYk3nzUTLNyfbH1mulF26Am6YjZgo57jnzrVfX8qoWHm7iY+XKj6bXEkGyiG3BWZxqx2LgQcAoGlT99YB+vdf4Phx555TmveP0Xs7busm258hthht72qru1xv5WoU97le/azGavNzyFpYEA2fiUlDe7tWb1A/eEBpC/yTz2GyiYiIiMhT1GrgySddG+nLiRtiv5u5ljMPH0bg5Yuu7Nk5xt/YR0QAr75quU58vNXC5PqWAY6+bUdSUkkiy50JJ1EEnnhCKpCs1dot/t1+7HDnWp+1bIn8ylVMZulHdbK4yXbQIgkwu2GUWyDc2g2zrZEHrcmwMkS6MVduiBXuDiUAaLB8MZKG9kbvdg2AiRMtR8Vz0ArPEXWBabF57Nsn/8n6lk5GLVdsFis3Xq7VIvi80UiNbrpBLwoKdv5JTryG6cl9TAYeMIiKcn6/zliwANiypWRaRkF5k26Lto7Rzsidvy5YCQD2P0NsxeHM6JTWCr7r5xlt/3rzRKvJPpufQ1ZE79rq2vEUM05UlarAP/kk1mwiIiIi8qT69Z1aXRQE3IqORbBWKyVwYmOB6KaIOvA7sCenpOiw0Q2IrVvmyKNWbuoUFLdlIxJff9lQbNiqpk2BP/5A+mmjhFjxN9uBmZek5M60aZYFcfX037b37YsjY19EsxWLgJwcpQ+lxLVrUpetuDipJYi94t/vvOPUpn9/dym6jCi+odu2DZviEzGgQWXLFY2TR3KSCkVFUoJs5040vXYbSLkfSGglv4VUSgo2NUvCgIZSMqwoMAh+t29Zrqc/7gkTgL59LZNLgZajHzpUWOj8c2QKvH4VmDsXSZhrufCJJ4CpUyHC9vvHFm2AxnRGZqbzwf3zT8nvTz5pvRaV0fKe/hoEG7/PatVSrBaUsUvt70bc9s0W8+2eJ2cThp4qMG0vgdGvH/Daa9Lns61C7nJrp5m9f1C9OnDqFNJPZgFdW9r/DLH1XjJ67wp2Wv/FbdkIzHzFkPxJApAfWQmAANy4ZrJupT8P4eD0d5B+X8+S97omEIefn4p2lSvL+qxpvOgdx8ez9ZD119hRgf/PP5eSjvri+tVbOIyHfAuTTURERESlZVy42NE/xc502SlOuKhv35YSHsX6qVRQGd9wxMfL6hKjLnLfjXzclo3WbxzMHTkCfP11yShhqanA+PFIMvpmvDAkFAECgFyzFlr6b9tTU4Enn0Szq1dNFmtVKqjdVa+quCC0rRtsQRQt47Xnjz9Qdf+ekmmdDgnffgmobko3WHFGQ5obH5ON4zOpJ9O4MXDjBgCgCQAseht9IisDU/7ncDsGRjeHVhNNevqi7WlpUoszk6BcaCn066/OP6c0bt+WEjXF158rbZsKIiuZzqhatXQxmV3X1pYHmc9zdgQ+QEoG5ufbfc9e7NINcWI+sGOHyfxb1WIRfNlG115PFOt2ln7EQXumTi35vWpVYNEi4I7uhlmC8efnnj1S4twW4+RKcDCgVjscAEGw914ySTbZSALZSN5YdPMsVvezj3G5YxeTEUn98m+j3XNPShPx8YibPAPp9/W0OShD0BXb3bP1xxO1dzcy23U2Xeho5E7AMAKkXs+Y6sDC+e7tXkmKYrKpjFp3MsvqtPl8/bwBdSOsTltbX+427c2zFZ+95ztaVx+3+bS95ztznObTts6ZtVicOS452zJfbm975sdo7Zjlvl724rd1HOZxe2pftrZh67jlvlZyritntidnuZxzYW19V197a+vI/Yww3pe996K919ne+ZV7/q0dg7Xl1rZl6zjsxSQnFjmfEfb2I4e9fdv7jDH/3dH5Nt+2ozjsTbvyPna0P7n7cjZWW9u2eo60Wuxc/S0SMi8B2enIW/yBSSuDnjHVsXvyG7BWWnVd9RboGVMdQZcyHBfirVwZuHoVAWbfSJt/sy2mp9tvCeGAnM90m9eCVosB5w6i9Ss2RgYzIwIQir/t3r3oE7QfO9ziPARY6wYIYF2zJAyYPh1i8U2h+b70CThXWqd4Q93VH5VMdOuGdmbLb1eqgrjp7+DbxDboVTxv29lsXKtq5bo1PofFiSZjATeuQXzuOcN5+e50NlC1pKvS4atSstLR54Itvx06iXMJrUyum9xCHUL14UHea7L/z1No7fTeXScWFDguNO5A4JXLJp8/YVENcL8y4dlkEa8oQhQEw3vL5t/vWqGGeVmx8Yg4fdJi26IglLwnVSpcul0E82pqgmg7WfnliRvQ+flhwIXD+O3QSdyOikaY0WeW3L97605moZ/x9D/XELV3t/S5m1jXNKl/7RqifkuTuuIWJ3qM96NP9Mh25QrEgQPR/IlngQ/flz6rpkwqWf7EE8ibMhVxU2YhPbmP3f9JcopEbD6ZJcUtg/69ZOzbUzcMnwGCTrT8O2cneWPv2k58Y7Ltrrnp6Wg/ZhgKIitbtIpyhn7gB+O/qX9N+h+aOXrfmbWsCrp4AWK/fhC++AK4o7v9v9HkE5hsIiIiInJGaip6jnnWJLlk3sog6OIFtB8/yuKpbcePxIX7euK/h4ej6fuz7O5m56qvkPTKWACWNwsW06Lo+iDoWq1r3VgEwaTbnMbxM6SnAdK33b+nSc91ohVEz7ubAZcybLcMMPrdUXLDFxJSgdeu2F9+/SraPzsCJweNNMyzeZOvtT8ynACzguS2aja5KDDzsjQSlT4J4GLXqPzKzrUKEgGI5i39nKDENRD+7zGT95GgKimL68nrzFFLksaL3gY++cAwK+LUCaBKFYuWVPmRVRB4Xbo2I48cRrVfLWuR2Rs5svqPm9By1v8BFy8YEqgF4aVPCPS5qx40WSWtdPqGlCTOcPo0kob2Rl5MdRwqTgDJjdeehkvnAxEatH/HsrtY0MULaD9mGH6dvwLpPR50uK3bVeTVobI2UILxFwyxW79DVpPmQK0ehnmOWk1ZIwAIzkjHHVOfs768+O+K+Zcdzrpdxew9/eKLaPr+W05vx3Bsgwcjbu7Hss45eRcLhBMRERHJFLdlo9XCvdaSQdb+6a+xaQPaTXwczebNREFEpOUKfkbfA6rUTt08uHpDG7V3t0vP88/JRvuxw20XMXag2u8/I/jiBafiDrokb0Q+AYBO7dx3qj7Y8ceg7trlht+FwgKr60T+87fD7Qgmv8s/4kLjm3orREGFxBmvGEai6tmlufRekVFHzNy15q0cr2RMEPDPY2Oce47C/PJvl7yPtFpUOnzAsKygkpUaXG5mnliJ27IRfdrWQ7N5M6UaZMbMpwFDogkAEr6zXufI3uvZbuJjFp8L/tnOteI2MEqyGCeaAOstIPUJoJavv2wyAqHskS6NGD7H333XaqtN/fJ240chblOqYUQ1ayMfxm3ZiLteeMru/sTiARAy21i2iY3ZudXwe6sZr0gFtatVQ+P5swGtFtW3fef08ekFXrPdbdPW3zK921WiHH6StB830jAyXdz3XwFvOZ9oMqHVov2zI+SPdkdew5ZNRERERHJotYaWOEq0VDCvo7F/ymy0/ngecEG6SQuUmVgpLVe/8Q+6lFG6c+FCdseZfalktPQxptUEwi/fTUPBl4J5nB2fHop9M96XvtXXahG1dzcCL2UgOm2bcxt2oiXQxU73IsHOjZ15a6ugSxloP3Y4CsLCnYsJANROfBceH49fJ89AenIfNFo63/l9ySC3ZVJg5iVDSz+Twt2i5a9yr2NXW0WZJFZSU9F+zDA7O7H/RgxwJUlkIzFjUFQkJdYLClD/048Qcu6U1c3Ebdlotxi2Nfr9NFi5BA1WLkFecZ2fzDZJyIupbvrayKXT2X0dVDod2o8fZVgnCZD2W8zvZq7DenYiIC3XD4BgJG7LRtwx7XnLJ127hmbzZqLh0vnwy3OiXpyCrjdsipjdO+2uE3DjOtqPHY5f31+OO16VWlEp8Tc08Y3JUj0p8llMNhERERHJELV3t2s3KjaY/7PddNFbwNWSFgWJb0xWbF/2uPKNPwCoiuwnc2wRAQgJCdD5uXcEKmdvZtQ+mGiyJiAnG+2fHYH0+3qg8l9/uHxNCqLouGaYfl1bBYntbFsUBPjnZDsfl8zkwtmeD6HG1+uQfjJLakliRqnua0VBwfC/ledwvdDTJ6WusRbFmUtaDjkTj2hrNEYHzxHi45F5R1tpdMdLGcCs/zm979JytK+o3TtQ58s1SPhug+1rUBSl5H4pBV28APTvj7j3l+O/AcPQbL797stKMW6Fqbl2xWFiXgBQFBgIv7Q0RN1UAzodqu3dDWh1qPP5StjLzpcm0VQQFo4AF96nelUP/O7w9RYAiKKIO6Y+L40IqQB9F8CovbuBBr0crk/ewWQTERERkQyutgCSS3PVtH6Ppvifcrk3za7eXGfe2d6FZ5XSoEFo+tZsn6ibpFfaODx9LHFbv3f6OSYxOkjqxH3/teH3+B83Ob0vwcVWb4JOXoKl6v7fgQ0b0PPZ8VYTblmNmiLyxHGpFU0p7J/2Ntq99IzddYoCNFJCwFGLHifITQTqGVrGDBqEnvcmmpwTX3mP6XUZNcBxTDduKJLcFwBAFNFu/CiX63rJ3o/xtNHrp9LKS9b63b4NzJ2LJMwt1b6dkXlHW8SmbXP53PjbG6nSiADHNepcEbdlIxAXKo3c6WKdOHIf1mwiIiIiksHVFkBy2bpJlZVocmWIecOOPHsreqXVXcCaNdKuPbpn93C2a5QSBKOHXOapC7vJjNRUtB83wum4lFB/2QJZ6wVfvAAMGGCzZljgxQulTjQBwO24BIfr5FWPd7r+mNIEAEXBocBbb7lcR82n3Fa2paE7E01lWfWffizT56b+J0uBe+4BatUCUq3XFyPvYbKJiIiISIbMNh2QH+n5Yr9y5FeqgvyISi49t/7yRUj4+gtg506LorYmtFqT7kquFtTWaTSlHmrel5SV4ygMDcO5Bx4smWFzVDvbQ6h7Qv1PP3JqfVvnP9CsJpor8mLjrBZrNqeyUbTd0/TdqXz9mpQV3/Hj7g6D4PvXimzp6UD//kw4+Rh2oyMiIiKSIW7rplIPAe0uhya/gbYvPu3ScxNnTTH83jckFP+MfBpX7uoE7LmJKF0YMu9oi8YfvAd88gGSrrlWf8ZYpT8PuvhMcllwMAJyc1Dju68Ms6LTtiOnboOSdYpbNzRe9LYiyUBf6iLpqit33IWE7zY4XC80/Zxb9u/sOSzr55vKnqKgYKhv5Xn/2tMnxydMAPr2ZZc6H8FkExEREZEj+pHofFSzuW86XePFmoCbuWi24C0A0tDUSVA+aWBtuHJyszzLAtctZ00xeV0bfTAXAdnX0VCBUd280yZKeTU2bUCNTY6TTXrlIcFG5Ay/W3m+9X4/dw5ISwOSkrwdCYHd6IiIiIgc0o9E56s3ku5qWQHw5rmi8M/NViTRBDhfT6q8UPqYK+I5pLLH567Tr792vA55hCCKXuqQ7SHnz59HQkICzp07h/j4eG+H47ysLGR2vheV/jwAPwByB55Vm61b2mlPbduT+ypLx+HObZeXc8Tj8N1te3JfPA7H2/bkvsrqtq3tSwd+Q0dEROTzoqKAjIwy0ZWuzOcqHGA3Ol9Wrx5w8iSijGY585YxX7e0057atif3VZaOw53bLi/niMfhu9v25L54HI637cl9ldVtm2OiiYiIqAzIzCz/XekWLgTeegu4eBFo2RKYPx+46y5vR2WB/zv5quJEExERERERERHJlJHh7Qjc5/PPgUmTgKlTgQMHpGRTcjJw+bK3I7PAZJMvyspioomIiIiIiIjIWdWqeTsC93n3XeCJJ4CRI4EmTYAlS4DgYGDZMm9HZoHJJl/Us6e3IyAiIiIiIiIiN8vJyUF2drbhkZ+fb33FggJg/37gvvtK5qlU0vSvv3omWCcw2eSLzp71dgREREREREREZY8Pdimzp0mTJoiIiDA8Zs6caX3FK1cArRaIjjadHx0t1W/yMSwQ7otq1ADOnfN2FERERERERERlS2ystyNwytGjRxEXF2eY1mg0XoxGOUw2+aJNm4DISG9HQURERERERFR2xMcDnTt7OwqnhIWFITw83PGKVasCajVw6ZLp/EuXgJgY9wRXCuxG54siIoC6db0dBREREREREVHZMW+elJApjwICgNatgW3bSubpdNJ0+/bei8sGJpt81YkTTDgRERERERERORIUBHz5JZCS4u1I3GvSJGDpUmDlSuDvv4GnnwZu3pRGp/Mx7Ebny06cALKykNn5XlT68wD8AGhlPlVttm5ppz21bU/uqywdhzu3XV7OEY/Dd7ftyX3xOBxv25P7KqvbdnVfOv8A6DQaaPz9kJ9fCEGrBVRAQHg4cqGGf3YWhMJCCKIIQAdBp4OfKEKrUqEwJAy3q0QhMv8m8rNyoAvwh6qwEJr829AWFZXsS6VCgdoPgACIIgJELbRa0yPR+fmjKDgE2oAA+N+6BWi1UBUUwF8QUejnj/zIytD5ByC8IA+F165DKCqCAEDtp0ahoIKoUgE6HQJEncW+b4eE4XalKgi6fBF+t/OKlwhQqwQUCSpo/f0hiCICRB0KRQG6AH9AJ0IjapEvqAEBEAoKEaAthFYUIar9oPX3h8ZPjTx/DXT+AVDn3URAbra0aZUK2oBAFIaEQFWQD7/cm/CHDkUqFbSBQdD5ByCo4DYKC4ogqgWIggoabRG0hYWmr48gQOfnD11AADQQUVBQBAgCRD8/6DQBgFYHv5vStgv8A1AQFo6Am7kIUAm4pfYHtEUIyM2BGkCRIED084coCAjQaVGkk15LAFALAopUauRXqoTC0Ahosq5Ddfs2hKIiBAgiCrVmrz0AEQDUavip1SiAAFETAFEHBPqrkZ9fAHVhAXT+AQgIC0V+dg78bt8yeb1FCBAFASoB0KlU0Kn9odFJ50CEAAgC/CBKcQsqqLRaqFG8b0EFEYC/qLN+jQsq6FQqQKWCKAgQRBH+Af64FRCIwqBgaK5dhabgNopUKhSGhqMwKBjh1zKhNRpJSa1SocA/ANqgYNyKjUPlpg1x7a9jCLpwHupbt6TXWKOBLiAAqoJ8qPNuQdBqoRK1hjhEQDqO4nNmvO0iQYCoUpe8toVa6XwUFcJfW1RynGo1RE0AchNq41rjpqi3bzcKMzKgKtJBVAvw8/NDvtoPQmERVIX58BMEFInSWw2iWPx/uABtQABEtQqa27ehFQQUaoIgqlXwz82FIEUqxaNWAyKkcyaI0ntLECAA8NcEIF8rQlQJEERAE6RB/s1bEIrfbwEqoKBIB5VWCwEidGo1dMHBKAoMhlYTCFVRIdR5N6HS6aBRCyi8mQehqFB6H+vPWfHrZfxaFgUFQhMQgNvF50h9+xYCigql4wrUQOsfAHVBAYSiIpPrBABEtRp+ISG4pfKD6tYtqPPz4SeIKIQAqFRQaYuk94fRsVv7fDKhUqMgLAw6P3+E5OWiqKBQut5EIAA6FBV/RhQFhyBILaAgOxeqogLT41KpofX3R0BQIG5pdfDLvQmVqAUEATqVGjo/f2i0hdJnmUoFrSYIAdWq4lZ2LtQ3c6XXx0+NAq0OEEWotEXwU6lQoFJDVPsBEKEpLIC2SCu9DoGBgE6UXitR+qmC9P4XBQF+KhWKdDrpuSoV/AP8kR1RGaqiIvhn3YCmqABFOh0gws57T4A2OBhZderDPzcXwRfOQV2Qb1gmCoAgwvT1UanhFxSIfAiG+AJUQIFWlP7mqAD/gADcDAoBIECVfwt+ebekDYmAoJX+DgCCdD791CgqLILW3x9QqaARgHytCKgEAAI0AX64qfKDX95NqAvy4efvj1uBwYAoQp2XB5W2EIAAnZ8fRD9/6AI10AYEAqKI0Fu5KLydD1Hth8LAQITcuomi/AKIKhVEtQoBAAqKX1d1QYH0OVukg6gSAIjwF0XpvalSoTAsHEF3JAIvviiNyFZeWzQZe/hhIDMTePVVqSh4YiKwebNl0XAfwGSTr4uIwM4N2wEAA+pGIPVklqynma9b2mlPbZvH4fltl5dzxOPw3W3zOHgcZW3bSuxro9n0904ch/lzzZd/XYrj+MrsuY6mzff9jZ3j2OBgW46Oa5MTx+FoX45en6/tHIf5+f3WbNp83/amzbftKE7zfZufs41OnCPzbZvHWZr3nqNz4ui4tin43jPft9z3Rz0Z16gz58zRcTjal/m0rWtUzrYdnbNvnHitzZ9r/tqb79veOXN0HI7eW/ZeW/PYnD0O822X5nPWPO4tCl1XrvztMT+O70pxHObb/k7m+be2bUfXjXncjq6NCmfsWOnh49iNjoiIiIiIiIiIFMNkExERERERERERKYbJJiIiIiIiIiIiUgyTTUREREREREREpJgykWxauBCoVQsIDATatgX27PF2REREREREREREZI3PJ5s+/xyYNAmYOhU4cABo2RJITgYuX/Z2ZEREREREREREZM7nk03vvgs88QQwciTQpAmwZAkQHAwsW+btyIiIiIiIiIiIyJyftwOwp6AA2L8fmDy5ZJ5KBdx3H/Drr9afk5+fj/z8fMN0VlYWACAjI8OdobrV1YxsAMB5TY7hd0fM1y3ttKe2zePw/LbLyznicfjutnkcPI6ytm0eB4+jrG2bx1G+j8Od2y4v54jH4VvH4c5tW5suq/Q5Cp1O5+VI3EMQRVH0dhC2XLgAxMUBu3cD7duXzH/xReCnn4Dff7d8zrRp0/Daa695LkgiIiIiIiIiIhfs2bMHbdq08XYYivPplk2umDx5MiZNmmSYLioqwt9//42EhASoVCovRua63bt34+GHH/Z2GEREREREREQ+Zc+ePYiNjfV2GE7T6XS4dOkSWrVq5e1Q3MKnk01VqwJqNXDpkun8S5eAmBjrz9FoNNBoNCbzOnbs6KYIPSMqKsrbIRARERERERH5nNjYWMTHx3s7DJfUqFHD2yG4jU839QkIAFq3BrZtK5mn00nTxt3qiIiIiIiIiIjIN/h0yyYAmDQJGD4cuPNO4K67gLlzgZs3pdHpiIiIiIiIiIjIt/h0yyYAePhh4O23gVdfBRITgUOHgM2bgehob0fmOTVq1DDUmxIEARqNBoIglHpayW15cts8joqzbR5Hxdk2j8O3tl1ejoPnyLf2xePgOSpr++Jx8ByVtX2V1W27ui8/Pz/cddddCA8PB/kenx6NjoiIiIiIiIiIyhafb9lERERERERERERlB5NNRERERERERESkGCabiIiIiIiIiIhIMUw2ERERERERERGRYphsIiIiIiIiIiIixfh5OwAiT9FqtRAEAQUFBfDz84MoisjOzoafnx+Cg4OhVqtRUFAAURTh5+cHQRCQm5sLjUYDf39/FBQU4OrVq6hatSrUajVu3bqFW7duoUqVKrh+/ToiIiKg0+lQWFgIjUYDrVYLrVYLlUoFjUaDgoICFBQUIDQ01DA/Pz8foigiMDAQoigiJycHoigiPDwcubm5AIDw8HDodDrcvn0bwcHBuH37NrRaLYKCgnD79m0EBAQYthMaGoqcnBwEBATAz88P+fn5KCwshFqtNsQQFBSEnJwc+Pv7AwByc3MREREBlUqFgoICBAcHIy8vz3COVCoVdDodAMDf3x95eXkQRRHBwcG4fPkyoqOjoVKpUFRUBFEU4e/vD61Wi9u3byMiIgL5+fnQ6XTw8/NDdnY2wsPDoVarDccaEhICrVaLW7duITg42LAtAIbhTYuKiuDv7w+dTofc3FyEhYWhoKAAAQEBKCwsRHBwsGE/+hhDQkKg0+mg0+kgCALUajVUKhWys7MRGRkJnU6H/Px8+Pv7QxAEwzlWq9XQarUQRRGXLl1CgwYNoNVqkZWVhfDwcMP5VKlUyMnJQXh4OIqKiqDT6QzXT2BgIK5cuYK4uDjk5uYaYlepVNBqtSgoKEBERAQKCgoM8/Ux669DlUqFmzdvIjQ0FDqdDqIoQq1Wo6ioCH5+flCpVMjNzUVAQADUajXUajUKCwuRk5OD0NBQ+Pv74/r166hSpQoKCwuRl5eHypUrIycnB4GBgYZrKDs72zB0rP4Y/P39DdsDAFEUDe8bjUaDmzdvIjAw0HA8hYWF+P/27jxMqurMH/j33lv73tX7StPs0OwuiCJGQHFBjYyGOI4xRhMnamISTDJDHKKDMaiJmRlnknkc4y6aGCWOuBAQBBTEhU0EbHql9626uvbt3t8f/O6d6qaRBrq53c338zw+0t1V5773nHNPVb3n3FOpVApmsxkAtP4vCILW19U+lEwmtXNzu93a80KhEEKhELxeLwRBQCgUgslkAgAYDAbtOJIkIRgMQpZlWK1W2Gw2LU6DwYBEIgGLxQJZlpFMJmEymbQ6U9vbaDQiGo1CURSYzWbEYjEAgMlkQnd3N2RZhsPhgN/vh9vtRnt7O0wmE2w2GxRFgdVq1fokAC2uRCKhtVUsFoPb7UZnZyccDkePa9xkMsFisSCZTGptajQatfMAAEmSEAqFtLHAarVCFEV0dXVBkiRYrVaEw2G43W4EAgEYDAatn5lMJoTDYe2rg+PxuBan2+3WrlWbzYZgMAhBEGAwGOD3+5GZmYlgMAhRFGGxWNDd3Q2HwwEAiMfjMJvNWtzqtQVAG88sFot2barXsNp/UqkU7Ha7dn2rY2UymUQoFILVakUkEoHX69WeG41GIQgCRFHUrjm1bHV8kiQJRqMRjY2N2nPNZrPWDur5qY9XjxuLxZBMJrWxorOzE06nUzuHcDisXRuCIGjtpMZlsVgQjUaRTCbhcDggiiKi0ajW/zs7O5GVlYVgMKiVYTKZtDpTX1/U/i6KIqxWq9YW6jguSRIURUE4HIbT6YQgCNrfrVYr/H4/HA4HYrGY1i/Ur4RW6ykSicBut2v1qvYBtf7U8V8Uj85BRqNR2O12hEIhbTy02+3a+K6OB6IooqOjAx6PB6lUShuDjUYjkskkUqmUdsx4PA673Q6fzwe73a6NOeo5quOw2lbqz+r4IYoiFEXR/qb2rfT/p1IprW+q56LWgXq+ALTxSG2L9Mepx1H/1teXNqt/U68BtXy1rdJjSS+79/F6l6+ec/o5qcfpK6708nrXR/rvev87vQ7T60eVPmYfr66/Kva+Ykx/DRRF8ZjHqMdT2yj9eOnl9C6vdz32Pie13nqfT/rrU+86SX9uenv0fmz6+abXrdoX0qU/Vn19TK/vvtrmeOee/tjev+/ruukda3rf7N1neuvdJ9NjTa/7vurhRP1I/X16eb37dV/9XK3P9Of3fk56W/V1nK9qv776YO+ye9dxev9VH6/Wc+9rJr383n1UfQ+qPuar4u79+/S/pT82vd569+u+2qSvelbHZvU9Tvo1nC79nNLH4/SY0sfI9OtRfa5aD+nXeF9jTu867+s6TdfXsdPb63jXQV/jZO9xLp3afr2vFfW81Oeor8VqH+ndn3pfJ73rJb1+0l8j+mrDvv6m1l9v6ePqQGCyic4KXV1dWL58OWw2G/7yl7+gvb1d+wBGRDTUmUyms27MSn8DT0OPwWDQEocDRRRF5OTkoLOzEyUlJeju7kZbW5v2ISc9uahOini9Xi3Zm0gkUFxcjKqqKoTDYWRnZ0MQBC3JDgA+n0+bZLJYLGhtbdWS5+qES/rkgZqUtVqt2qSExWKBw+FAKBTSJoAU5ehEVTwehyAIsFgsWpLZYrEgLy8PyWQSXV1diEQiAKDFrF7fkUgEJpMJBQUFaGhogKIoyMzM1M41lUppiUI1sQwcTeKPGTMGdXV1CAaDcDgckCQJXV1dsFgsyM7ORiQSQTgchslkQiQSgSAI2sSZJEnweDzo6urSEiWiKGoJbKfTie7ubkiShLy8PLS3t2vnrSZX1Qkcg8GAoqIidHd3IxgMIiMjAzabDY2NjUgmk0gmkz0Siy6XC9nZ2WhpadES4k1NTTCZTCgsLNRiUuvK4XBAURQEg0F4PB7EYjHE43EkEgkYjUbk5eWhvr5eS5jH4/EekzhqIlRtr/REtiAIWkLcaDTCYrEgHA5DlmVtcsTn88FkMiE/Px91dXVaHaVPkMiy3KM+R40ahba2Nq391A+N6uSIOiHicrkQDoe1yUr1w21WVhbC4bA2EZCRkQFBELR+kUgkEI1GtXIVRYHJZNImu9QJElEUtbZUJygCgQDy8/MRi8XQ0dEBq9WqTVyqk49qWbIsY8yYMWhpadEm+NQP7gCQkZGBjo4OGI1GbWIjEokcM5FisVi0pLJ6TarJ+EQiAbvdrk1sqo9Xrw+r1apNtiqKgmQyiVgsBlEUYbPZEIlEYLFYkJubi46ODiSTSXg8HgBAU1MTRFFEZmYmBEFAW1sbzGYzcnJy0NbWpl23ABCLxRCNRuH1ehGNRhEMBrWEgNqHMzMzEQgEABz98G61WrUJKjWZYDQatX6g9lev16uVr9ZDMBiEJEkoKipCXV0dzGaz1lbq2KNet2q/UScdbTYbHA4HIpGINsmmjkWRSERLNKjt4HQ6tYkudVxVJ37UiW11skBRlB4TzWoZXq+3R+I4Ly8PxcXFOHDgANrb27WJHnWySp1sUicOQ6GQNgluNBq1x6uTeurkmtlsht1uRywWQ1ZWFnw+nzb2qv0uEokglUrBZrMhIyMDdrsdnZ2d2ngUi8W0vhEOh2GxWCBJEmKxGMxmszYGu91umM1mBINBbbJJ7cPqwoNIJAJFURCNRrVJJnWcjsfjaGtr08YcddyxWCzIysrSyunu7kY8HofX69UmM81mMwKBADweD0wmk1bX0WhUa5NwOAxJkrR+l/4609bWBq/Xi87OTiiK0mMyGQCys7PR1taGcDiMnJwcdHR0aMdVx4ZwOIyMjAytXUtLS3Huuedi+fLlKCsrO+XXdUE5XiqbaATp7u7GkiVLsGXLFr1DISIiIiIiIhqyioqKsGXLFowePfqUy+CeTTTiKcrR29Kuv/56vUMhIiIiIiIiGrIEQcDPf/5zFBQUaCt9TwVvo6MRTxAEvPDCC3A6nZgzZw527dql7dFCREREREREREcpioIHHngADQ0NWLx4MTweD8aOHQubzXZS5fA2OhrRFOXoxrTq5qXp940TERERERERUd/UPcm+9a1v4dFHH9W+cKQ/uLKJRqT0b09Qd/NnoomIiIiIiIiof9QvpbjyyitPKtEEMNlEI5Qoinj44Yfx3HPPoa6ujrfNERERERERDQBJkrRvhKORw2Kx4MILL4TVakVdXR0mTJiA0tJSfPOb38S0adO0b1rsLyabaMRQvzbU7/ejs7MThw4dQkNDA8LhsN6hERERERERjQhMNI1M0WgUGzduhCRJKC8vx49+9CNccMEFp1wek000IkSjUdxzzz3YtWsXKisrEQwG9Q6JiIiIiIiIaFhRFAWBQABGo/G0yhEHKB4iXRkMBsyfPx979uxhoomIiIiIiIion0RRREFBATZu3Ai/348vvvgC55xzzumVOUCxEelKFEVMnTpV7zCIiIiIiIiIhhVZltHe3o6dO3cCOLov1+lisomGPVmWIcsyZs+ejX379uEf//Ef9Q6JiIiIiIiIaMgTRRFOpxOzZs3CggUL4HA4YDCc/o5L3LOJhqW9e/eipqYG0WgUH3/8MYxGI0RRRGdnJzo7OzF16lTs27dP7zCJiIiIiIiIhrRzzjkHL774IvLz8wesTCabaNhJJpNYsGAB2tvb9Q6FiIiIiIiIaNhyOBy46667BjTRBACCoijKgJZINIhkWdb+7/F4EAqFdI6IiIiIiIiIaOix2+04//zzkZeXh3g8jhkzZsDr9aKmpgbjx49HRkYGzj33XBQUFEAURQiCMGDH5somGpZeffVVuN1uJpuIiIiIiIiI+hAKhbB161ZccsklCAQCCIVC8Hq9WLZsGa666qoBTS71xpVNNOz85je/wX333Qd2XSIiIiIiIqL+E0URpaWlWLNmDc4777zBO86glUw0SD766CO43W5YrVYYjUYYjUa9QyIiIiIiIiIasnJzc7F27VqkUikcOHBgUBNNAJNNNAyFw2H4/X5EIhEkEgkkEgm9QyIiIiIiIiIaslpaWrB69Wo0NDSckQUb3LOJhjR1Q/DXXnsNGzduxN69e9Ha2spb6IiIiIiIiIj6wWAwYMaMGXj66adRWFh4Zo55Ro5CdIpEUcQvf/lLrFq1CqlUSu9wiIiIiIiIiIYVq9WKX/7ylxg/fvwZOyZvo6MhK5FI4KmnnsLDDz+sdyhEREREREREw4IgCJAkCW63GwsWLMAbb7yBxYsXD+q3z/XGlU00pHz88cfYsWMHFEXBp59+ioqKCjidTvh8Pr1DIyIiIiIiIhqy7HY7vvWtb2HSpEm4+uqrUVpaqlssgsLNb2gIKS8vx/79+/UOg4iIiIiIiGhYkiQJ119/PX7/+98jMzNTlxh4Gx0NCbIsQ5Zl7N69GwUFBXqHQ0RERERERDQs2e123HrrrbolmgAmm2iIefLJJ/UOgYiIiIiIiGhY8ng8eO6553D55ZfrGgf3bCLdJRIJKIqCJ598Enfffbfe4RARERERERENeYIgoKioCHl5ecjLy8O8efOwZMkSjBs3DqKo79oiJptIN9u2bUM0GkVtbS0aGxvxxhtvwGQyacknIiIiIiIiIuqboihob2/H6tWr8c1vflPvcHrgBuGkm7KyMlRXV+sdBhEREREREdGwNXv2bLz++usoLi7WOxQN92wi3ezbtw9ZWVl6h0FEREREREQ07IiiiBkzZuCll14aUokmgMkm0kkqlYLdbkdVVRVcLpfe4RARERERERENKzabDQ8++CDGjRundyjH4G10dEbJsgwA2L9/P7788ku0t7ejpqYGjz76KFKplM7REREREREREQ09giDAaDTCaDTC6/Vi7ty5uOeeezBnzhyIoghBEPQOsQduEE5nlCAIWLlyJX79618jkUjoHQ4RERERERHRkKcoCjweD1555RVccskleodzQryNjs6oZ555Br/61a+YaCIiIiIiIiI6CW1tbfj1r3+N9vZ2vUM5Ia5sojOqvr4eGRkZSCaTCAaDMBgMiEajeodFRERERERENCR5PB783d/9HcrLy7FgwYJh8UVbTDbRoFIUBYIgIJlMQhRFNDU19cjCJpNJHaMjIiIiIiIiGroEQUB2djbuv/9+lJSU6B1OvzHZRIMmmUwiFAph/fr12LJlC+rr61FXVwdJkrgZOBEREREREdEJKIqCZDI57BZqMNlEA+69997Dq6++imQyiTfffBNNTU16h0REREREREQ07LjdbvzmN79BWVmZ3qGcFEFRFEXvIGhkWbZsGV555RW9wyAiIiIiIiIaVux2OywWC3JycnDhhRfiu9/9LmbNmgVRFCEIgt7h9RuTTTQoli5ditdee03vMIiIiIiIiIiGDYfDgf/6r//CP/zDP+gdymkR9Q6ARg5ZliHLMurr6/Hcc89h0aJFeodERERERERENGwEg0H8x3/8B2pra/UO5bRwzyYaELIsAwBWrFiBJ554AtFodNhtYEZERERERER0pi1YsACTJk3CmDFjUFRUhHPOOQejRo3SO6zTwmQTDQhRFLFixQo89thjTDIRERERERER9dN7772HyZMn43vf+x6sVqve4QwI3kZHA6K5uRlPPvkkDIaj+cvhtHEZERERERERkV4EQcAHH3wwor7JnckmGhBerxfJZBLRaBQAwH3niYiIiIiIiL7a9ddfjx07dmDt2rUoKyvTO5wBw9vo6JSoezQ9//zz2LZtG3bu3Am32w2fz6dzZERERERERERDmyAIMJvNKCoqwrnnnqt3OAOOySY6JaIo4v7778evf/1r7tFEREREREREdBIURYHZbMZll12mdyiDQlB4vxOdgjVr1uDb3/42kskkUqmU3uEQERERERERDRsejwd//OMfcc0110AUxRG37zFXNlG/ybIMQRAQDodhMBgwevRoNDY2oru7W+/QiIiIiIiIiIYko9GI2bNnIxqNYubMmZg4cSIWLFiAGTNmjMhEE8CVTdQPahcRBAEPPPAAnnjiCfj9fiQSCZ0jIyIiIiIiIhoeBEHAVVddhT//+c+wWCx6hzOouLKJTkjNsv7tb3/DH/7wB4RCISaaiIiIiIiIiE6Cy+XCnXfeOeITTQBXNlE/yLKMbdu2Yf78+XqHQkRERERERDTsuN1uPPvss7j66qtH7K1z6ZhsohNS92q67LLLsGHDBr3DISIiGrYkSeIXaxAREY1gDocD06ZNg9lsRjQaxbhx4zBjxgxceeWVGDt27FmRaAJ4Gx0dRzQahaIoeP/997F9+3YcOXIEwNFlf9wQnIiI6NQw0UREROlEUYQsy3qHQQMoGo1i0aJF+OlPfwqbzQZFUc6K5FJvXNlEPWzYsAEbN26Ez+fDW2+9pSWZiIiIiIiIiOjEJEnCP/3TP+Ff/uVfYDQa9Q5HF0w2UQ/XX389Xn/9db3DICIiIiIiIhqWBEHAzJkz8eqrr2L06NF6h6MLJptIoy7vW7x4Md599129wyEiIiIiIiIaNpxOJ1asWIEFCxYgNzcXxcXFeoekG+7ZROjs7MSOHTsgyzJeeOEFFBYWwmazIRwO6x0aERERERER0bAQCASwceNGfPe730VGRobe4eiKyaazXCqVwp/+9Cc89NBDaG1tRTwe1zskIiIiIiIioiFPEARccMEFyMnJQUlJCSZOnIivfe1rZ32iCeBtdATg888/x8UXXwyfz6d3KERERERERETDhslkwi9+8Qv85Cc/gc1m0zucIUPUOwDSX3l5OebMmXPW7pJPREREREREdCoSiQTefPNNdHV16R3KkMKVTaTZuXMnbrnlFlRUVECWZb3DISIiIiIiIhpy8vLy4PF4MH78eNx444244IILUFZWpndYQwqTTWeheDwOQRAgCAJEUUQkEgFw9Nvo1q1bhxUrVqCyslLnKImIiIiIiIiGLqvVim3btmHWrFl6hzLkcIPws8gnn3wCi8WCL774ApIkobW1FU6nE83NzUgkEliwYAEikQgWLlyI0aNHo7q6Gp2dnTAYDBAEAT6fD8lkEqIoar+LxWLona/MzMxENBpFKBQCAFgsFoiiCFmWkUqlYDKZenzTncFggMlkQjKZRCwW05JgkiRBURRIkoRoNNrj8V6vF6FQSDuG2WyGwXC0O6vlANDKcjgcCIVCSCaTEAQBJpMJHo8HJpMJTU1NUBQFRqNROx+LxYJEIgGz2QxBEJBIJOByuRAIBBCLxWC1WuF0OhGNRpFIJLS4DQYDrFYrIpEIFEWBLMtIJpMwmUxagk+WZSQSCYiiiFQqBUmSkEql4PF4IEkSOjo6tHN1OByw2Wzw+/3aOaWzWCwQBAFGoxEmkwmiKCIQCCCVSkFRFCiKov0bAGw2GwwGAxRFQSAQ0Mqx2+0QBAHhcBiiKCKZTMJqtcJisUCWZUQiEcTjca3dE4mEVr/qcUVRhCAIkCQJ4XBYqz9FUZBMJrX2EQRBq291Q3qj0aj1p2QyqcVlNBphsVi09lDjS+8Pbrcb8Xi8R/+KxWJIpVLaYyRJgsPhgMvlQltbm3Yusixr/Uw9b7UN4/G41pfMZjOMRiMikQhSqRSsViuMRiO6u7u1dlD7jiiKsNlsWr9Q29Hr9aKlpQWxWAySJGntnkqltOtDkqQ+2yMrKwtdXV2IRqM9zstkMmn3hauxqX1NURREo1HIsqz1EfX6kWUZ0WgUoijCaDRClmWt/tTHSJKknbvH40F3d3ePYyeTSW0FpNvtBgAEg0FIkgSj0YhoNApBELTnSJKknad6HSqKApPJBKvVClEUtWNIkgSLxaJd34IgwOFwaOOG2mZqPxRFEQUFBUgkEmhtbYXBYIDZbEYwGNTiFQQBGRkZSCaTUBQFwWBQG19sNpt2Lav9TlEUbZwBji6PzsjIgM/n046tlhmJRBCJRCCKIsxmM2KxGAwGA4xGI8LhMBRF0WJKJpOIx+PaNaBeF2p9q9eL2j+ORx3z1HqJRCI9rh11DE0kEtqYqSiKNgaFQiFEIhGtrg0GA/x+f5/HstvtEEURoVAIsizDZDJp5ykIAiwWC6LRqNbf1evWZrMhEAho7SYIgha72WzuMa5YLBYAQDQa1fqHOi4AOGb8U1+H1PNX29XpdMJsNsPv98NkMml9NZlMIpVKwWAw9ChLHV/MZjO6urq060CWZVitVkiSpPUjo9GIGTNm4PDhwz32OLRardq4rl4TRqMRWVlZEEURDQ0NPWJWxxq1vURRRG5uLiKRCARBQGZmJiKRCDo7O7XJICIiIhpaJEnCmDFj8Lvf/Y6JpuPgyqazRCKRQF5eHjo7O/UOhYiIaNg6USLwdI0fPx5ffvnlST3H4XAgFov1SMCqia/0fwOnH7/RaNSO05/HqpMFfU1OpVMT0Cfrq87nVMvsTU0Snugbe9OPpybyv6quj1eXBoOhR/K4t95terJOpl7S6zd90qw/+ttXjnc+Nputx+SkGrckSZBl+aTatq9zVhPlvfXuU4IgwGazaZMPJzoXdbKvL+pkxle170BQJ7XS++zxrhU1qZ8e88mME+mPVScej3ec022zM6k/xy8vL0dubi42b9583Prqz/WqTlSfKB51Urf3daVOkp7K2P5VbSaKR7d37it+SZJgtVp7TOz1ZjAYekx6fxV1gcCJzqGv/tqXrzqvEz1v3LhxuP/++3HxxReju7sbRqMRoVAIkiQhNzcX0WgUZrNZmyhTJ4klSdLio6OYbDoLqLPZFRUVmDx58qC/wBEREREREY10JpPphIloGn6mT5+Oxx9/HOXl5ZBlWVuhHggEYLVatVX56p0tsixryTn6P7yN7iyg3s713nvvoaSkBFVVVXqHRERERERENKwx0TQy7dmzBwsWLMCiRYtQUVGB7OxstLS0ICsrCzabDdXV1Rg9ejQmTpyIn/zkJ5gwYYLeIQ9JXNl0lnjkkUfw85//XNflqEREREREREQjQW5uLl5//XVccMEFeocyJHGt1winKAri8Tj+/Oc/91juR0REREREREQnr7i4GK+++ioTTV+ByaYRLv2b19TNObm6iYiIiIiIiOjkFRYW4sUXX8RFF12kdyhDGvdsGoHUbwzYsGEDPv74Y1RWVqK9vX1Qvz2HiIiIiIiIaCQSBAEWiwXjxo3DE088gXnz5ukd0pDHPZtGqAceeAD/+q//ygQTERERERER0Umy2+34wx/+gOLiYng8HlitVmRnZyMjI0Pv0IYFJptGoD/+8Y/43ve+h1QqxVvmiIiIiIiIiPrJbDZj+vTpWLFiBRYvXgwAMBgMEEXuQnQyeBvdCKMoCpqbm1FeXo7q6mr4/X69QyIiIiIiIiIaklwuF5YvX47x48dj0aJF8Hq9kGUZoihCURR+wdYp4sqmEUDdo6mqqgoOhwMrVqzAH//4R52jIiIiIiIiIhr6BEGA3W7HHXfcgYceeghWq1XvkIY9rmwa5tRE0/3334/HH38csVhM+x0RERERERERfTVFUSCKIhYuXMhE0wBhsmmYE0URv/rVr7B69WpuBk5ERERERER0ktxuN5599llcfvnleocyYnCHq2EuHo/j5ZdfhsPhgMFggMViOeaeUlEUj3uf6ZnY5EySpNMu42TjNBj+L48qCEKPnwfC8crr77lKknTKMR2vLk6lLQe6XgbKyfYZvTfrS7++BiqWU7k3vD/H7m+5X/W4071v3Waz9auNB/r+eD37+6mOQ33Vk9FoPOU4+opBEIST7rcD0TanUh8n0y8tFku/y83Pzz/pWE4UT28FBQWndAwiIiIaOBaLBR6PBx6PB5mZmZg2bRruvfdevPfee7j66qt1/1wxknDPphGgqKgILS0tSCaTeodCREREfXC5XOju7j6p5wiCwG+VHUSiKHLrAR2YzWbEYrFBK1+SpH6t9lcT7bwzoG9n8/gzZ84cVFZWoq2t7bTK6W9fPB6DwXDGP98NRrsPlb6UmZmJ2267Dbt27cLUqVORn5+Pv/u7v8Po0aP1Dm3EYrJpmFHfFLW1tUEQBDQ3N+Phhx/Gyy+/rHNkRERERERERMPD7Nmz8dprr6GkpETvUEakoXkPDR2XKIpYuXIlVq9ePaizQkREREREREQjkcvlwi9/+UsmmgYRb0gcZl544QU8+uijTDQRERERERERnQRJkjBt2jT86U9/whVXXDEkbvEbqXgb3TDyxhtv4Bvf+AYSiQTvLyciIiIiIiI6AYvFgscffxx33nmn3qGcVXgb3TCQSqWQTCaxe/duRKNRvcMhIiIiIiIiGhai0Sh++MMfwmaz4Zvf/OZpfbMv9R+TTUOYuhl4IpGA0WjUMrErV67UMywiIiIiIiKiIctkMkEURQiCAKfTienTp2Ps2LFMNJ1BvI1uiFITTQ8//DD+4z/+A+3t7bx1joiIiIiIiOgEBEHA0qVL8dxzz8FqtUJRFAiCoHdYZxVuED5EiaKIVatWYeXKlWhpaWGiiYiIiIiIiKgfFEXBq6++igceeICJJp3wNrohasOGDXjooYe0FU5ERERERERE9NWys7NRUFCAKVOm4PLLL2eiSSe8jW4IUhQF0WgUL7/8Mt5991288soreodERERERERENOSJoogdO3Zg9uzZEEWRK5t0wpVNQ0QkEoEgCPj8888BANXV1UgkEqirq9M5MiIiIiIiIqLhoaCgAD6fD6J4dNcgJpr0wWSTznbt2oW2tjYcOnQIb775JtavX693SERERERERETDTlFRETZu3IgxY8ZwRZPOmGzSUSAQwM0334wDBw6AdzMSERERERERnZqMjAz85je/wfjx4/UOhcBvo9OVw+HA8uXL4Xa79Q6FiIiIiIiIaNgQRRFLly7F1q1bsWvXLhw4cABLly7lQo4hgskmnciyDFmWcfPNN+O3v/0tJEnSOyQiIiIiIiKiYUGWZaxduxbvv/8+pk+fjtzcXEiSxFvnhggmm3QgyzIAoKKiAg0NDcjNzcXKlSuZcCIiIiIiIiI6DqPRiJycHGRnZ2PixIm44YYbMH/+fCaYhiDu2aQDURTx4IMP4l//9V+RTCb1DoeIiIiIiIhoyEskEigqKsLbb7+NnJwcbgI+hHFlkw6eeeYZrF69mokmIiIiIiIiopPw2Wef4a677kIymWSiaQjjyqYz7J133sEPf/hDxONxvUMhIiIiIiIiGhbKysowc+ZMjBkzBkuWLIHBwHTGUMbWOUMURYEsy9i+fTvC4TBXNRERERERERH1U1VVFX784x/j+9//Plc0DQNMNg0ydTPwXbt2IR6PY+zYsbjlllvw9NNP8ysZiYiIiIiIiPpgNBqRnZ2NSCSCzMxMTJ06FRMmTGCiaZhgsmmQCYKABx54AA899BBXMxERERERERH1QyKRQFlZGbZu3QpFUaAoCkRR5KbgwwQ3CB9kTzzxBFatWoVUKqV3KERERERERETDxrZt23D11VdDEASI4tH0BRNNwwNXNg0SdY+mDRs2oKCgAC0tLdwUnIiIiIiIiOg4LBYLrr32WlRUVGDChAnIz8/H1VdfrXdYdAqYbBokgiBAkiQUFRXhzTff1PZuIiIiIiIiIqJjRaNRvP7668jLy8Py5cvxjW98g7fODVO8jW6QTZkyBZIk6R0GERERERER0ZAXj8fh9/uRlZXFW+eGMUHhV6INivTM67Jly/DXv/4V0WhU56iIiIiIiIiIhi63243nnnsO11xzjd6h0GlgsmmAxGIxGI1GBINBbTPwVCoFSZIQj8cRi8XwzjvvYN++fejs7ITRaITZbMbHH3+slVFUVIRwOAyfzwdBEJBIJBCJRJCVlYWZM2fio48+QiwWgyiKyMvLQyKRgCiKsFqtAICuri5Eo1EoigKr1YqcnBzU1NQgFovBZDJBkiQIggCDwYBUKoVUKoWmpiZkZGQgIyMDEyZMwJEjR1BRUQGTyQS32w2PxwOLxYK2tjaEQiHYbDaEw2FkZWUhmUwiFAohEonAZrNhzJgxyM/PR0dHByorK7X6iMViEAQBHo8H4XAYBQUFCAaDsFgsyMjIQGNjI/x+P0aNGgWn04m2tjYoioK2tjaYzWY4nU5kZGQgFApBURQEAgHIsgyDwYBgMIisrCy0trZClmVYrVbE43E4HA5EIhGMGjUKRqMRn332GQBAFEVMnDgR0WgUgUAADQ0NUBQFyWQSyWQSbrcbRUVFiMfjyM/Ph8lkQmlpKT766CMEg0EYjUYkEgnEYjEkEgkYjUZ4vV7tNsnq6moIgoDMzEyMGjUKwWAQra2tyMzMRFtbG8aMGQNZlhGLxVBXVwdBECAIAlwuF7q7uyHLMrKyspCRkYFIJAKLxQKj0QhFUXD48GFEo1Hk5+cjFotBlmVkZmaio6MDoijCaDTC6XRqsUmSBKvVCp/Ph+bmZgSDQbjdbmRlZcHtdmPUqFGor6+Hw+FAV1cXKisrtZmDKVOmoKurC5IkIRqNwmazoampCUajEX6/H7IsIycnB16vFyUlJdi/fz8SiQQURYEkSRBFEQ6HAz6fDy6XC6lUCtnZ2fD7/YhEIj36QXt7OxKJhFZfHR0dWp34/X4kk0ntWH6/H+3t7UilUpg8eTK8Xi8OHTqEjo4OWCwWyLIMRVHQ2dkJr9cLi8UCQRCQSqW08sPhMGw2G4qKilBVVYVEIoGamhrYbDYkEglMnjwZmZmZ6OzshMFgQF1dHXJychCJRGAymZBIJNDe3q493ul0wmAwoKurC6lUCoqiwOl0wu/3w2q1wu/3w+PxQJIkSJIEv9+PsrIyiKKIxsZGxGIxeL1eJJNJ+Hw+tLW1IS8vD5MmTYIgCDhy5AhEUYTdbtfOPRKJIJVKaf0jEolo5242m+H1elFYWAi/34+qqirE43EUFhYilUrh8OHDMBgMGDduHARBQDAYRCKRgM1mQyQSQTAYRDweR15eHsrLy1FXVwe/3w+DwYDCwkLs2rUL4XAYFosFbrcb48aNQ1dXF8xmMw4ePAij0QiDwQCv1wtRFNHR0QGD4egd2263G8XFxWhoaIDNZkM8HkdWVhZaWloQCoVw5MgR5OTkaPvcqd844vV60dTUhJycHCSTSdTV1SGRSMBut2PMmDHo6urS6t9ms8HhcCAjIwOKoqC9vV07x/TxRRRFyLIMs9ms9fOCggJ4PB64XC7E43Hs2rULiUQCra2tyM3NhclkgtlshslkQm5uLqZMmaJdH1VVVWhra0NzczNyc3PhdrvR3t6OI0eOaNdSZmYmAoEAvF4vioqKYDabsW/fPu26Hz16NDo7O+F2uxGNRhEMBtHU1ASLxYK8vDw4HA44nU4cPnwY7e3tWp+yWq0oLS2Fz+dDNBpFV1cXvF4vvF4vJElCY2Mj2tvb4Xa74fV6AQCBQADt7e0wGo2QJAmJRAImkwmFhYWw2+2ora2Fw+GA3+/HrFmzEIvF0NbWhoKCAiQSCTQ2NsLn88HhcKC5uRkulwstLS1wu92w2+0oLS1FMplEd3c32tvbEYvFIEkSJk2aBIPBgM8++wypVAqFhYWYMGECKioqUFVVpX218ahRoxCNRrU6NBgMmDx5MrKzsyFJEjZt2gSr1Qqz2Yzx48ejra0NyWQSLS0tcDgcsFqtmDFjBqqrq5GTkwO32w2z2Yz9+/fD5/Np43hHRwd8Pt+ZeaNARDTI1Ne20yEIAvjxsP/U9/LcMuX0qe//582bh+XLl+Oiiy7iHULDHJNNp+HIkSPYsmUL/vu//xt79+7FvHnzsGvXLjQ0NGj3ldpsNgCA2WyGxWJBd3c3gsEgAGDy5Mk4cOAAFEWBwWCAIAiwWCyQJAnJZBKCICAQCGg779tsNi1R1N3dDQDIz8/XPpAbjUaEQiEtPq/XC6PRiJaWFlgsFm1llVqGmphJ7wJOpxPBYBDJZBIAYDKZ4PV60dLSApPJpJ2XWpbJZEI8HofJZNI+7KZ/857NZoMkSbDb7Whubu4RW2dnZ48XRfVDZXt7O4qLi1FfX68lENRkniiKGDNmDOrq6rQP3Xa7HaFQCIIgwO12o7u7Wzu3RCIBs9msnafT6URxcTG++OILLXFkNpsRi8W02NTfFxQUIB6Po7OzU4sxIyMDPp8PJpMJBoMB4XAYHo8HXV1dMJlMcLlcEEURfr8foigiEon06DMWiwWpVAqjR49GIBBAU1OTdu4Wi0VL0rS1tWmJREEQ4Pf74fV6tQ9FfV22LpcLOTk56OzsRCKRQCAQgMvlQkFBAQ4dOgS3241kMqklo3Jzc9HS0tLjTYXJZNLavq8XTbUN0tvDZrMhmUwiEAjAarUilUohHo/3KFftN0ajUfub2i/8fr9WvtqfgKOJiWAwiMzMTO2aCYfDPcrNzs5GW1ub9vhRo0aho6MDDQ0NsNvtMJlMWqJB7Qd2ux3hcBijRo1CdXV1j/Oz2WwQRREulwuKoqC1tVVLnql9Pjc3Fx0dHVo9qdRkwOHDh5GVlYVIJIJQKKSdkyAIMJlMWl9T+xlw9LpzuVxoaGjQ6gFAjy8VUK+/SZMmYdeuXT3avbu7G4IgwOFwIBAIaHGqySmV1WrFxRdfjIqKCjQ3N0OWZUSjUdjtdu16SW8Hq9WKSCSiJTTUMUklCAJKSkq0azkUCmnJL6vVClEUkUqltCTvnj17esRjMpm0x6mJdDX509raqsVhNptht9thNBoRDoe1GNLjdLvdiMVi2jWiJmBdLhfOO+88VFZWwmKxoLq6GqFQCMlkEqIowu1293iO0+lENBpFZmYmBEFAR0cHZFlGMpnUrgmbzYZoNAqLxYJEIoGSkhI0NTUhFovB5XJpEwa5ubnw+XyQZRmJRAIOh0Pry2azWUvIq5MB6rWjUsdt9W9utxuyLGvnbzAYYDAYesSn9iu17QwGA5xO5zEJFTVRbTKZUFBQgJqaGgDQjqX+X2UwGKAoCvLz8yHLMhobGwEAOTk5aG1t1eoilUr1uI7T+4r6mphKpRCLxVBQUIDGxkbMnTsXH330kXY8t9uNVCqF0tJS1NTUaHVWUFCAjo4O7Rqy2WyIxWJwu91acliWZXg8Hi0JPH36dCiKgmnTpuGTTz5BR0cHQqEQLr30UmRlZeHTTz/Fhg0btDe3DQ0NqKmpwZIlS7B48WK8//77WLNmDQDgxhtvhCzL+MY3voGPPvoIe/bswfr165GVlYWFCxeipqYGzc3N6OzsxA9/+EM4HA7853/+J+bOnYv169djzpw5mD17NgRBwFNPPYVDhw5h7ty5qK2tRXl5OebPn4+Wlha0trYilUqhs7MTe/bswcKFC2E2m/HGG28gkUjg17/+NebMmYODBw/i888/R2trK0pKSlBbWwuLxYIjR45g+/bt8Hq9uPTSS/Hhhx9i3759WLZsGXJychCNRtHR0YHXXnsNc+fO1ZK85eXlWLduHZYvX65NLtXX1+Mvf/kLxo0bh8OHD2PJkiUoKyvDCy+8gJycHDQ3N6Ourg5jxozB+eefD5PJhC+//BIHDx5EeXm5Ng6tW7cOd9xxB+rq6tDV1YXPP/8cd999t5aErKurw3vvvYebb74Z1dXVWpJ8yZIlqK2txSuvvIIf/ehHKC0tBQBUVVXh008/xe7du+H3+7XJq/vuuw9+vx8HDhyA1+vF9u3b0dLSgmuuuQaiKKKwsBBNTU14//33UVBQAODoe7lly5Zh165diMfjkGVZG/fmzJmDF154AbNmzUJ5eTleeuklmM1m3HbbbZAkCa+88goCgQBSqRRuuukmBINBbN++HZdccgl27tyJrVu3IiMjA36/H+eeey4yMjKQlZWFrVu3AgDGjx+Pffv2aceSJAlNTU2or69HdXU1fvazn6GjowObNm2CyWTC0qVL4ff7YTKZsGvXLpSXl+P555+H1WpFVlYWPvjgAxQUFMDpdMJisaC+vh6JRAL5+flIJBK4+eab0dXVhaysLOzZswdr167FlVdeiYqKCgDATTfdpLX5xIkTMX36dPh8Prz66quYNWsWxowZg507d2LBggWYNm0a3nzzTezdu1e7nrKyspBKpfDCCy+gsbERDocDo0aNwqRJk1BSUgKTyYR/+7d/w6xZs3DBBRegu7sb//u//4vp06ejoaFBm6CaPXs2nnvuOZx77rmora2F2+3GZZddBoPBgC+//BLl5eV4+eWXYbVa8fWvf12bLEulUvjb3/6GgoIChMNhNDY2YsqUKWhoaMDEiRPR0NCAtrY2+P1+zJs3D2VlZTCZTPjrX/+KefPmae/l1fd+NTU18Hq9WLZsGTo7O5FMJvHXv/4VkyZNwrhx42C329HZ2Ym9e/di586dmD9/PnJycpCVlaVNAOzevRvr16/H4sWLsXPnTlx66aXa61o0GsXWrVsRCoUwadIkbNq0CQsWLEBXVxcKCgpQX1+PRYsWobCwEAcPHsRnn32G2tpaTJkyBXv27IGiKCgtLUVRURHy8vJw8OBBVFRUIJlMYuHChXj33XfR2NiI+fPno62tDYsWLcLatWths9ngcrlw6NAhZGdn4+KLL9ZiaW5uxtVXXw1ZljF69GjY7XbttWv9+vUoKSmBoig4ePAgmpubUVBQgGuuuQaffvopNm3ahAsvvBBFRUV47rnncO+99yIQCKC6uhotLS2YOXMmamtrUVVVhVGjRmHfvn2YOXMm6urq4PF40NnZie9///u46KKLoCgKnnrqKe36qKysxB133IHf/e53uP3225FIJODz+fCXv/wFEyZMQElJCQ4cOIBx48Zh6tSpkCQJCxYswKeffoqmpibs378fXq8XZrMZO3bswKxZs1BaWgqr1Yo9e/bAbDajsLAQb7/9NiZNmoRbbrkFoVAIH374IQ4dOoSZM2finHPOQUNDAz799FN8+OGH+M53vqNNsjz//PPo7u5GXl4e5s+fjzFjxmDv3r1obW1FZWUlvva1r2H9+vUQBAG33XYbamtrsXbtWlx11VVIJBIoKyuD3W7HnDlzUFFRgbfeegvhcBhbt25FKpXSJpTvuOMOGAwGbZLotddeg81mQ1lZGTZs2IBp06ahpaVF21x77NixyM3NRU1NDVpbW2EwGLBz507MnDkTALB161ZkZ2cjEAjglltuQXV1NXbs2IG77roLBoMBW7duRUNDA8aPH4+ZM2fC6/Vix44dyMrKQjgcxscff4yDBw9i1KhRWLBgAdauXYsrrrgCoihi3bp1uPTSS+HxeDBt2jT4/X4sWrQIZrNZe1+gnpuiKNp7IeD/Fmyo7814+9zwxWTTKXrjjTfw93//99qbYCIiIiIiIjp16iQajSxGoxFf//rX8cQTT2gLH8xmszY5bzQaYTKZtMls9W4LGt6YbDoF77//PhYuXHjMygYiIiIiIiIiOpbRaMQ3vvEN7N69GyUlJaiurkZ+fj5EUURVVRXGjh2LCRMm4K677sKECRP0DpdOE5NNp+Cee+7B2rVr0d7ejmg0ynubiYiIiIiIiE5Tfn4+1q1bp93uR8MXk02naMeOHfjBD36AgwcP9tjDhIiIiIiIiIhOTnFxMV588UXMmzdP71BoADDZdJLUTYPVb745cOAAvv3tb2ub2/KbCIiIiIiIiIj6r7CwEGvWrGGiaQQx6B3AcHPw4EFcd911qK6uRjKZ7HH7HBNNRERERERERCcmCALMZjPGjRuHJ554gommEYYrm05CRUUFFi9ejJqaGiaWiIiIiIiIiE6CxWLBY489htLSUni9XjidTuTm5iI7O1vv0GiAcWXTCahJpVQqhbVr12LUqFEAgJaWFoRCIT1DIyIiIiIiIhryLBYLrrjiCvz4xz/GrFmzIEkSjEYjRFHUOzQaJFzZdBzt7e0QRREdHR3YvHkzbDYbtm3bhkmTJqGzsxMAUF9fj6eeekrnSOl4LBYLotGo3mEMqrNxnzB+++PJu/jii7Fly5YBK89kMiEejw9YeXqz2WwIh8N6h0FEI5QkSUilUnqHQUPUSHtNPRW8RkYW9b365Zdfjq997WvYvXs3Zs2ahe985ztwuVyQJAmCIOgdJp0BTDYdx5133ok1a9YgEokgkUj0+Rh+6CUiIiIiIiLqSRRF2Gw2uFwu3HDDDVi1ahUcDofeYdEZxGTTVzhRxtVutyORSJz1sxFEREREREREfTn//POxZMkS/PznP4ckSXqHQ2cIb5DsQzgcRjwex9ixY0/4uGQyeYaiIiIiIiIiIhpedu/ejdGjRzPRdJbhyqY06t43FRUVMJvNOHz4MKxWKy666CKdIyMiIiIiIiIaXsxmMx555BHcc8893KvpLMNkUy/33Xcffvvb3551my4TERERERERnS71S4xMJhMee+wx3H333Uw0nYWYbEqzfv16fP3rX+e3EhERERERERGdBLvdjry8PLS2tsJut+O+++7Dj3/8Y73DIp0Y9A5gqHjxxRdxyy23cEUTERERERER0QkYjUbccccd2LVrF6xWK6ZNm4YPP/wQ48aNQzKZRHFxMWRZhihyq+izEVc2/X+VlZWYNGkSEomE3qEQERERERERDRtZWVlob2/XbqErKSnBa6+9htmzZ+sdGunkrE02qSuYdu/ejYqKCjQ3N2P//v148skndY6MiIiIiIiIaHjwer3w+XyQJAmpVApFRUV48cUXMW/ePL1DIx2d1cmmf/mXf8EjjzzC1UxEREREREREJ0ldyWQwGJBKpVBYWIiXXnqJiSY6e/ds+t3vfodHHnkEyWRS71CIiIiIiIiIhhWTyQSHwwGLxYJIJIKxY8di9erVTDQRgLM42VRZWYnp06fjwIEDCIVCeodDRERERERENGQJgoC8vDzcfPPN+Na3voUxY8YgEAjAYrEgGAwiIyMDFotF7zBpiDhrk00NDQ345JNP9A6DiIiIiIiIaMhTFAXt7e1oaWlBXl4eTCYTvF4vRFGE0+nUOzwaYs6KZJO6Gfj27duxb98+NDQ0wG636xwVERERERER0fAwfvx4LFq0CHfeeScyMzP1DoeGuLNmg/AVK1bg4YcfxllyukREREREREQDYtmyZVizZo3eYdAwIuodwJlQUVGB559/nvePEhEREREREZ0EURQRDAbR2tqqdyg0jIzY2+jUW+fWrFmDl156CW1tbUilUgAAo9GIRCKhZ3hEREREREREQ9Jll12GSZMmITMzE6Io4rrrrkNOTo7eYdEwMqJvo3vooYfwi1/8Qu8wiIiIiIiIiIYNQRDg9Xpx99134xe/+AUMhhG7ToUGyYi9je7111/H008/DY/HA0mS9A6HiIiIiIiIaFhQFAXJZBJz5sxhoolOyYhb2ZRMJlFTU4Nx48bpHQoRERERERHRsON2u/H8889jyZIleodCw9SIW9lUW1sLl8uFn/3sZxAEQe9wiIiIiIiIiIY8URRRVlaGb3/729i8eTOuvPJKfps7nbIRsR5O3Qz8+eefx6233qpvMERERERERETDiNfrxc9+9jP89Kc/1TsUGiFGxMomURTxq1/9Cv/8z/+sdyhEREREREREw4rf78c777yDpqYmvUOhEWJE7Nn06quv4oYbbtA7DCIiIiIiIqJhw263Y/HixZgzZw6uu+46jB07Vu+QaIQYEbfR1dTUwOFwIJlMIhqN6h0OERERERER0ZAmSRKuvvpqPPnkk3A6nXqHQyPMsL6NTpZlKIqCCRMmIBgMMtFERERERERE1A+KoqCmpgZHjhzROxQagYbdbXTqZuBPPPEEXnzxRXz55ZcIBAJIpVI6R0ZEREREREQ09AmCgLKyMnzwwQfIzc3VOxwagYbdbXSiKGLVqlVYuXKllngiIiIiIiIiov6RJAlGoxEOhwOKokAQBL1DohFm2K1s2r59Oy699FLE43Emm4iIiIiIiIhOkiRJ+NOf/oTrr79e71BohBp2ezZlZWVh3LhxcLlceodCRERERERENCxIkgQAsFqtePnll5lookE15G+jU1cvvffee4hEIvjss8+wb98+naMiIiIiIiIiGj4yMjKwfPly3HTTTSgsLNQ7HBrhhnSySU00rVy5Eg899BCG2R1/RERERERERENCIBDAkSNHUFxcrHcodBYY0rfRiaKIxx57DA8//DATTURERERERESnwGA4us6kvb0dkUiEn69p0A3pZJMsy3jnnXfgdrthNBr1DoeIiIiIiIho2Ekmk8jMzMSKFStgtVr57XM06IZ0skkUReTk5KCzsxOJRELvcIiIiIiIiIiGvIyMDAiCAIvFAlEUMX78eLz99tuYOnWq3qHRWWLI7tmkKAoURcGjjz6KzMxMfPLJJ9i5c6feYRERERERERENaXl5eXjnnXcwadIkdHd3w+v1wmq16h0WnUUEZQjerKkoClKpFNatW4fbbrsNnZ2deodERERERERENOR5PB4888wzuOaaawCAt8yRLnS/ja6rqwvhcBh1dXX48ssv8ctf/hKRSAT//u//jptuuomJJiIiIiIiIqJ+KCgowB//+EdcffXVAJhoIv3ourJp8+bN+M53voNAIIC2tjbt9waDAclkEgBgMpkQj8f1CpGIiIiIiIhoSPJ4PLjhhhuwcOFCjBo1CmVlZfB4PDAYDEw0ka50Sza9+eabWLJkiR6HJiIiIiIiIhoRcnNz8cEHH6CkpITf4k5Dhi7Jprq6OpSWlgIArFYrwuFwj9VMAFc0EREREREREZ2IKIowGo3Iy8vDzp07kZOTo3dIRPrs2VRSUoKLL74YWVlZmDt3LgD0SDQBYKKJiIiIiIiI6ARkWQYA/PjHP2aiiYYMw5k8WHNzMzIyMvDZZ5/hsssuQ05ODv785z9rf5ckCYqiaBcLERERERERER2f2WzGo48+invuuUfvUIg0Z+w2ug0bNmDx4sUwmUyIRCJn4pBEREREREREI4ooihAEAalUCiaTCY899hjuvvtubghOQ8oZSTZVVFTgwgsv7PGNc0RERERERETUP4IgYPr06Zg5cyaampoQi8WwdOlS3HXXXXqHRnSMQb+NTlEUPP7442hvbx/sQxERERERERGNSKIoIh6P47nnnoPNZkM8HofFYsG3vvUtOBwOvcMj6mHQNwgXBAGFhYXweDwwmUyDfTgiIiIiIiKiESH91jiPx4MvvvgCABAMBpGdnY2f/vSnTDTRkDRoyaZQKIRgMIiWlhZccsklmD9/Psxm82AdjoiIiIiIiGhEUXe9ycrKQkdHBwwGA2RZRmFhIV566SVccskl+gZIdByDsmfTW2+9hdtuuw1tbW38ZjkiIiIiIiKiU2S1WhGJRGAwGJBMJlFYWIg1a9Zg3rx5eodGdFwDnmzatm0bOz0RERERERHRacrNzcX8+fORSqWQSqXg8Xhw55134vzzz9c7NKKvNOAbhK9btw4ZGRkIh8NIJBJQFAVn4AvviIiIiIiIiEaMG2+8ES+99BIURYEoihDFQd9ymWjADFiy6fXXX8d///d/4+DBg/D5fANVLBEREREREdGIJkkScnJy0N3dDUVRsGzZMvz+97/X/pa+UTjRcDAgt9Ft3LgRl112GfdnIiIiIiIiIjpJZrMZoiji97//Pf7hH/4BwP99Ex0TTTQcnfY6vLfffhtXXXUVE01EREREREREp8BoNCIej6OzsxMAIIoiBEFgoomGrdNKNr355pu4/vrrEYvFBioeIiIiIiIiorNKMBiE1+vFnDlzuDcTjQinfBvdoUOHMHv2bITDYSiKAkmSkEqlBjo+IiIiIiIiohEtMzMTzz33HK644goAvHWOhr9TTjY1Nzfjr3/9Kw4ePIgNGzYgHo/jyy+/HOj4iIiIiIiIiEYUq9WKuXPnYurUqaiqqsKtt96Ka6+9lrfO0YhxWhuEHz58GPPmzUNzc/NAxkREREREREQ0YomiiP/8z//Ed77zHUiSBFEUoSgKE000YpzyzaCHDh3ClVdeidbW1oGMh4iIiIiIiGhE83g8sFqtMBqN2h5NTDTRSHJKyaYDBw7g2muvRXV1Nb+FjoiIiIiIiOgkxONxFBcX6x0G0aA56WRTe3s7br75ZlRXV3NDcCIiIiIiIqKTkJeXh5dffhmXXnqp3qEQDZqT3rMpGAxix44dqKyshM/nwyeffIKNGzeiq6trkEIkIiIiIiIiGr5cLhceeOABXHnllcjNzYXD4YAoirx1jkYsw8k+weFwYOHChVi4cCFSqRRSqRRuueUW/O1vf0M0GkU4HB6MOImIiIiIiEYcQRBwGt/ZREOUwWCAIAgQRRGyLMNsNsNkMqG0tBQGg0Hbp4lopDqtHi5JEkwmE2RZhizLvK2O+sVgOOkcJxERnaasrKx+P9ZoNAIATCZTj99/1ezrmZyZtVqtAE7/9UTv16P+Hl9tj/7q3W5nWn/6gs1mO+Xy+/MBbebMmcf9W2Fh4UmXp1LPTX1OX/utHK+83r8fM2YMXC5Xv489VKX3z1O9ptLLMBqNEARBu871IEnSoJXdux8IggCz2az9GwC+/vWvn9SY3V9FRUUAoB3vq9jtdtx9992nNLafztjan+uxv2OcWtZXne9AvXapx0rvO6IoIpFIIBaLIZFIIJVKYebMmTCZTEw00VnhpG+jS6coChRFwerVq/Hwww8jEAgMZGxEREQ0AAwGA5LJZL8eazQakUgktJnYocZqtSISiZx2fMNlJYEkSSc1mXcyba0Xk8mEeDw+aOXn5uaipaWlz79ZLBZEo1Ht55PpR2qfUZ9js9lOeUW/y+VCIpFAJBI5pecPFQM9TkiSpK0ASW+nM+lMj33qmKteu7NmzcKhQ4cQCoUG9Dh2ux2hUKhfY4rFYsHFF1+M9evXn/RxBrv++jvGqeep15jYux7cbjdefPFFXHXVVWc8FiK9nFZKVV0WWFpaykSTzjwej94hnFB+fr7eIdBZbsKECUO6PDozvF6v3iFoBqsPmUwmbbbW7Xaf8I22KIowmUzIzMxEKpWC0+ns8fevWllzurOz/ZkBlyQJZrMZeXl5EAQBHo+nXx9m0mes0+O02WzHJJrU9zTHm+UeyFno/qwqAICMjIx+JZrU9vN6vX229WCsOuurzPR+kr4CyGg0wmQywWw2Izs7u0fbnahe0//ucDhO+LixY8ciHA73eJ7676ysrB4JDLvd3u8PxRaLBYqiwGazQZZl5OTkaIkmtQ9bLJYez1FXOKirMNTHZWZmIj8/f8gnmgRB0M6hr/ZOvw4tFssprWYxGAxav7Hb7bBYLMjJyQFwtD991Qqj/vRrQRBgNBq125m+iiiKcLlckGUZgiCc9G1OJzr/3uciSRIyMzORTCa1MXfBggVIpVJ9Jpr6ex2nt5tK7fsul0v7myiKkCTpmHIzMjLw/e9/Hx9++OExf+v9c+8+brPZ+lXXfTnRaiVBELQx7kTl2+12mM3m446JAI5ZTXaq1LjTX3fVsUUURYiiiMLCQjz//PNMNNFZ57RWNqlaW1uxefNmVFVVoaWlBfv374fb7ca4ceO0jcTNZjNsNht8Ph/y8vIwd+5cbNq0CV1dXdob3EgkgnA4jMzMTK3sSCQCWZYxc+ZMtLS0oLGxEYWFhWhoaEBhYSEqKyu1mSX1/5mZmcjOzkZOTg7WrVsHg8Gg7fQvCAKCwSAaGhp6lD9u3DgtlsrKSq2MsWPH4q233oLP50N5eTkSiQQaGxtx7bXXYuPGjbBYLJg7dy62b98Ou92OwsJCLc5Zs2ahubkZBw4c0M6nd70ARwe74uJieDweLYaGhgZkZGSgqqoK5eXlqKysxMSJEzFmzBhs2rQJkUgEVqsV4XAY55xzDqZOnYo//OEPsFqtyMjIgM1mg8fjQSKRwDnnnIPKykqIoghFUdDS0oIvvvhCi8fj8WDfvn3Izs5GcXExioqKEAwG0djYqLWJeuzKykqMHz8eH3zwgXa+wWDwmPNJbwsAGD16NObPn48//elPmDJlCsLhMLZs2YKSkhIYDAb4fD5cdNFF2L17N8xmM+rr67X27d03fD4f6uvrkZGR0aNdgaMb2Pt8PmRkZODzzz9HMpnENddcg+3btx8zi51eps1mw6RJk2AymbS2jMfjqK6uxvnnn6+V2dDQAJvNBqPRiMbGRowfPx6HDx9GOBxGcXExjEYjDhw4oLVzY2Njj2tFPaZazy0tLaiqqtJ+BoBQKITDhw9r/TK9DJvNpj3O5XKhvb0d27Ztw8KFC9HU1ISqqqrjXkvHi7v3Y9T2r6ys7DMGn8+HZDKJSy65BFu2bMGkSZNQVlaGHTt2aHUciUS0616tX4/Ho5U5c+bMHscoKCjQ6sFoNGrncby41D6ZnZ2NDRs2wGKxoKioCB6PB42Njdq5ppczevRoXH/99fj3f/931NTU4LzzzkNDQ4MWq9vtxsUXXwyj0Yi9e/fCbDZj165dMBgMOO+8845pS7W8//3f/0U4HEZnZycyMjK0vpLeL9S2PnDgAPLy8lBeXo6PP/4YEyZMQH19/THtU1hYiC+++AJut1urG/WaEkVRO4bP50NZWVmfY5n69+LiYjQ3N6OqqgqiKKK+vh5GoxHFxcU92jY7OxuzZ8/G3r17kUwmMXbsWGzcuFEba8xmM0aPHo13330XOTk5KCoq0tqkq6sLxcXFCAQCWv2njyN9tX/6eNy7L6rPV68Pm80Gs9mMCy+8ENu3b0c0GkVnZ6fWv9KvLfWDoHoMl8uF7OxsVFVVobW1FeFwGDfddBOefvppiKIIi8VyTF/pPTakX5vprx3qY9L7UHrfbmlpgSzLKC8v18b39D5iMpmwdOlS/Nu//Ru+/PJL5OXlwWw246abbsLevXvxySefoLCwEB0dHbjqqqu0cTwQCMDn88FkMuGLL77o8RpSWVkJj8eDhx56CDU1NQiFQrjooovw5ptvIiMjA4lEAoIgaLfuCIKA7u5uFBcXQ1EUeL1e1NbWorS0FJ2dnWhoaICiKJgyZQpqa2sRCoVQWFiovc53dXXhwgsvRE1NDcLhMAoLC1FXVwePxwOn04nu7m4IggC/3w+XywW/34+SkhLtMbIso7S0FB9++CHcbjdsNhsCgQAEQdA+fAmCALfbDeDohyC1HmtqahAIBCDLMpxOJxoaGlBUVIQjR46guLgYTqcToijiwIEDmDx5MlKpFILBIACgpKQEtbW12sxzeh2IoogvvvgCkydPRmdnJ5qbm6EoCubMmYN9+/Zh9OjRqKmp0drU7XbD7/fD7XbD5XKhu7sbgUAATqcTiqLA4/HgyJEjKCkpgc/nQzAYRHl5OXw+Hw4dOgSHwwG73Q5BELSJu+7ubkyePBlutxv19fUQBEH7UN/d3Q3g6Opy9ThFRUXaB7Ha2lp4PB74fD7t72pcHo8H+/fvR1FRERwOBxoaGuB2u+F0OnscR+0fgUAAxcXFPdr0wIED2vMDgYBWD4IgoKSkBB9++CGKi4tht9u1vyuKor1Oq4+vr69HUVERZFnWztvv92vn5nK54Ha7IQgC6uvrUVxcDJfLhf3790MQBNjtdi1Gl8sFl8uF+vp6zJ8/H5WVldp7C3UcOHLkCObPn4/NmzfDYDDAZrNh1KhRqKur067LQCAARVG0vqe2nSAI2jVQVlaGPXv24JJLLsGmTZswevRoJJNJBAIBjBo1CjU1NWhqasLEiRMhyzIaGxsxdepU7NmzBzNmzMDbb7+Nm266Ca2trWhqaoKiKOjq6oLL5dL6i9/vRyAQQFFRkdbf6+rqjmkf9dpQH9/d3Q2Hw4GioiLU19dr11j6NXTgwAEUFhZq7fdVK/zU53R3d8PtdkNRFHR3d6OhoQGTJk3S6jwQCGDKlCnw+XxobGxEUVERfD4fRFHU2lS9NtNXewQCAcydOxc+nw9NTU0oLy9HZ2en9l4vPbYjR44AAGRZRnFxMfx+vzYeeDwerX7UhGT6dad+6Ff7WHd3t3Z3hlqWmmjyeDz4/PPPUVJSglQq1eMc1PMHAKfTCbfb3WOMmzp1Kvbu3av1p/SxrqurC9OmTcPevXshSRLsdjvcbrfWtqWlpaiursasWbPQ0dGBQCCA/fv39xgf1L6hXlPq+4fCwsIedave2imKIo4cOYJAIIArrrgCu3btwtixY7Xy1T4nCAKOHDkCl8ulxZlep7W1tXC5XHA6ndr12Pvn9D7e0dEBSZJQV1enJe8CgQACgQAmTZqErq4uhEIhrT4nT56Muro6zJgxA9XV1ZAkSWtvdaI6GAyiuLgYbrcbR44c0ca49PFHfY0JBALaGJuZmamN159//jlcLhcKCgpQX1+P6dOno7q6Gl6vVyurrq5OO4baZ91uNxwOh9YG6pig1vv06dO1c6+qqoIkSSguLkZtba3WF0pLS+HxeLgZOJ11BiTZlE4dvAFoLyZqkkP9ffqLh7pcNv1vajm9L0b1TaBatjqoqv9Xy03/v3r8VCoFRVGOyfSnn75avvpctUy1DHVvKnWgUJdmqvGr55J+HukvcL1nz3rXi/q89PjV56dSKa389I3mep+vJElaBl+NIX3Zd+/m7j27mEqltBjS2yK9TXrXe+92630+vdtSXdaqHiP937Is9zjP3u3bu2+ox+9r5iu9bmRZ1tqqL+llpsei/qzWf3qZ6t/UGNVz7/38vuo9/Zjp55L+c3p99lVG+uMEQUAymdTq4Xj1lf74vuLuq/yvikGtV7UN+1o63fvaVusv/XpO/zm9HtLP43hxqcdVZ//Tr6H0c+3dB9V95tR2TY9VvcbT+6F6jffVlunXfu9rsne/UOtNfZ76Zrb3ddP7GutrnOs9DqbXefpY1vua6d2/ex8/vV/0Ndao40xfY0XvcaOvn3u3f3rcvfti77h7j7W9j9O7DdKPkd4v0vtu73rvq6y+jtHXY9L7UPo5qbH09TqVfk7p/UG9ntXfqeNjX8dOb8/0OtZ7TyIiIiIiOjsNeLKJiIiIiIiIiIjOXtwGn4iIiIiIiIiIBgyTTURERERERERENGCYbCIiIiIiIiIiogHDZBMREREREREREQ0YJpuIiIiIiIiIiGjAMNlEREREREREREQDhskmIiIiGjba2trwj//4jygpKYHZbEZeXh4uv/xyfPDBB3qHNiBKS0vxu9/9Tu8wiIiIiE6LQe8AiIiIiPpr6dKliMfjePbZZ1FWVoaWlhZs3LgRHR0deodGRERERP8fVzYRERHRsNDV1YWtW7di9erV+NrXvoZRo0bhvPPOwz/90z/hmmuu0R5z++23Izs7Gy6XC5deein27NnTo5xVq1YhJycHTqcTt99+O37+859jxowZ2t9vvfVWXHfddfjVr36F3NxceDwePPjgg0gmk7jvvvvg9XpRVFSEp59+uke5R44cwY033giPxwOv14trr70WNTU1x5T72GOPIT8/H5mZmbjrrruQSCQAAJdccglqa2vxox/9CIIgQBAEAEBtbS2WLFmCjIwM2O12TJkyBW+99dYg1DARERHRwGCyiYiIiIYFh8MBh8OBtWvXIhaL9fmYG264Aa2trXj77bfx6aefYtasWViwYAE6OzsBAC+++CIeeughrF69Gp9++ilKSkrw+9///phy3nvvPTQ2NmLLli347W9/i5UrV+Lqq69GRkYGPvroI9x555343ve+h/r6egBAIpHA5ZdfDqfTia1bt+KDDz6Aw+HA4sWLEY/HtXI3bdqEyspKbNq0Cc8++yyeeeYZPPPMMwCA1157DUVFRXjwwQfR1NSEpqYmAMBdd92FWCyGLVu2YN++fVi9ejUcDsdAVi0RERHRgBIURVH0DoKIiIioP/7yl7/gjjvuQCQSwaxZszB//nwsW7YM06ZNw7Zt23DVVVehtbUVZrNZe87YsWPx05/+FN/97ncxZ84cnHPOOXjiiSe0v1900UUIBoPYvXs3gKMrkDZv3oyqqiqI4tF5uYkTJyInJwdbtmwBAKRSKbjdbvzP//wPli1bhhdeeAGrVq3CgQMHtBVJ8XgcHo8Ha9euxWWXXaaVW1lZCUmSAAA33ngjRFHEyy+/DODonk333nsv7r33Xi2+adOmYenSpVi5cuWg1SsRERHRQOLKJiIiIho2li5disbGRrzxxhtYvHgxNm/ejFmzZuGZZ57Bnj17EAwGkZmZqa2CcjgcqK6uRmVlJQDg0KFDOO+883qU2ftnAJgyZYqWaAKA3NxcTJ06VftZkiRkZmaitbUVALBnzx4cPnwYTqdTO67X60U0GtWOrZarJpoAID8/XyvjeH7wgx9g1apVuPDCC7Fy5Urs3bv3JGqMiIiI6MzjBuFEREQ0rFgsFixatAiLFi3C/fffj9tvvx0rV67E97//feTn52Pz5s3HPMfj8ZzUMYxGY4+fBUHo83eyLAMAgsEgZs+ejRdffPGYsrKzs7+yXLWM47n99ttx+eWXY926dVi/fj0efvhh/OY3v8E999xzUudEREREdKZwZRMRERENa5MnT0YoFMKsWbPQ3NwMg8GAsWPH9vgvKysLADBhwgR8/PHHPZ7f++dTMWvWLFRUVCAnJ+eYY7vd7n6XYzKZkEqljvl9cXEx7rzzTrz22mv4yU9+gieffPK0YyYiIiIaLEw2ERER0bDQ0dGBSy+9FC+88AL27t2L6upq/PnPf8YjjzyCa6+9FgsXLsQFF1yA6667DuvXr0dNTQ0+/PBDrFixAp988gkA4J577sFTTz2FZ599FhUVFVi1ahX27t2r7bN0qv7+7/8eWVlZuPbaa7F161ZUV1dj8+bN+MEPfqBtIt4fpaWl2LJlCxoaGtDe3g4AuPfee/Huu++iuroan332GTZt2oRJkyadVrxEREREg4m30REREdGw4HA4cP755+Pxxx9HZWUlEokEiouLcccdd+Cf//mfIQgC3nrrLaxYsQLf/va30dbWhry8PFx88cXIzc0FcDQpVFVVheXLlyMajeLGG2/Erbfeip07d55WbDabDVu2bMHPfvYzXH/99QgEAigsLMSCBQvgcrn6Xc6DDz6I733vexgzZgxisRgURUEqlcJdd92F+vp6uFwuLF68GI8//vhpxUtEREQ0mPhtdERERHRWW7RoEfLy8vD888/rHQoRERHRiMCVTURERHTWCIfD+MMf/oDLL78ckiRhzZo12LBhA/72t7/pHRoRERHRiMGVTURERHTWiEQiWLJkCXbt2oVoNIoJEybgF7/4Ba6//nq9QyMiIiIaMZhsIiIiIiIiIiKiAcNvoyMiIiIiIiIiogHDZBMREREREREREQ0YJpuIiIiIiIiIiGjAMNlEREREREREREQDhskmIiIiIiIiIiIaMEw2ERERERERERHRgGGyiYiIiIiIiIiIBgyTTURERERERERENGCYbCIiIiIiIiIiogHz/wBPlck3VzODrQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#step e visualization\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#file containing analysis results\n",
        "analysis_file = \"segment_analysis.txt\"\n",
        "if not os.path.exists(analysis_file):\n",
        "    print(f\"Analysis file '{analysis_file}' not found!\")\n",
        "else:\n",
        "    segment_names = []\n",
        "    max_amplitudes = []\n",
        "    num_spikes = []\n",
        "    with open(analysis_file, \"r\") as f:\n",
        "        next(f)\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\"\\t\")\n",
        "            segment_name = parts[0]\n",
        "            max_amplitude = float(parts[1])\n",
        "            spikes = int(parts[2])\n",
        "            segment_names.append(segment_name)\n",
        "            max_amplitudes.append(max_amplitude)\n",
        "            num_spikes.append(spikes)\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    #bar chart for number of spikes\n",
        "    ax1.bar(segment_names, num_spikes, color='skyblue', alpha=0.7, label='Number of Spikes')\n",
        "    ax1.set_xlabel(\"Segments\")\n",
        "    ax1.set_ylabel(\"Number of Spikes\", color='blue')\n",
        "    ax1.tick_params(axis='x', rotation=45, labelsize=8)\n",
        "    ax1.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "    #line plot for maximum spike amplitudes\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(segment_names, max_amplitudes, color='red', marker='o', label='Max Amplitude')\n",
        "    ax2.set_ylabel(\"Max Amplitude\", color='red')\n",
        "    ax2.tick_params(axis='y', labelcolor='red')\n",
        "    plt.title(\"Analysis of Segments: Spikes and Amplitudes\")\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZz2IHsxK5-a",
        "outputId": "60d44ff6-7fa7-4d8d-b918-1859ca97416a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized results saved to 'quantized_analysis.txt'.\n"
          ]
        }
      ],
      "source": [
        "#step f\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#function to quantize values into 5 bits (32 levels)\n",
        "def quantize(values, num_bits=5):\n",
        "    \"\"\"\n",
        "    Quantize a list of values into the specified number of bits.\n",
        "\n",
        "    Parameters:\n",
        "        values (list or numpy.ndarray): The values to quantize.\n",
        "        num_bits (int): The number of bits for quantization (default is 5).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The quantized values.\n",
        "    \"\"\"\n",
        "    num_levels = 2 ** num_bits\n",
        "    min_val = np.min(values)\n",
        "    max_val = np.max(values)\n",
        "    if max_val == min_val:\n",
        "        return np.zeros_like(values)\n",
        "    #map values to [0, num_levels - 1]\n",
        "    quantized_values = np.floor((values - min_val) / (max_val - min_val) * (num_levels - 1)).astype(int)\n",
        "    return quantized_values\n",
        "\n",
        "analysis_file = \"segment_analysis.txt\"\n",
        "quantized_output_file = \"quantized_analysis.txt\"\n",
        "if not os.path.exists(analysis_file):\n",
        "    print(f\"Analysis file '{analysis_file}' not found!\")\n",
        "else:\n",
        "    segment_names = []\n",
        "    max_amplitudes = []\n",
        "    num_spikes = []\n",
        "    with open(analysis_file, \"r\") as f:\n",
        "        next(f)\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\"\\t\")\n",
        "            segment_name = parts[0]\n",
        "            max_amplitude = float(parts[1])\n",
        "            spikes = int(parts[2])\n",
        "            segment_names.append(segment_name)\n",
        "            max_amplitudes.append(max_amplitude)\n",
        "            num_spikes.append(spikes)\n",
        "    max_amplitudes = np.array(max_amplitudes)\n",
        "    num_spikes = np.array(num_spikes)\n",
        "    quantized_amplitudes = quantize(max_amplitudes, num_bits=5)\n",
        "    quantized_spikes = quantize(num_spikes, num_bits=5)\n",
        "    with open(quantized_output_file, \"w\") as f:\n",
        "        f.write(\"Segment\\tQuantized Amplitude\\tQuantized Spikes\\n\")\n",
        "        for i, segment in enumerate(segment_names):\n",
        "            f.write(f\"{segment}\\t{quantized_amplitudes[i]}\\t{quantized_spikes[i]}\\n\")\n",
        "\n",
        "    print(f\"Quantized results saved to '{quantized_output_file}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "qaaT3726Ui1h",
        "outputId": "ea5f254c-e272-4eed-8683-a369c1320682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original and Quantized Data Example:\n",
            "Segment Name: segment_1\n",
            "Original Max Amplitude: 45.7 -> Quantized: 11\n",
            "Original Spike Count: 15 -> Quantized: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#step f visualization\n",
        "import numpy as np\n",
        "\n",
        "segment_names = [\"segment_1\", \"segment_2\", \"segment_3\"]\n",
        "max_amplitudes = [45.7, 32.8, 68.3]\n",
        "num_spikes = [15, 25, 30]\n",
        "\n",
        "def quantize(values, num_bits=5):\n",
        "    num_levels = 2 ** num_bits\n",
        "    min_val = np.min(values)\n",
        "    max_val = np.max(values)\n",
        "    if max_val == min_val:\n",
        "        return np.zeros_like(values)\n",
        "    quantized_values = np.floor((values - min_val) / (max_val - min_val) * (num_levels - 1)).astype(int)\n",
        "    return quantized_values\n",
        "\n",
        "quantized_amplitudes = quantize(max_amplitudes, num_bits=5)\n",
        "quantized_spikes = quantize(num_spikes, num_bits=5)\n",
        "\n",
        "print(\"Original and Quantized Data Example:\")\n",
        "print(f\"Segment Name: {segment_names[0]}\")\n",
        "print(f\"Original Max Amplitude: {max_amplitudes[0]} -> Quantized: {quantized_amplitudes[0]}\")\n",
        "print(f\"Original Spike Count: {num_spikes[0]} -> Quantized: {quantized_spikes[0]}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "x = np.arange(len(segment_names))\n",
        "width = 0.35\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "#max amplitudes\n",
        "ax.bar(x - width/2, max_amplitudes, width, label=\"Original Amplitude\", color=\"blue\", alpha=0.7)\n",
        "ax.bar(x + width/2, quantized_amplitudes, width, label=\"Quantized Amplitude\", color=\"cyan\", alpha=0.7)\n",
        "#spike counts\n",
        "ax.plot(x, num_spikes, \"ro-\", label=\"Original Spikes\")\n",
        "ax.plot(x, quantized_spikes, \"go-\", label=\"Quantized Spikes\")\n",
        "\n",
        "ax.set_xlabel(\"Segments\")\n",
        "ax.set_ylabel(\"Values\")\n",
        "ax.set_title(\"Original vs Quantized Amplitudes and Spikes\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(segment_names)\n",
        "ax.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-KkRG3cUpaV",
        "outputId": "08aa7853-a139-4aef-bf0b-9420c8a3e8d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LAMSTAR input words saved to 'lamstar_input.txt'.\n"
          ]
        }
      ],
      "source": [
        "#step g\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def quantize_to_binary(value, bits=5):\n",
        "    \"\"\"\n",
        "    Convert an integer value to its binary representation with fixed bit length.\n",
        "\n",
        "    Parameters:\n",
        "        value (int): The integer value to convert.\n",
        "        bits (int): The number of bits for the binary representation.\n",
        "\n",
        "    Returns:\n",
        "        str: Binary representation of the value as a string.\n",
        "    \"\"\"\n",
        "    return format(value, f\"0{bits}b\")\n",
        "\n",
        "input_word_file = \"quantized_analysis.txt\"\n",
        "lamstar_input_file = \"lamstar_input.txt\"\n",
        "\n",
        "if not os.path.exists(input_word_file):\n",
        "    print(f\"Input word file '{input_word_file}' not found!\")\n",
        "else:\n",
        "    with open(input_word_file, \"r\") as f:\n",
        "        lines = f.readlines()[1:]\n",
        "    lamstar_words = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split(\"\\t\")\n",
        "        segment = parts[0]\n",
        "        quantized_amplitude = int(parts[1])\n",
        "        quantized_spike = int(parts[2])\n",
        "        rounded_amplitude = round(quantized_amplitude / 100)  # Round to nearest multiple of 100, then divide\n",
        "        binary_amplitude = quantize_to_binary(rounded_amplitude, bits=5)\n",
        "        binary_spike = quantize_to_binary(quantized_spike, bits=5)\n",
        "        #LAMSTAR input word (2 subwords)\n",
        "        lamstar_word = f\"{binary_amplitude};{binary_spike}\"\n",
        "        lamstar_words.append((segment, lamstar_word))\n",
        "    with open(lamstar_input_file, \"w\") as f:\n",
        "        f.write(\"Segment\\tLAMSTAR_Input_Word\\n\")\n",
        "        for segment, word in lamstar_words:\n",
        "            f.write(f\"{segment}\\t{word}\\n\")\n",
        "\n",
        "    print(f\"LAMSTAR input words saved to '{lamstar_input_file}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKimqL-U3F1Q",
        "outputId": "70ee5268-96e7-4937-b1e2-dd146b9865c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeled data saved to lamstar_input_labeled.txt\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "input_file = \"lamstar_input.txt\"\n",
        "output_file = \"lamstar_input_labeled.txt\"\n",
        "data = pd.read_csv(input_file, sep=\"\\t\", header=0)\n",
        "if 'Segment' not in data.columns:\n",
        "    raise ValueError(\"The input file must contain a 'Segment' column.\")\n",
        "\n",
        "#if 'Segment' starts with 'S', label as 'epileptic'; if 'Z', label as 'healthy'\n",
        "data['Label'] = data['Segment'].apply(lambda x: 'epileptic' if x.startswith('S') else ('healthy' if x.startswith('Z') else 'unknown'))\n",
        "data.to_csv(output_file, sep=\"\\t\", index=False)\n",
        "print(f\"Labeled data saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSJ_fTkLymAN",
        "outputId": "0fa4f980-c6ae-4814-de8c-21abb9f555a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Segment 0: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 1: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 2: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 3: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 4: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 5: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 6: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 7: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 8: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 9: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 10: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 11: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 12: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 13: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 14: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 15: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 16: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 17: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 18: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 19: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 20: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 21: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 22: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 23: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 24: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 25: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 26: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 27: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 28: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 29: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 30: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 31: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 32: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 33: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 34: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 35: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 36: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 37: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 38: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 39: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 40: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 41: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 42: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 43: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 44: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 45: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 46: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 47: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 48: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 49: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 50: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 51: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 52: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 53: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 54: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 55: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 56: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 57: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 58: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 59: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 60: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 61: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 62: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 63: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 64: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 65: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 66: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 67: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 68: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 69: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 70: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 71: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 72: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 73: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 74: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 75: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 76: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 77: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 78: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 79: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 80: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 81: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 82: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 83: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 84: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 85: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 86: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 87: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 88: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 89: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 90: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 91: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 92: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 93: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 94: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 95: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 96: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 97: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 98: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 99: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 100: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 101: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 102: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 103: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 104: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 105: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 106: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 107: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 108: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 109: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 110: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 111: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 112: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 113: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 114: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 115: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 116: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 117: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 118: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 119: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 120: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 121: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 122: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 123: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 124: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 125: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 126: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 127: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 128: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 129: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 130: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 131: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 132: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 133: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 134: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 135: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 136: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 137: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 138: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 139: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 140: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 141: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 142: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 143: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 144: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 145: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 146: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 147: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 148: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 149: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 150: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 151: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 152: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 153: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 154: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 155: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 156: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 157: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 158: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 159: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 160: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 161: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 162: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 163: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 164: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 165: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 166: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 167: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 168: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 169: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 170: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 171: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 172: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 173: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 174: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 175: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 176: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 177: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 178: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 179: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 180: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 181: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 182: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 183: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 184: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 185: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 186: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 187: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 188: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 189: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 190: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 191: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 192: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 193: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 194: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 195: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 196: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 197: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 198: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 199: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 200: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 201: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 202: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 203: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 204: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 205: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 206: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 207: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 208: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 209: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 210: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 211: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 212: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 213: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 214: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 215: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 216: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 217: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 218: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 219: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 220: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 221: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 222: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 223: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 224: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 225: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 226: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 227: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 228: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 229: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 230: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 231: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 232: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 233: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 234: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 235: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 236: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 237: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 238: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 239: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 240: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 241: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 242: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 243: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 244: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 245: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 246: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 247: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 248: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 249: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 250: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 251: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 252: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 253: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 254: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 255: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 256: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 257: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 258: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 259: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 260: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 261: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 262: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 263: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 264: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 265: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 266: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 267: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 268: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 269: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 270: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 271: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 272: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 273: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 274: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 275: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 276: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 277: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 278: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 279: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 280: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 281: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 282: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 283: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 284: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 285: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 286: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 287: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 288: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 289: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 290: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 291: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 292: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 293: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 294: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 295: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 296: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 297: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 298: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 299: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 300: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 301: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 302: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 303: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 304: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 305: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 306: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 307: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 308: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 309: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 310: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 311: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 312: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 313: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 314: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 315: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 316: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 317: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 318: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 319: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 320: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 321: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 322: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 323: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 324: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 325: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 326: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 327: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 328: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 329: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 330: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 331: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 332: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 333: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 334: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 335: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 336: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 337: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 338: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 339: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 340: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 341: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 342: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 343: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 344: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 345: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 346: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 347: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 348: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 349: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 350: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 351: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 352: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 353: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 354: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 355: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 356: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 357: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 358: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 359: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 360: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 361: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 362: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 363: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 364: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 365: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 366: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 367: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 368: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 369: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 370: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 371: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 372: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 373: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 374: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 375: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 376: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 377: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 378: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 379: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 380: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 381: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 382: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 383: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 384: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 385: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 386: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 387: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 388: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 389: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 390: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 391: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 392: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 393: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 394: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 395: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 396: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 397: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 398: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 399: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 400: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 401: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 402: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 403: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 404: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 405: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 406: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 407: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 408: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 409: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 410: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 411: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 412: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 413: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 414: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 415: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 416: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 417: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 418: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 419: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 420: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 421: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 422: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 423: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 424: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 425: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 426: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 427: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 428: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 429: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 430: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 431: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 432: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 433: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 434: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 435: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 436: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 437: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 438: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 439: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 440: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 441: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 442: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 443: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 444: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 445: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 446: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 447: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 448: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 449: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 450: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 451: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 452: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 453: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 454: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 455: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 456: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 457: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 458: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 459: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 460: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 461: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 462: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 463: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 464: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 465: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 466: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 467: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 468: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 469: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 470: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 471: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 472: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 473: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 474: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 475: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 476: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 477: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 478: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 479: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 480: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 481: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 482: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 483: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 484: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 485: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 486: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 487: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 488: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 489: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 490: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 491: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 492: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 493: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 494: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 495: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 496: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 497: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 498: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 499: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 500: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 501: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 502: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 503: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 504: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 505: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 506: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 507: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 508: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 509: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 510: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 511: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 512: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 513: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 514: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 515: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 516: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 517: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 518: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 519: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 520: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 521: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 522: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 523: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 524: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 525: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 526: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 527: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 528: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 529: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 530: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 531: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 532: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 533: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 534: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 535: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 536: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 537: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 538: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 539: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 540: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 541: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 542: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 543: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 544: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 545: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 546: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 547: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 548: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 549: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 550: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 551: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 552: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 553: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 554: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 555: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 556: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 557: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 558: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 559: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 560: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 561: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 562: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 563: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 564: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 565: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 566: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 567: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 568: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 569: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 570: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 571: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 572: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 573: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 574: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 575: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 576: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 577: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 578: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 579: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 580: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 581: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 582: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 583: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 584: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 585: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 586: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 587: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 588: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 589: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 590: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 591: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 592: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 593: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 594: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 595: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 596: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 597: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 598: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 599: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 600: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 601: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 602: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 603: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 604: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 605: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 606: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 607: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 608: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 609: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 610: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 611: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 612: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 613: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 614: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 615: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 616: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 617: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 618: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 619: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 620: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 621: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 622: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 623: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 624: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 625: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 626: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 627: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 628: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 629: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 630: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 631: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 632: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 633: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 634: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 635: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 636: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 637: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 638: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 639: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 640: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 641: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 642: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 643: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 644: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 645: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 646: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 647: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 648: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 649: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 650: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 651: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 652: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 653: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 654: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 655: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 656: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 657: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 658: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 659: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 660: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 661: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 662: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 663: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 664: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 665: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 666: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 667: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 668: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 669: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 670: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 671: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 672: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 673: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 674: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 675: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 676: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 677: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 678: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 679: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 680: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 681: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 682: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 683: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 684: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 685: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 686: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 687: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 688: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 689: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 690: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 691: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 692: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 693: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 694: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 695: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 696: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 697: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 698: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 699: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 700: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 701: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 702: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 703: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 704: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 705: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 706: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 707: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 708: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 709: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 710: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 711: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 712: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 713: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 714: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 715: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 716: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 717: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 718: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 719: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 720: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 721: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 722: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 723: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 724: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 725: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 726: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 727: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 728: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 729: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 730: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 731: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 732: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 733: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 734: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 735: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 736: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 737: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 738: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 739: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 740: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 741: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 742: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 743: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 744: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 745: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 746: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 747: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 748: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 749: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 750: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 751: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 752: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 753: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 754: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 755: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 756: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 757: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 758: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 759: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 760: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 761: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 762: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 763: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 764: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 765: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 766: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 767: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 768: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 769: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 770: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 771: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 772: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 773: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 774: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 775: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 776: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 777: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 778: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 779: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 780: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 781: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 782: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 783: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 784: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 785: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 786: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 787: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 788: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 789: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 790: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 791: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 792: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 793: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 794: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 795: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 796: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 797: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 798: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 799: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 800: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 801: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 802: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 803: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 804: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 805: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 806: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 807: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 808: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 809: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 810: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 811: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 812: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 813: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 814: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 815: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 816: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 817: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 818: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 819: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 820: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 821: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 822: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 823: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 824: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 825: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 826: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 827: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 828: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 829: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 830: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 831: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 832: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 833: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 834: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 835: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 836: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 837: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 838: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 839: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 840: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 841: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 842: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 843: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 844: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 845: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 846: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 847: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 848: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 849: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 850: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 851: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 852: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 853: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 854: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 855: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 856: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 857: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 858: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 859: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 860: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 861: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 862: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 863: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 864: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 865: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 866: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 867: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 868: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 869: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 870: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 871: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 872: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 873: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 874: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 875: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 876: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 877: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 878: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 879: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 880: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 881: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 882: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 883: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 884: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 885: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 886: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 887: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 888: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 889: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 890: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 891: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 892: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 893: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 894: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 895: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 896: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 897: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 898: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 899: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 900: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 901: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 902: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 903: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 904: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 905: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 906: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 907: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 908: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 909: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 910: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 911: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 912: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 913: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 914: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 915: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 916: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 917: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 918: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 919: True Label: Epileptic, Predicted: Epileptic\n"
          ]
        }
      ],
      "source": [
        "#LAMSTAR (no denoising, no tuning)\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SOM:\n",
        "    def __init__(self, input_dim, num_neurons, learning_rate=0.5):\n",
        "        self.input_dim = input_dim\n",
        "        self.num_neurons = num_neurons\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.random.rand(num_neurons, input_dim)\n",
        "        self.weights = self.weights / np.linalg.norm(self.weights, axis=1, keepdims=True)\n",
        "\n",
        "    def train(self, input_data, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point in input_data:\n",
        "                distances = np.linalg.norm(self.weights - data_point, axis=1)\n",
        "                winner_index = np.argmin(distances)\n",
        "                self.weights[winner_index] += self.learning_rate * (data_point - self.weights[winner_index])\n",
        "                self.weights[winner_index] /= np.linalg.norm(self.weights[winner_index])\n",
        "    def get_winner(self, input_vector):\n",
        "        distances = np.linalg.norm(self.weights - input_vector, axis=1)\n",
        "        winner_index = np.argmin(distances)\n",
        "        return winner_index\n",
        "\n",
        "class LAMSTAR:\n",
        "    def __init__(self, input_dim, subword_dims, num_neurons_per_som, num_output_neurons):\n",
        "        self.soms = [SOM(dim, num_neurons_per_som) for dim in subword_dims]\n",
        "        self.output_weights = np.random.rand(num_output_neurons, len(self.soms))\n",
        "        self.output_weights /= np.linalg.norm(self.output_weights, axis=1, keepdims=True)\n",
        "        self.learning_rate = 0.1\n",
        "\n",
        "    def train(self, input_data, labels, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point, label in zip(input_data, labels):\n",
        "                winners = []\n",
        "                for i, som in enumerate(self.soms):\n",
        "                    winner = som.get_winner(data_point[i])\n",
        "                    winners.append(winner)\n",
        "                activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "                predicted_label = np.argmax(activations)\n",
        "                if predicted_label == label:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                else:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                    self.output_weights[predicted_label, winners] -= self.learning_rate\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        predictions = []\n",
        "        for data_point in input_data:\n",
        "            winners = []\n",
        "            for i, som in enumerate(self.soms):\n",
        "                winner = som.get_winner(data_point[i])\n",
        "                winners.append(winner)\n",
        "\n",
        "            activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "            predicted_label = np.argmax(activations)\n",
        "            predictions.append(predicted_label)\n",
        "        return predictions\n",
        "\n",
        "lamstar_input = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            subword1, subword2 = map(int, subwords.split(';'))\n",
        "            lamstar_input.append([subword1, subword2])\n",
        "            #labels: 1 for epileptic (S directory), 0 for healthy (Z directory)\n",
        "            labels.append(1 if \"S\" in segment else 0)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "lamstar_input = np.array(lamstar_input)\n",
        "labels = np.array(labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(lamstar_input, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "lamstar = LAMSTAR(input_dim=2, subword_dims=[1, 1], num_neurons_per_som=10, num_output_neurons=2)\n",
        "lamstar.train(X_train, y_train, epochs=100)\n",
        "predictions = lamstar.predict(X_test)\n",
        "for i, (true_label, prediction) in enumerate(zip(y_test, predictions)):\n",
        "    print(f\"Test Segment {i}: True Label: {'Epileptic' if true_label == 1 else 'Healthy'}, Predicted: {'Epileptic' if prediction == 1 else 'Healthy'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obli4IYv6u8c",
        "outputId": "023edeb2-98dd-49d0-b54c-46452ac76bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.48\n",
            "Confusion Matrix:\n",
            "[[  0 475]\n",
            " [  0 445]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.00      0.00      0.00       475\n",
            "   Epileptic       0.48      1.00      0.65       445\n",
            "\n",
            "    accuracy                           0.48       920\n",
            "   macro avg       0.24      0.50      0.33       920\n",
            "weighted avg       0.23      0.48      0.32       920\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "classification_report_str = classification_report(y_test, predictions, target_names=[\"Healthy\", \"Epileptic\"])\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMseyclT7ipJ",
        "outputId": "f38b6912-dd06-4ce7-874d-dfe46115eafd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-de74327672ad>:11: RuntimeWarning: invalid value encountered in divide\n",
            "  self.weights = self.weights / np.linalg.norm(self.weights, axis=1, keepdims=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Segment 0: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 1: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 2: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 3: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 4: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 5: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 6: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 7: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 8: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 9: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 10: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 11: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 12: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 13: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 14: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 15: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 16: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 17: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 18: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 19: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 20: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 21: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 22: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 23: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 24: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 25: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 26: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 27: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 28: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 29: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 30: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 31: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 32: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 33: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 34: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 35: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 36: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 37: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 38: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 39: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 40: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 41: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 42: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 43: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 44: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 45: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 46: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 47: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 48: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 49: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 50: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 51: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 52: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 53: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 54: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 55: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 56: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 57: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 58: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 59: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 60: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 61: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 62: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 63: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 64: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 65: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 66: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 67: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 68: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 69: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 70: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 71: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 72: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 73: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 74: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 75: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 76: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 77: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 78: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 79: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 80: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 81: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 82: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 83: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 84: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 85: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 86: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 87: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 88: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 89: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 90: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 91: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 92: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 93: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 94: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 95: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 96: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 97: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 98: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 99: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 100: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 101: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 102: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 103: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 104: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 105: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 106: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 107: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 108: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 109: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 110: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 111: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 112: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 113: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 114: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 115: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 116: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 117: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 118: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 119: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 120: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 121: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 122: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 123: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 124: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 125: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 126: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 127: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 128: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 129: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 130: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 131: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 132: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 133: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 134: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 135: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 136: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 137: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 138: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 139: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 140: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 141: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 142: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 143: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 144: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 145: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 146: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 147: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 148: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 149: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 150: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 151: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 152: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 153: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 154: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 155: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 156: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 157: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 158: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 159: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 160: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 161: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 162: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 163: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 164: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 165: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 166: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 167: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 168: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 169: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 170: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 171: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 172: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 173: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 174: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 175: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 176: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 177: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 178: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 179: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 180: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 181: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 182: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 183: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 184: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 185: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 186: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 187: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 188: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 189: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 190: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 191: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 192: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 193: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 194: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 195: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 196: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 197: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 198: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 199: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 200: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 201: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 202: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 203: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 204: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 205: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 206: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 207: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 208: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 209: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 210: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 211: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 212: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 213: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 214: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 215: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 216: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 217: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 218: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 219: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 220: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 221: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 222: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 223: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 224: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 225: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 226: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 227: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 228: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 229: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 230: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 231: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 232: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 233: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 234: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 235: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 236: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 237: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 238: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 239: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 240: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 241: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 242: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 243: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 244: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 245: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 246: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 247: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 248: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 249: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 250: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 251: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 252: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 253: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 254: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 255: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 256: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 257: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 258: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 259: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 260: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 261: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 262: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 263: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 264: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 265: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 266: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 267: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 268: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 269: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 270: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 271: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 272: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 273: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 274: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 275: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 276: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 277: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 278: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 279: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 280: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 281: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 282: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 283: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 284: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 285: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 286: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 287: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 288: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 289: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 290: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 291: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 292: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 293: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 294: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 295: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 296: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 297: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 298: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 299: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 300: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 301: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 302: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 303: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 304: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 305: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 306: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 307: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 308: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 309: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 310: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 311: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 312: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 313: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 314: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 315: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 316: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 317: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 318: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 319: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 320: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 321: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 322: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 323: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 324: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 325: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 326: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 327: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 328: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 329: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 330: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 331: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 332: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 333: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 334: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 335: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 336: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 337: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 338: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 339: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 340: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 341: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 342: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 343: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 344: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 345: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 346: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 347: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 348: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 349: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 350: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 351: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 352: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 353: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 354: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 355: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 356: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 357: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 358: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 359: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 360: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 361: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 362: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 363: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 364: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 365: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 366: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 367: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 368: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 369: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 370: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 371: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 372: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 373: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 374: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 375: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 376: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 377: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 378: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 379: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 380: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 381: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 382: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 383: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 384: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 385: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 386: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 387: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 388: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 389: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 390: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 391: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 392: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 393: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 394: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 395: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 396: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 397: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 398: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 399: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 400: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 401: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 402: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 403: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 404: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 405: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 406: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 407: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 408: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 409: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 410: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 411: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 412: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 413: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 414: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 415: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 416: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 417: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 418: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 419: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 420: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 421: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 422: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 423: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 424: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 425: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 426: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 427: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 428: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 429: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 430: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 431: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 432: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 433: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 434: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 435: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 436: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 437: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 438: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 439: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 440: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 441: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 442: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 443: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 444: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 445: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 446: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 447: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 448: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 449: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 450: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 451: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 452: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 453: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 454: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 455: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 456: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 457: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 458: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 459: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 460: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 461: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 462: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 463: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 464: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 465: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 466: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 467: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 468: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 469: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 470: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 471: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 472: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 473: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 474: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 475: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 476: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 477: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 478: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 479: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 480: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 481: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 482: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 483: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 484: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 485: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 486: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 487: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 488: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 489: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 490: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 491: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 492: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 493: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 494: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 495: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 496: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 497: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 498: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 499: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 500: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 501: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 502: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 503: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 504: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 505: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 506: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 507: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 508: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 509: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 510: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 511: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 512: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 513: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 514: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 515: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 516: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 517: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 518: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 519: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 520: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 521: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 522: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 523: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 524: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 525: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 526: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 527: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 528: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 529: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 530: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 531: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 532: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 533: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 534: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 535: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 536: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 537: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 538: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 539: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 540: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 541: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 542: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 543: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 544: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 545: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 546: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 547: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 548: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 549: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 550: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 551: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 552: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 553: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 554: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 555: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 556: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 557: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 558: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 559: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 560: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 561: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 562: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 563: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 564: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 565: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 566: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 567: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 568: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 569: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 570: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 571: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 572: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 573: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 574: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 575: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 576: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 577: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 578: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 579: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 580: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 581: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 582: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 583: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 584: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 585: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 586: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 587: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 588: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 589: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 590: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 591: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 592: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 593: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 594: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 595: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 596: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 597: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 598: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 599: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 600: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 601: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 602: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 603: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 604: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 605: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 606: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 607: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 608: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 609: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 610: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 611: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 612: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 613: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 614: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 615: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 616: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 617: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 618: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 619: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 620: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 621: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 622: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 623: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 624: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 625: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 626: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 627: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 628: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 629: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 630: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 631: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 632: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 633: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 634: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 635: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 636: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 637: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 638: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 639: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 640: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 641: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 642: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 643: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 644: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 645: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 646: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 647: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 648: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 649: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 650: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 651: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 652: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 653: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 654: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 655: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 656: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 657: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 658: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 659: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 660: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 661: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 662: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 663: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 664: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 665: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 666: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 667: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 668: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 669: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 670: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 671: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 672: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 673: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 674: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 675: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 676: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 677: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 678: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 679: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 680: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 681: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 682: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 683: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 684: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 685: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 686: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 687: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 688: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 689: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 690: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 691: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 692: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 693: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 694: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 695: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 696: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 697: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 698: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 699: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 700: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 701: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 702: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 703: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 704: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 705: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 706: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 707: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 708: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 709: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 710: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 711: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 712: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 713: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 714: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 715: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 716: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 717: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 718: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 719: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 720: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 721: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 722: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 723: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 724: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 725: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 726: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 727: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 728: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 729: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 730: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 731: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 732: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 733: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 734: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 735: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 736: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 737: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 738: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 739: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 740: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 741: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 742: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 743: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 744: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 745: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 746: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 747: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 748: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 749: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 750: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 751: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 752: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 753: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 754: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 755: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 756: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 757: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 758: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 759: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 760: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 761: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 762: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 763: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 764: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 765: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 766: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 767: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 768: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 769: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 770: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 771: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 772: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 773: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 774: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 775: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 776: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 777: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 778: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 779: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 780: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 781: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 782: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 783: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 784: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 785: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 786: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 787: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 788: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 789: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 790: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 791: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 792: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 793: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 794: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 795: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 796: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 797: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 798: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 799: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 800: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 801: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 802: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 803: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 804: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 805: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 806: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 807: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 808: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 809: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 810: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 811: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 812: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 813: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 814: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 815: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 816: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 817: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 818: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 819: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 820: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 821: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 822: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 823: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 824: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 825: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 826: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 827: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 828: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 829: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 830: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 831: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 832: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 833: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 834: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 835: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 836: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 837: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 838: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 839: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 840: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 841: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 842: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 843: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 844: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 845: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 846: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 847: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 848: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 849: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 850: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 851: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 852: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 853: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 854: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 855: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 856: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 857: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 858: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 859: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 860: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 861: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 862: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 863: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 864: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 865: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 866: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 867: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 868: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 869: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 870: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 871: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 872: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 873: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 874: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 875: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 876: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 877: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 878: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 879: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 880: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 881: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 882: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 883: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 884: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 885: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 886: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 887: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 888: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 889: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 890: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 891: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 892: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 893: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 894: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 895: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 896: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 897: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 898: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 899: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 900: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 901: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 902: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 903: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 904: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 905: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 906: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 907: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 908: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 909: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 910: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 911: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 912: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 913: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 914: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 915: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 916: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 917: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 918: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 919: True Label: Epileptic, Predicted: Epileptic\n"
          ]
        }
      ],
      "source": [
        "#LAMSTAR\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SOM:\n",
        "    def __init__(self, input_dim, num_neurons, learning_rate=0.5):\n",
        "        self.input_dim = input_dim\n",
        "        self.num_neurons = num_neurons\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.linspace(0, 1, num_neurons * input_dim).reshape(num_neurons, input_dim)\n",
        "        self.weights = self.weights / np.linalg.norm(self.weights, axis=1, keepdims=True)\n",
        "\n",
        "    def train(self, input_data, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point in input_data:\n",
        "                distances = np.linalg.norm(self.weights - data_point, axis=1)\n",
        "                winner_index = np.argmin(distances)\n",
        "                self.weights[winner_index] += self.learning_rate * (data_point - self.weights[winner_index])\n",
        "                self.weights[winner_index] /= np.linalg.norm(self.weights[winner_index])  # Normalize weights\n",
        "\n",
        "    def get_winner(self, input_vector):\n",
        "        distances = np.linalg.norm(self.weights - input_vector, axis=1)\n",
        "        winner_index = np.argmin(distances)\n",
        "        return winner_index\n",
        "\n",
        "class LAMSTAR:\n",
        "    def __init__(self, input_dim, subword_dims, num_neurons_per_som, num_output_neurons):\n",
        "        self.soms = [SOM(dim, num_neurons_per_som) for dim in subword_dims]\n",
        "        self.output_weights = np.random.rand(num_output_neurons, len(self.soms))\n",
        "        self.output_weights /= np.linalg.norm(self.output_weights, axis=1, keepdims=True)\n",
        "        self.learning_rate = 0.1\n",
        "\n",
        "    def train(self, input_data, labels, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point, label in zip(input_data, labels):\n",
        "                winners = []\n",
        "                for i, som in enumerate(self.soms):\n",
        "                    winner = som.get_winner(data_point[i])\n",
        "                    winners.append(winner)\n",
        "                activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "                predicted_label = np.argmax(activations)\n",
        "                if predicted_label == label:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                else:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                    self.output_weights[predicted_label, winners] -= self.learning_rate\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        predictions = []\n",
        "        for data_point in input_data:\n",
        "            winners = []\n",
        "            for i, som in enumerate(self.soms):\n",
        "                winner = som.get_winner(data_point[i])\n",
        "                winners.append(winner)\n",
        "\n",
        "            activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "            predicted_label = np.argmax(activations)\n",
        "            predictions.append(predicted_label)\n",
        "        return predictions\n",
        "\n",
        "lamstar_input = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            subword1, subword2 = map(int, subwords.split(';'))\n",
        "            lamstar_input.append([subword1, subword2])\n",
        "            #labels: 1 for epileptic (S directory), 0 for healthy (Z directory)\n",
        "            labels.append(1 if \"S\" in segment else 0)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "lamstar_input = np.array(lamstar_input)\n",
        "labels = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(lamstar_input, labels, test_size=0.2, random_state=42)\n",
        "lamstar = LAMSTAR(input_dim=2, subword_dims=[1, 1], num_neurons_per_som=10, num_output_neurons=2)\n",
        "lamstar.train(X_train, y_train, epochs=100)\n",
        "predictions = lamstar.predict(X_test)\n",
        "for i, (true_label, prediction) in enumerate(zip(y_test, predictions)):\n",
        "    print(f\"Test Segment {i}: True Label: {'Epileptic' if true_label == 1 else 'Healthy'}, Predicted: {'Epileptic' if prediction == 1 else 'Healthy'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIIDe-Pg7v_n",
        "outputId": "137c7f4e-3268-4814-ee6c-fa8dfa1471ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.48\n",
            "Confusion Matrix:\n",
            "[[  0 475]\n",
            " [  0 445]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.00      0.00      0.00       475\n",
            "   Epileptic       0.48      1.00      0.65       445\n",
            "\n",
            "    accuracy                           0.48       920\n",
            "   macro avg       0.24      0.50      0.33       920\n",
            "weighted avg       0.23      0.48      0.32       920\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, predictions)\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "classification_report_str = classification_report(y_test, predictions, target_names=[\"Healthy\", \"Epileptic\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIGhg9as9_9_",
        "outputId": "f2141b0b-b4f3-4dc4-d739-1156cceedf66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a7384fa582f5>:11: RuntimeWarning: invalid value encountered in divide\n",
            "  self.weights = self.weights / np.linalg.norm(self.weights, axis=1, keepdims=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Segment 0: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 1: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 2: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 3: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 4: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 5: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 6: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 7: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 8: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 9: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 10: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 11: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 12: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 13: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 14: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 15: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 16: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 17: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 18: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 19: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 20: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 21: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 22: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 23: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 24: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 25: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 26: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 27: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 28: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 29: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 30: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 31: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 32: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 33: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 34: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 35: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 36: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 37: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 38: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 39: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 40: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 41: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 42: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 43: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 44: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 45: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 46: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 47: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 48: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 49: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 50: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 51: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 52: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 53: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 54: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 55: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 56: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 57: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 58: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 59: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 60: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 61: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 62: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 63: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 64: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 65: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 66: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 67: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 68: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 69: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 70: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 71: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 72: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 73: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 74: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 75: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 76: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 77: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 78: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 79: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 80: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 81: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 82: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 83: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 84: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 85: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 86: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 87: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 88: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 89: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 90: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 91: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 92: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 93: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 94: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 95: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 96: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 97: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 98: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 99: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 100: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 101: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 102: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 103: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 104: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 105: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 106: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 107: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 108: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 109: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 110: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 111: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 112: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 113: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 114: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 115: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 116: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 117: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 118: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 119: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 120: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 121: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 122: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 123: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 124: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 125: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 126: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 127: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 128: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 129: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 130: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 131: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 132: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 133: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 134: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 135: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 136: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 137: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 138: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 139: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 140: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 141: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 142: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 143: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 144: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 145: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 146: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 147: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 148: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 149: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 150: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 151: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 152: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 153: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 154: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 155: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 156: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 157: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 158: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 159: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 160: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 161: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 162: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 163: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 164: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 165: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 166: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 167: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 168: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 169: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 170: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 171: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 172: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 173: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 174: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 175: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 176: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 177: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 178: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 179: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 180: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 181: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 182: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 183: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 184: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 185: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 186: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 187: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 188: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 189: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 190: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 191: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 192: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 193: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 194: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 195: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 196: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 197: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 198: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 199: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 200: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 201: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 202: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 203: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 204: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 205: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 206: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 207: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 208: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 209: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 210: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 211: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 212: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 213: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 214: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 215: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 216: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 217: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 218: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 219: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 220: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 221: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 222: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 223: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 224: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 225: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 226: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 227: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 228: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 229: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 230: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 231: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 232: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 233: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 234: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 235: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 236: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 237: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 238: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 239: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 240: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 241: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 242: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 243: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 244: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 245: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 246: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 247: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 248: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 249: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 250: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 251: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 252: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 253: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 254: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 255: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 256: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 257: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 258: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 259: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 260: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 261: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 262: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 263: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 264: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 265: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 266: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 267: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 268: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 269: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 270: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 271: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 272: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 273: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 274: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 275: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 276: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 277: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 278: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 279: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 280: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 281: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 282: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 283: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 284: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 285: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 286: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 287: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 288: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 289: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 290: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 291: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 292: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 293: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 294: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 295: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 296: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 297: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 298: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 299: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 300: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 301: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 302: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 303: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 304: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 305: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 306: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 307: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 308: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 309: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 310: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 311: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 312: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 313: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 314: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 315: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 316: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 317: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 318: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 319: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 320: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 321: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 322: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 323: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 324: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 325: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 326: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 327: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 328: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 329: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 330: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 331: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 332: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 333: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 334: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 335: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 336: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 337: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 338: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 339: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 340: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 341: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 342: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 343: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 344: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 345: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 346: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 347: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 348: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 349: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 350: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 351: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 352: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 353: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 354: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 355: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 356: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 357: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 358: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 359: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 360: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 361: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 362: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 363: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 364: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 365: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 366: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 367: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 368: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 369: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 370: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 371: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 372: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 373: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 374: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 375: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 376: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 377: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 378: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 379: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 380: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 381: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 382: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 383: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 384: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 385: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 386: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 387: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 388: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 389: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 390: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 391: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 392: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 393: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 394: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 395: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 396: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 397: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 398: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 399: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 400: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 401: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 402: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 403: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 404: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 405: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 406: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 407: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 408: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 409: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 410: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 411: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 412: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 413: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 414: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 415: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 416: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 417: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 418: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 419: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 420: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 421: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 422: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 423: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 424: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 425: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 426: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 427: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 428: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 429: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 430: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 431: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 432: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 433: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 434: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 435: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 436: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 437: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 438: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 439: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 440: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 441: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 442: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 443: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 444: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 445: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 446: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 447: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 448: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 449: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 450: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 451: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 452: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 453: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 454: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 455: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 456: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 457: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 458: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 459: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 460: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 461: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 462: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 463: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 464: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 465: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 466: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 467: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 468: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 469: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 470: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 471: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 472: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 473: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 474: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 475: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 476: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 477: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 478: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 479: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 480: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 481: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 482: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 483: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 484: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 485: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 486: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 487: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 488: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 489: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 490: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 491: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 492: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 493: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 494: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 495: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 496: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 497: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 498: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 499: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 500: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 501: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 502: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 503: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 504: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 505: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 506: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 507: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 508: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 509: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 510: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 511: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 512: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 513: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 514: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 515: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 516: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 517: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 518: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 519: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 520: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 521: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 522: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 523: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 524: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 525: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 526: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 527: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 528: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 529: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 530: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 531: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 532: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 533: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 534: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 535: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 536: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 537: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 538: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 539: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 540: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 541: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 542: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 543: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 544: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 545: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 546: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 547: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 548: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 549: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 550: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 551: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 552: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 553: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 554: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 555: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 556: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 557: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 558: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 559: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 560: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 561: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 562: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 563: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 564: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 565: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 566: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 567: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 568: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 569: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 570: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 571: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 572: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 573: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 574: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 575: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 576: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 577: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 578: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 579: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 580: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 581: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 582: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 583: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 584: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 585: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 586: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 587: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 588: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 589: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 590: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 591: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 592: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 593: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 594: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 595: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 596: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 597: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 598: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 599: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 600: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 601: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 602: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 603: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 604: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 605: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 606: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 607: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 608: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 609: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 610: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 611: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 612: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 613: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 614: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 615: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 616: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 617: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 618: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 619: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 620: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 621: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 622: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 623: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 624: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 625: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 626: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 627: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 628: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 629: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 630: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 631: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 632: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 633: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 634: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 635: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 636: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 637: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 638: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 639: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 640: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 641: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 642: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 643: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 644: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 645: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 646: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 647: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 648: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 649: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 650: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 651: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 652: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 653: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 654: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 655: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 656: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 657: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 658: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 659: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 660: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 661: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 662: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 663: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 664: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 665: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 666: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 667: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 668: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 669: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 670: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 671: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 672: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 673: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 674: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 675: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 676: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 677: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 678: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 679: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 680: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 681: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 682: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 683: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 684: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 685: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 686: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 687: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 688: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 689: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 690: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 691: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 692: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 693: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 694: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 695: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 696: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 697: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 698: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 699: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 700: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 701: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 702: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 703: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 704: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 705: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 706: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 707: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 708: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 709: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 710: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 711: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 712: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 713: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 714: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 715: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 716: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 717: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 718: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 719: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 720: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 721: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 722: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 723: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 724: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 725: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 726: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 727: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 728: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 729: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 730: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 731: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 732: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 733: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 734: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 735: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 736: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 737: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 738: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 739: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 740: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 741: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 742: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 743: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 744: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 745: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 746: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 747: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 748: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 749: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 750: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 751: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 752: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 753: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 754: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 755: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 756: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 757: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 758: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 759: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 760: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 761: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 762: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 763: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 764: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 765: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 766: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 767: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 768: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 769: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 770: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 771: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 772: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 773: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 774: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 775: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 776: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 777: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 778: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 779: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 780: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 781: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 782: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 783: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 784: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 785: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 786: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 787: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 788: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 789: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 790: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 791: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 792: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 793: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 794: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 795: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 796: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 797: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 798: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 799: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 800: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 801: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 802: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 803: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 804: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 805: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 806: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 807: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 808: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 809: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 810: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 811: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 812: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 813: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 814: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 815: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 816: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 817: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 818: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 819: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 820: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 821: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 822: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 823: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 824: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 825: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 826: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 827: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 828: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 829: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 830: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 831: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 832: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 833: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 834: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 835: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 836: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 837: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 838: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 839: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 840: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 841: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 842: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 843: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 844: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 845: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 846: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 847: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 848: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 849: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 850: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 851: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 852: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 853: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 854: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 855: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 856: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 857: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 858: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 859: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 860: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 861: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 862: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 863: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 864: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 865: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 866: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 867: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 868: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 869: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 870: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 871: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 872: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 873: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 874: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 875: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 876: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 877: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 878: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 879: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 880: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 881: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 882: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 883: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 884: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 885: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 886: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 887: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 888: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 889: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 890: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 891: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 892: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 893: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 894: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 895: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 896: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 897: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 898: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 899: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 900: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 901: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 902: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 903: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 904: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 905: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 906: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 907: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 908: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 909: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 910: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 911: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 912: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 913: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 914: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 915: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 916: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 917: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 918: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 919: True Label: Epileptic, Predicted: Epileptic\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SOM:\n",
        "    def __init__(self, input_dim, num_neurons, learning_rate=0.5):\n",
        "        self.input_dim = input_dim\n",
        "        self.num_neurons = num_neurons\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.linspace(0, 1, num_neurons * input_dim).reshape(num_neurons, input_dim)\n",
        "        self.weights = self.weights / np.linalg.norm(self.weights, axis=1, keepdims=True)\n",
        "\n",
        "    def train(self, input_data, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point in input_data:\n",
        "                distances = np.linalg.norm(self.weights - data_point, axis=1)\n",
        "                winner_index = np.argmin(distances)\n",
        "                self.weights[winner_index] += self.learning_rate * (data_point - self.weights[winner_index])\n",
        "                self.weights[winner_index] /= np.linalg.norm(self.weights[winner_index])  # Normalize weights\n",
        "\n",
        "    def get_winner(self, input_vector):\n",
        "        distances = np.linalg.norm(self.weights - input_vector, axis=1)\n",
        "        winner_index = np.argmin(distances)\n",
        "        return winner_index\n",
        "\n",
        "class LAMSTAR:\n",
        "    def __init__(self, input_dim, subword_dims, num_neurons_per_som, num_output_neurons):\n",
        "        self.soms = [SOM(dim, num_neurons_per_som) for dim in subword_dims]\n",
        "        self.output_weights = np.random.rand(num_output_neurons, len(self.soms))\n",
        "        self.output_weights /= np.linalg.norm(self.output_weights, axis=1, keepdims=True)\n",
        "        self.learning_rate = 0.1\n",
        "\n",
        "    def train(self, input_data, labels, epochs=50):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point, label in zip(input_data, labels):\n",
        "                winners = []\n",
        "                for i, som in enumerate(self.soms):\n",
        "                    winner = som.get_winner(data_point[i])\n",
        "                    winners.append(winner)\n",
        "                activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "                predicted_label = np.argmax(activations)\n",
        "                if predicted_label == label:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                else:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                    self.output_weights[predicted_label, winners] -= self.learning_rate\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        predictions = []\n",
        "        for data_point in input_data:\n",
        "            winners = []\n",
        "            for i, som in enumerate(self.soms):\n",
        "                winner = som.get_winner(data_point[i])\n",
        "                winners.append(winner)\n",
        "\n",
        "            activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "            predicted_label = np.argmax(activations)\n",
        "            predictions.append(predicted_label)\n",
        "        return predictions\n",
        "\n",
        "lamstar_input = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            subword1, subword2 = map(int, subwords.split(';'))\n",
        "            lamstar_input.append([subword1, subword2])\n",
        "            #labels: 1 for epileptic (S directory), 0 for healthy (Z directory)\n",
        "            labels.append(1 if \"S\" in segment else 0)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "lamstar_input = np.array(lamstar_input)\n",
        "labels = np.array(labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(lamstar_input, labels, test_size=0.2, random_state=42)\n",
        "lamstar = LAMSTAR(input_dim=2, subword_dims=[1, 1], num_neurons_per_som=10, num_output_neurons=2)\n",
        "lamstar.train(X_train, y_train, epochs=50)\n",
        "predictions = lamstar.predict(X_test)\n",
        "for i, (true_label, prediction) in enumerate(zip(y_test, predictions)):\n",
        "    print(f\"Test Segment {i}: True Label: {'Epileptic' if true_label == 1 else 'Healthy'}, Predicted: {'Epileptic' if prediction == 1 else 'Healthy'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH7TZU4m-45Z",
        "outputId": "e798a93c-5047-45e3-8ee5-6fcf6641adc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-36-b4ce689ec318>:11: RuntimeWarning: invalid value encountered in divide\n",
            "  self.weights = self.weights / np.linalg.norm(self.weights, axis=1, keepdims=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Segment 0: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 1: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 2: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 3: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 4: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 5: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 6: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 7: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 8: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 9: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 10: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 11: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 12: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 13: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 14: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 15: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 16: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 17: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 18: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 19: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 20: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 21: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 22: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 23: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 24: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 25: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 26: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 27: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 28: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 29: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 30: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 31: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 32: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 33: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 34: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 35: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 36: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 37: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 38: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 39: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 40: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 41: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 42: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 43: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 44: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 45: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 46: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 47: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 48: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 49: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 50: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 51: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 52: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 53: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 54: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 55: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 56: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 57: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 58: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 59: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 60: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 61: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 62: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 63: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 64: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 65: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 66: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 67: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 68: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 69: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 70: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 71: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 72: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 73: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 74: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 75: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 76: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 77: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 78: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 79: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 80: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 81: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 82: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 83: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 84: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 85: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 86: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 87: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 88: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 89: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 90: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 91: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 92: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 93: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 94: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 95: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 96: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 97: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 98: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 99: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 100: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 101: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 102: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 103: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 104: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 105: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 106: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 107: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 108: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 109: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 110: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 111: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 112: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 113: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 114: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 115: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 116: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 117: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 118: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 119: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 120: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 121: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 122: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 123: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 124: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 125: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 126: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 127: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 128: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 129: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 130: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 131: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 132: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 133: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 134: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 135: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 136: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 137: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 138: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 139: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 140: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 141: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 142: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 143: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 144: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 145: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 146: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 147: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 148: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 149: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 150: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 151: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 152: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 153: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 154: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 155: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 156: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 157: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 158: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 159: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 160: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 161: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 162: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 163: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 164: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 165: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 166: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 167: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 168: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 169: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 170: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 171: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 172: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 173: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 174: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 175: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 176: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 177: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 178: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 179: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 180: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 181: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 182: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 183: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 184: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 185: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 186: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 187: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 188: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 189: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 190: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 191: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 192: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 193: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 194: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 195: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 196: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 197: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 198: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 199: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 200: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 201: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 202: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 203: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 204: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 205: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 206: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 207: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 208: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 209: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 210: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 211: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 212: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 213: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 214: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 215: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 216: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 217: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 218: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 219: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 220: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 221: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 222: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 223: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 224: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 225: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 226: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 227: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 228: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 229: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 230: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 231: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 232: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 233: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 234: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 235: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 236: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 237: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 238: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 239: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 240: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 241: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 242: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 243: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 244: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 245: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 246: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 247: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 248: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 249: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 250: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 251: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 252: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 253: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 254: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 255: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 256: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 257: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 258: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 259: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 260: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 261: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 262: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 263: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 264: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 265: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 266: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 267: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 268: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 269: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 270: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 271: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 272: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 273: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 274: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 275: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 276: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 277: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 278: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 279: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 280: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 281: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 282: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 283: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 284: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 285: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 286: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 287: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 288: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 289: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 290: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 291: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 292: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 293: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 294: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 295: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 296: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 297: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 298: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 299: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 300: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 301: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 302: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 303: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 304: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 305: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 306: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 307: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 308: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 309: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 310: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 311: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 312: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 313: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 314: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 315: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 316: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 317: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 318: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 319: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 320: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 321: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 322: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 323: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 324: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 325: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 326: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 327: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 328: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 329: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 330: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 331: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 332: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 333: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 334: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 335: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 336: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 337: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 338: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 339: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 340: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 341: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 342: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 343: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 344: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 345: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 346: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 347: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 348: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 349: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 350: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 351: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 352: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 353: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 354: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 355: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 356: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 357: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 358: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 359: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 360: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 361: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 362: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 363: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 364: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 365: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 366: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 367: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 368: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 369: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 370: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 371: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 372: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 373: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 374: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 375: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 376: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 377: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 378: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 379: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 380: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 381: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 382: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 383: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 384: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 385: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 386: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 387: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 388: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 389: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 390: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 391: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 392: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 393: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 394: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 395: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 396: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 397: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 398: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 399: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 400: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 401: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 402: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 403: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 404: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 405: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 406: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 407: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 408: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 409: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 410: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 411: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 412: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 413: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 414: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 415: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 416: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 417: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 418: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 419: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 420: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 421: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 422: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 423: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 424: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 425: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 426: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 427: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 428: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 429: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 430: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 431: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 432: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 433: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 434: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 435: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 436: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 437: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 438: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 439: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 440: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 441: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 442: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 443: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 444: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 445: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 446: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 447: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 448: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 449: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 450: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 451: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 452: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 453: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 454: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 455: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 456: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 457: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 458: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 459: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 460: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 461: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 462: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 463: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 464: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 465: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 466: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 467: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 468: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 469: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 470: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 471: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 472: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 473: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 474: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 475: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 476: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 477: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 478: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 479: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 480: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 481: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 482: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 483: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 484: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 485: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 486: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 487: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 488: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 489: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 490: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 491: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 492: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 493: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 494: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 495: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 496: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 497: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 498: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 499: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 500: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 501: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 502: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 503: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 504: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 505: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 506: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 507: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 508: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 509: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 510: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 511: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 512: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 513: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 514: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 515: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 516: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 517: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 518: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 519: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 520: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 521: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 522: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 523: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 524: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 525: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 526: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 527: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 528: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 529: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 530: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 531: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 532: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 533: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 534: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 535: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 536: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 537: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 538: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 539: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 540: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 541: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 542: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 543: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 544: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 545: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 546: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 547: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 548: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 549: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 550: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 551: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 552: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 553: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 554: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 555: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 556: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 557: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 558: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 559: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 560: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 561: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 562: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 563: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 564: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 565: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 566: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 567: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 568: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 569: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 570: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 571: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 572: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 573: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 574: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 575: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 576: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 577: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 578: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 579: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 580: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 581: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 582: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 583: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 584: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 585: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 586: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 587: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 588: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 589: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 590: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 591: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 592: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 593: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 594: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 595: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 596: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 597: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 598: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 599: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 600: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 601: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 602: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 603: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 604: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 605: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 606: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 607: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 608: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 609: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 610: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 611: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 612: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 613: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 614: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 615: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 616: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 617: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 618: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 619: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 620: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 621: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 622: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 623: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 624: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 625: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 626: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 627: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 628: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 629: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 630: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 631: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 632: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 633: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 634: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 635: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 636: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 637: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 638: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 639: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 640: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 641: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 642: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 643: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 644: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 645: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 646: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 647: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 648: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 649: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 650: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 651: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 652: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 653: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 654: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 655: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 656: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 657: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 658: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 659: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 660: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 661: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 662: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 663: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 664: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 665: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 666: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 667: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 668: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 669: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 670: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 671: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 672: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 673: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 674: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 675: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 676: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 677: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 678: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 679: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 680: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 681: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 682: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 683: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 684: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 685: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 686: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 687: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 688: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 689: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 690: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 691: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 692: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 693: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 694: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 695: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 696: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 697: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 698: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 699: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 700: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 701: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 702: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 703: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 704: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 705: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 706: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 707: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 708: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 709: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 710: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 711: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 712: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 713: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 714: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 715: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 716: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 717: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 718: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 719: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 720: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 721: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 722: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 723: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 724: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 725: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 726: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 727: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 728: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 729: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 730: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 731: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 732: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 733: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 734: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 735: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 736: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 737: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 738: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 739: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 740: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 741: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 742: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 743: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 744: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 745: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 746: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 747: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 748: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 749: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 750: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 751: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 752: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 753: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 754: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 755: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 756: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 757: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 758: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 759: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 760: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 761: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 762: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 763: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 764: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 765: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 766: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 767: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 768: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 769: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 770: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 771: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 772: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 773: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 774: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 775: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 776: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 777: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 778: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 779: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 780: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 781: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 782: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 783: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 784: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 785: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 786: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 787: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 788: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 789: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 790: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 791: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 792: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 793: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 794: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 795: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 796: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 797: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 798: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 799: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 800: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 801: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 802: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 803: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 804: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 805: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 806: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 807: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 808: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 809: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 810: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 811: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 812: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 813: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 814: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 815: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 816: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 817: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 818: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 819: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 820: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 821: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 822: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 823: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 824: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 825: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 826: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 827: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 828: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 829: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 830: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 831: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 832: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 833: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 834: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 835: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 836: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 837: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 838: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 839: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 840: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 841: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 842: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 843: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 844: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 845: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 846: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 847: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 848: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 849: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 850: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 851: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 852: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 853: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 854: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 855: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 856: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 857: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 858: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 859: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 860: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 861: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 862: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 863: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 864: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 865: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 866: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 867: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 868: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 869: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 870: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 871: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 872: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 873: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 874: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 875: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 876: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 877: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 878: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 879: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 880: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 881: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 882: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 883: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 884: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 885: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 886: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 887: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 888: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 889: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 890: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 891: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 892: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 893: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 894: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 895: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 896: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 897: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 898: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 899: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 900: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 901: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 902: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 903: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 904: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 905: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 906: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 907: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 908: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 909: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 910: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 911: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 912: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 913: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 914: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 915: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 916: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 917: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 918: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 919: True Label: Epileptic, Predicted: Epileptic\n"
          ]
        }
      ],
      "source": [
        "#LAMSTAR\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SOM:\n",
        "    def __init__(self, input_dim, num_neurons, learning_rate=0.5):\n",
        "        self.input_dim = input_dim\n",
        "        self.num_neurons = num_neurons\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.linspace(0, 1, num_neurons * input_dim).reshape(num_neurons, input_dim)\n",
        "        self.weights = self.weights / np.linalg.norm(self.weights, axis=1, keepdims=True)\n",
        "\n",
        "    def train(self, input_data, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point in input_data:\n",
        "                distances = np.linalg.norm(self.weights - data_point, axis=1)\n",
        "                winner_index = np.argmin(distances)\n",
        "                self.weights[winner_index] += self.learning_rate * (data_point - self.weights[winner_index])\n",
        "                self.weights[winner_index] /= np.linalg.norm(self.weights[winner_index])  # Normalize weights\n",
        "\n",
        "    def get_winner(self, input_vector):\n",
        "        distances = np.linalg.norm(self.weights - input_vector, axis=1)\n",
        "        winner_index = np.argmin(distances)\n",
        "        return winner_index\n",
        "\n",
        "class LAMSTAR:\n",
        "    def __init__(self, input_dim, subword_dims, num_neurons_per_som, num_output_neurons):\n",
        "        self.soms = [SOM(dim, num_neurons_per_som) for dim in subword_dims]\n",
        "        self.output_weights = np.random.rand(num_output_neurons, len(self.soms))\n",
        "        self.output_weights /= np.linalg.norm(self.output_weights, axis=1, keepdims=True)\n",
        "        self.learning_rate = 0.1\n",
        "\n",
        "    def train(self, input_data, labels, epochs=2000):  #2000 epochs\n",
        "        for epoch in range(epochs):\n",
        "            for data_point, label in zip(input_data, labels):\n",
        "                winners = []\n",
        "                for i, som in enumerate(self.soms):\n",
        "                    winner = som.get_winner(data_point[i])\n",
        "                    winners.append(winner)\n",
        "                activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "                predicted_label = np.argmax(activations)\n",
        "                if predicted_label == label:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                else:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                    self.output_weights[predicted_label, winners] -= self.learning_rate\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        predictions = []\n",
        "        for data_point in input_data:\n",
        "            winners = []\n",
        "            for i, som in enumerate(self.soms):\n",
        "                winner = som.get_winner(data_point[i])\n",
        "                winners.append(winner)\n",
        "\n",
        "            activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "            predicted_label = np.argmax(activations)\n",
        "            predictions.append(predicted_label)\n",
        "        return predictions\n",
        "\n",
        "lamstar_input = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            subword1, subword2 = map(int, subwords.split(';'))\n",
        "            lamstar_input.append([subword1, subword2])\n",
        "            #labels: 1 for epileptic (S directory), 0 for healthy (Z directory)\n",
        "            labels.append(1 if \"S\" in segment else 0)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "lamstar_input = np.array(lamstar_input)\n",
        "labels = np.array(labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(lamstar_input, labels, test_size=0.2, random_state=42)\n",
        "lamstar = LAMSTAR(input_dim=2, subword_dims=[1, 1], num_neurons_per_som=10, num_output_neurons=2)\n",
        "lamstar.train(X_train, y_train, epochs=2000)\n",
        "predictions = lamstar.predict(X_test)\n",
        "for i, (true_label, prediction) in enumerate(zip(y_test, predictions)):\n",
        "    print(f\"Test Segment {i}: True Label: {'Epileptic' if true_label == 1 else 'Healthy'}, Predicted: {'Epileptic' if prediction == 1 else 'Healthy'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQjnfw4lKipj",
        "outputId": "dd193371-e05d-484b-b355-c3a93fe6984e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.48\n",
            "Confusion Matrix:\n",
            "[[  0 475]\n",
            " [  0 445]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.00      0.00      0.00       475\n",
            "   Epileptic       0.48      1.00      0.65       445\n",
            "\n",
            "    accuracy                           0.48       920\n",
            "   macro avg       0.24      0.50      0.33       920\n",
            "weighted avg       0.23      0.48      0.32       920\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "classification_report_str = classification_report(y_test, predictions, target_names=[\"Healthy\", \"Epileptic\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4xwkxAvLXR-",
        "outputId": "66359f00-8118-4d05-9ed0-df2c09096506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from PyWavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/4.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/4.5 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PyWavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAcbZQp9LRrp",
        "outputId": "eaec7836-8071-4022-daac-33c688466839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Segment 0: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 1: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 2: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 3: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 4: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 5: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 6: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 7: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 8: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 9: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 10: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 11: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 12: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 13: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 14: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 15: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 16: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 17: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 18: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 19: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 20: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 21: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 22: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 23: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 24: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 25: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 26: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 27: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 28: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 29: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 30: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 31: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 32: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 33: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 34: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 35: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 36: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 37: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 38: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 39: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 40: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 41: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 42: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 43: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 44: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 45: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 46: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 47: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 48: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 49: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 50: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 51: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 52: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 53: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 54: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 55: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 56: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 57: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 58: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 59: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 60: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 61: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 62: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 63: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 64: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 65: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 66: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 67: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 68: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 69: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 70: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 71: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 72: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 73: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 74: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 75: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 76: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 77: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 78: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 79: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 80: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 81: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 82: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 83: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 84: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 85: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 86: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 87: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 88: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 89: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 90: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 91: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 92: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 93: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 94: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 95: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 96: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 97: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 98: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 99: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 100: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 101: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 102: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 103: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 104: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 105: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 106: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 107: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 108: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 109: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 110: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 111: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 112: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 113: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 114: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 115: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 116: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 117: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 118: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 119: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 120: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 121: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 122: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 123: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 124: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 125: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 126: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 127: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 128: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 129: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 130: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 131: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 132: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 133: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 134: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 135: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 136: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 137: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 138: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 139: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 140: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 141: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 142: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 143: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 144: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 145: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 146: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 147: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 148: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 149: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 150: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 151: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 152: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 153: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 154: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 155: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 156: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 157: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 158: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 159: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 160: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 161: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 162: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 163: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 164: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 165: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 166: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 167: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 168: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 169: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 170: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 171: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 172: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 173: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 174: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 175: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 176: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 177: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 178: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 179: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 180: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 181: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 182: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 183: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 184: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 185: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 186: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 187: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 188: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 189: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 190: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 191: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 192: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 193: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 194: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 195: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 196: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 197: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 198: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 199: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 200: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 201: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 202: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 203: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 204: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 205: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 206: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 207: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 208: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 209: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 210: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 211: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 212: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 213: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 214: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 215: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 216: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 217: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 218: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 219: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 220: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 221: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 222: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 223: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 224: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 225: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 226: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 227: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 228: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 229: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 230: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 231: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 232: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 233: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 234: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 235: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 236: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 237: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 238: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 239: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 240: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 241: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 242: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 243: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 244: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 245: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 246: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 247: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 248: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 249: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 250: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 251: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 252: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 253: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 254: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 255: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 256: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 257: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 258: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 259: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 260: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 261: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 262: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 263: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 264: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 265: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 266: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 267: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 268: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 269: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 270: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 271: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 272: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 273: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 274: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 275: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 276: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 277: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 278: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 279: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 280: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 281: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 282: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 283: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 284: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 285: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 286: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 287: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 288: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 289: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 290: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 291: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 292: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 293: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 294: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 295: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 296: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 297: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 298: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 299: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 300: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 301: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 302: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 303: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 304: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 305: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 306: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 307: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 308: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 309: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 310: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 311: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 312: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 313: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 314: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 315: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 316: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 317: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 318: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 319: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 320: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 321: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 322: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 323: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 324: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 325: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 326: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 327: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 328: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 329: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 330: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 331: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 332: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 333: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 334: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 335: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 336: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 337: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 338: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 339: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 340: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 341: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 342: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 343: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 344: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 345: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 346: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 347: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 348: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 349: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 350: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 351: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 352: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 353: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 354: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 355: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 356: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 357: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 358: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 359: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 360: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 361: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 362: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 363: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 364: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 365: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 366: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 367: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 368: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 369: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 370: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 371: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 372: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 373: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 374: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 375: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 376: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 377: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 378: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 379: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 380: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 381: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 382: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 383: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 384: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 385: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 386: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 387: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 388: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 389: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 390: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 391: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 392: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 393: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 394: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 395: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 396: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 397: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 398: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 399: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 400: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 401: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 402: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 403: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 404: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 405: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 406: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 407: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 408: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 409: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 410: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 411: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 412: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 413: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 414: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 415: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 416: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 417: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 418: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 419: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 420: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 421: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 422: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 423: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 424: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 425: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 426: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 427: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 428: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 429: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 430: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 431: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 432: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 433: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 434: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 435: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 436: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 437: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 438: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 439: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 440: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 441: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 442: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 443: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 444: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 445: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 446: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 447: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 448: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 449: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 450: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 451: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 452: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 453: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 454: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 455: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 456: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 457: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 458: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 459: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 460: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 461: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 462: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 463: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 464: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 465: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 466: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 467: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 468: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 469: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 470: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 471: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 472: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 473: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 474: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 475: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 476: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 477: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 478: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 479: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 480: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 481: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 482: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 483: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 484: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 485: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 486: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 487: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 488: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 489: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 490: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 491: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 492: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 493: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 494: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 495: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 496: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 497: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 498: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 499: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 500: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 501: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 502: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 503: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 504: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 505: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 506: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 507: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 508: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 509: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 510: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 511: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 512: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 513: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 514: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 515: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 516: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 517: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 518: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 519: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 520: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 521: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 522: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 523: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 524: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 525: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 526: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 527: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 528: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 529: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 530: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 531: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 532: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 533: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 534: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 535: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 536: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 537: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 538: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 539: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 540: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 541: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 542: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 543: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 544: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 545: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 546: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 547: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 548: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 549: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 550: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 551: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 552: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 553: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 554: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 555: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 556: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 557: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 558: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 559: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 560: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 561: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 562: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 563: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 564: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 565: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 566: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 567: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 568: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 569: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 570: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 571: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 572: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 573: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 574: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 575: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 576: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 577: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 578: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 579: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 580: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 581: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 582: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 583: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 584: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 585: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 586: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 587: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 588: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 589: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 590: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 591: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 592: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 593: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 594: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 595: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 596: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 597: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 598: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 599: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 600: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 601: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 602: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 603: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 604: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 605: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 606: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 607: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 608: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 609: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 610: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 611: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 612: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 613: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 614: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 615: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 616: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 617: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 618: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 619: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 620: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 621: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 622: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 623: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 624: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 625: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 626: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 627: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 628: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 629: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 630: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 631: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 632: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 633: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 634: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 635: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 636: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 637: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 638: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 639: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 640: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 641: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 642: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 643: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 644: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 645: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 646: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 647: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 648: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 649: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 650: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 651: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 652: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 653: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 654: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 655: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 656: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 657: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 658: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 659: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 660: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 661: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 662: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 663: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 664: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 665: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 666: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 667: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 668: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 669: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 670: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 671: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 672: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 673: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 674: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 675: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 676: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 677: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 678: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 679: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 680: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 681: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 682: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 683: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 684: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 685: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 686: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 687: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 688: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 689: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 690: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 691: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 692: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 693: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 694: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 695: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 696: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 697: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 698: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 699: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 700: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 701: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 702: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 703: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 704: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 705: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 706: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 707: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 708: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 709: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 710: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 711: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 712: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 713: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 714: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 715: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 716: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 717: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 718: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 719: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 720: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 721: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 722: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 723: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 724: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 725: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 726: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 727: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 728: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 729: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 730: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 731: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 732: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 733: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 734: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 735: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 736: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 737: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 738: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 739: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 740: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 741: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 742: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 743: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 744: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 745: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 746: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 747: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 748: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 749: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 750: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 751: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 752: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 753: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 754: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 755: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 756: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 757: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 758: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 759: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 760: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 761: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 762: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 763: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 764: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 765: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 766: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 767: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 768: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 769: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 770: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 771: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 772: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 773: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 774: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 775: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 776: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 777: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 778: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 779: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 780: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 781: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 782: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 783: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 784: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 785: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 786: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 787: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 788: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 789: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 790: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 791: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 792: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 793: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 794: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 795: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 796: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 797: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 798: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 799: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 800: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 801: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 802: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 803: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 804: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 805: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 806: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 807: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 808: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 809: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 810: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 811: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 812: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 813: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 814: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 815: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 816: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 817: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 818: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 819: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 820: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 821: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 822: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 823: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 824: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 825: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 826: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 827: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 828: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 829: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 830: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 831: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 832: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 833: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 834: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 835: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 836: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 837: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 838: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 839: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 840: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 841: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 842: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 843: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 844: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 845: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 846: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 847: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 848: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 849: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 850: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 851: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 852: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 853: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 854: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 855: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 856: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 857: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 858: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 859: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 860: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 861: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 862: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 863: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 864: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 865: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 866: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 867: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 868: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 869: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 870: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 871: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 872: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 873: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 874: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 875: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 876: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 877: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 878: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 879: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 880: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 881: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 882: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 883: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 884: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 885: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 886: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 887: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 888: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 889: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 890: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 891: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 892: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 893: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 894: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 895: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 896: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 897: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 898: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 899: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 900: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 901: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 902: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 903: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 904: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 905: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 906: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 907: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 908: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 909: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 910: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 911: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 912: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 913: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 914: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 915: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 916: True Label: Healthy, Predicted: Epileptic\n",
            "Test Segment 917: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 918: True Label: Epileptic, Predicted: Epileptic\n",
            "Test Segment 919: True Label: Epileptic, Predicted: Epileptic\n"
          ]
        }
      ],
      "source": [
        "#LAMSTAR\n",
        "import numpy as np\n",
        "import pywt\n",
        "from scipy.signal import medfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def wavelet_denoising(signal, wavelet='db1', level=2):\n",
        "    \"\"\"\n",
        "    Perform wavelet denoising on a 1D signal.\n",
        "    :param signal: 1D numpy array of the signal\n",
        "    :param wavelet: Type of wavelet to use\n",
        "    :param level: Decomposition level\n",
        "    :return: Denoised signal\n",
        "    \"\"\"\n",
        "    if len(signal) < 2 ** level:\n",
        "        return signal\n",
        "    coeffs = pywt.wavedec(signal, wavelet, mode='symmetric', level=level)\n",
        "    threshold = np.sqrt(2 * np.log(len(signal)))\n",
        "    denoised_coeffs = [pywt.threshold(c, threshold, mode='soft') for c in coeffs]\n",
        "    return pywt.waverec(denoised_coeffs, wavelet, mode='symmetric')\n",
        "\n",
        "\n",
        "def median_filter(signal, kernel_size=3):\n",
        "    \"\"\"\n",
        "    Apply median filtering to reduce noise.\n",
        "    :param signal: 1D numpy array of the signal\n",
        "    :param kernel_size: Kernel size for the filter\n",
        "    :return: Filtered signal\n",
        "    \"\"\"\n",
        "    if len(signal) < kernel_size:\n",
        "        return signal\n",
        "    return medfilt(signal, kernel_size=kernel_size)\n",
        "\n",
        "\n",
        "def preprocess_data(input_data):\n",
        "    \"\"\"\n",
        "    Preprocess the data by applying denoising techniques.\n",
        "    :param input_data: 2D numpy array where each row represents a signal [subword1, subword2]\n",
        "    :return: Preprocessed data\n",
        "    \"\"\"\n",
        "    denoised_data = []\n",
        "    for row in input_data:\n",
        "        subword1 = np.array([row[0]])\n",
        "        subword2 = np.array([row[1]])\n",
        "        subword1 = wavelet_denoising(subword1)\n",
        "        subword2 = wavelet_denoising(subword2)\n",
        "        subword1 = median_filter(subword1) if len(subword1) >= 3 else subword1\n",
        "        subword2 = median_filter(subword2) if len(subword2) >= 3 else subword2\n",
        "        denoised_data.append([subword1[0] if len(subword1) > 0 else row[0],\n",
        "                              subword2[0] if len(subword2) > 0 else row[1]])\n",
        "    return np.array(denoised_data)\n",
        "\n",
        "\n",
        "class SOM:\n",
        "    def __init__(self, input_dim, num_neurons, learning_rate=0.5):\n",
        "        self.input_dim = input_dim\n",
        "        self.num_neurons = num_neurons\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.random.rand(num_neurons, input_dim)\n",
        "        self.weights = self.weights / np.linalg.norm(self.weights, axis=1, keepdims=True)\n",
        "\n",
        "    def train(self, input_data, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point in input_data:\n",
        "                distances = np.linalg.norm(self.weights - data_point, axis=1)\n",
        "                winner_index = np.argmin(distances)\n",
        "                self.weights[winner_index] += self.learning_rate * (data_point - self.weights[winner_index])\n",
        "                self.weights[winner_index] /= np.linalg.norm(self.weights[winner_index])\n",
        "    def get_winner(self, input_vector):\n",
        "        distances = np.linalg.norm(self.weights - input_vector, axis=1)\n",
        "        return np.argmin(distances)\n",
        "\n",
        "\n",
        "class LAMSTAR:\n",
        "    def __init__(self, input_dim, subword_dims, num_neurons_per_som, num_output_neurons):\n",
        "        self.soms = [SOM(dim, num_neurons_per_som) for dim in subword_dims]\n",
        "        self.output_weights = np.random.rand(num_output_neurons, len(self.soms))\n",
        "        self.output_weights /= np.linalg.norm(self.output_weights, axis=1, keepdims=True)\n",
        "        self.learning_rate = 0.1\n",
        "    def train(self, input_data, labels, epochs=2000):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point, label in zip(input_data, labels):\n",
        "                winners = [som.get_winner([data_point[i]]) for i, som in enumerate(self.soms)]\n",
        "                activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "                predicted_label = np.argmax(activations)\n",
        "                if predicted_label == label:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                else:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                    self.output_weights[predicted_label, winners] -= self.learning_rate\n",
        "    def predict(self, input_data):\n",
        "        predictions = []\n",
        "        for data_point in input_data:\n",
        "            winners = [som.get_winner([data_point[i]]) for i, som in enumerate(self.soms)]\n",
        "            activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "            predictions.append(np.argmax(activations))\n",
        "        return predictions\n",
        "\n",
        "\n",
        "lamstar_input = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            subword1, subword2 = map(float, subwords.split(';'))\n",
        "            lamstar_input.append([subword1, subword2])\n",
        "            labels.append(1 if \"S\" in segment else 0)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "lamstar_input = np.array(lamstar_input)\n",
        "labels = np.array(labels)\n",
        "\n",
        "lamstar_input = preprocess_data(lamstar_input)\n",
        "X_train, X_test, y_train, y_test = train_test_split(lamstar_input, labels, test_size=0.2, random_state=42)\n",
        "lamstar = LAMSTAR(input_dim=2, subword_dims=[1, 1], num_neurons_per_som=10, num_output_neurons=2)\n",
        "lamstar.train(X_train, y_train, epochs=2000)\n",
        "predictions = lamstar.predict(X_test)\n",
        "for i, (true_label, prediction) in enumerate(zip(y_test, predictions)):\n",
        "    print(f\"Test Segment {i}: True Label: {'Epileptic' if true_label == 1 else 'Healthy'}, Predicted: {'Epileptic' if prediction == 1 else 'Healthy'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZtERVEMNwKB",
        "outputId": "812b81bd-0eec-45d4-8953-63e857138f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.48\n",
            "Confusion Matrix:\n",
            "[[  0 475]\n",
            " [  0 445]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.00      0.00      0.00       475\n",
            "   Epileptic       0.48      1.00      0.65       445\n",
            "\n",
            "    accuracy                           0.48       920\n",
            "   macro avg       0.24      0.50      0.33       920\n",
            "weighted avg       0.23      0.48      0.32       920\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "classification_report_str = classification_report(y_test, predictions, target_names=[\"Healthy\", \"Epileptic\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUT_T7_CO5Hv",
        "outputId": "b2650fa5-7786-49cc-a439-472ed357dc9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LAMSTAR Model Accuracy: 0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 7.6286 - val_accuracy: 0.5978 - val_loss: 0.9744\n",
            "Epoch 2/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5824 - loss: 1.3151 - val_accuracy: 0.5924 - val_loss: 1.3714\n",
            "Epoch 3/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 1.3016 - val_accuracy: 0.5978 - val_loss: 0.8656\n",
            "Epoch 4/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5731 - loss: 1.6509 - val_accuracy: 0.5978 - val_loss: 1.0888\n",
            "Epoch 5/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5846 - loss: 1.1429 - val_accuracy: 0.5978 - val_loss: 0.7402\n",
            "Epoch 6/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 1.6022 - val_accuracy: 0.5978 - val_loss: 0.7648\n",
            "Epoch 7/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5761 - loss: 1.1166 - val_accuracy: 0.5978 - val_loss: 0.7031\n",
            "Epoch 8/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5801 - loss: 1.4885 - val_accuracy: 0.5978 - val_loss: 0.6811\n",
            "Epoch 9/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5821 - loss: 0.9267 - val_accuracy: 0.5842 - val_loss: 0.6593\n",
            "Epoch 10/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5896 - loss: 1.2772 - val_accuracy: 0.5978 - val_loss: 0.8900\n",
            "Epoch 11/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5804 - loss: 1.3169 - val_accuracy: 0.5924 - val_loss: 1.4145\n",
            "Epoch 12/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 1.5768 - val_accuracy: 0.5978 - val_loss: 0.6662\n",
            "Epoch 13/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 1.0802 - val_accuracy: 0.5978 - val_loss: 0.6967\n",
            "Epoch 14/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5805 - loss: 1.1680 - val_accuracy: 0.5978 - val_loss: 0.6716\n",
            "Epoch 15/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5877 - loss: 1.2631 - val_accuracy: 0.5978 - val_loss: 1.2436\n",
            "Epoch 16/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 1.7489 - val_accuracy: 0.5978 - val_loss: 0.7196\n",
            "Epoch 17/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5913 - loss: 0.8408 - val_accuracy: 0.5978 - val_loss: 0.7180\n",
            "Epoch 18/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 1.0200 - val_accuracy: 0.5978 - val_loss: 0.8106\n",
            "Epoch 19/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5706 - loss: 1.0112 - val_accuracy: 0.5978 - val_loss: 0.7523\n",
            "Epoch 20/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 1.0522 - val_accuracy: 0.5842 - val_loss: 0.6728\n",
            "Epoch 21/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5763 - loss: 0.8097 - val_accuracy: 0.5978 - val_loss: 0.6838\n",
            "Epoch 22/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5852 - loss: 0.8561 - val_accuracy: 0.5978 - val_loss: 0.7464\n",
            "Epoch 23/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 1.1306 - val_accuracy: 0.5978 - val_loss: 0.6702\n",
            "Epoch 24/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5796 - loss: 1.0234 - val_accuracy: 0.5978 - val_loss: 0.7915\n",
            "Epoch 25/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5894 - loss: 1.0832 - val_accuracy: 0.5163 - val_loss: 0.9367\n",
            "Epoch 26/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5421 - loss: 1.2191 - val_accuracy: 0.5978 - val_loss: 0.6768\n",
            "Epoch 27/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5902 - loss: 0.8809 - val_accuracy: 0.5924 - val_loss: 0.8360\n",
            "Epoch 28/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.7681 - val_accuracy: 0.5978 - val_loss: 0.7395\n",
            "Epoch 29/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5784 - loss: 0.9769 - val_accuracy: 0.5978 - val_loss: 0.6557\n",
            "Epoch 30/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5618 - loss: 0.9738 - val_accuracy: 0.5978 - val_loss: 0.6620\n",
            "Epoch 31/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5647 - loss: 0.9398 - val_accuracy: 0.5978 - val_loss: 0.6691\n",
            "Epoch 32/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 0.7691 - val_accuracy: 0.5978 - val_loss: 0.6556\n",
            "Epoch 33/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.7516 - val_accuracy: 0.5978 - val_loss: 0.7948\n",
            "Epoch 34/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5866 - loss: 0.9543 - val_accuracy: 0.5978 - val_loss: 0.8039\n",
            "Epoch 35/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 0.8950 - val_accuracy: 0.5978 - val_loss: 0.7751\n",
            "Epoch 36/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5597 - loss: 0.8688 - val_accuracy: 0.5842 - val_loss: 0.6712\n",
            "Epoch 37/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5700 - loss: 0.7944 - val_accuracy: 0.5842 - val_loss: 0.6658\n",
            "Epoch 38/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5820 - loss: 0.9859 - val_accuracy: 0.5842 - val_loss: 0.6622\n",
            "Epoch 39/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5650 - loss: 0.7700 - val_accuracy: 0.5978 - val_loss: 0.6789\n",
            "Epoch 40/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 0.9846 - val_accuracy: 0.5978 - val_loss: 0.7554\n",
            "Epoch 41/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.7329 - val_accuracy: 0.5924 - val_loss: 1.0383\n",
            "Epoch 42/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5492 - loss: 1.1113 - val_accuracy: 0.5978 - val_loss: 0.7585\n",
            "Epoch 43/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 0.8169 - val_accuracy: 0.5163 - val_loss: 1.4209\n",
            "Epoch 44/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5686 - loss: 1.1962 - val_accuracy: 0.5978 - val_loss: 0.6569\n",
            "Epoch 45/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.7423 - val_accuracy: 0.5978 - val_loss: 0.7843\n",
            "Epoch 46/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5751 - loss: 0.7656 - val_accuracy: 0.5978 - val_loss: 0.6786\n",
            "Epoch 47/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5802 - loss: 0.7564 - val_accuracy: 0.5978 - val_loss: 0.6572\n",
            "Epoch 48/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5772 - loss: 0.9717 - val_accuracy: 0.5978 - val_loss: 0.6595\n",
            "Epoch 49/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5909 - loss: 0.7310 - val_accuracy: 0.5978 - val_loss: 0.6740\n",
            "Epoch 50/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5856 - loss: 0.8849 - val_accuracy: 0.5978 - val_loss: 0.6562\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Deep Learning Model Accuracy: 0.61\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pywt\n",
        "from scipy.signal import medfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def wavelet_denoising(signal, wavelet='db1', level=2):\n",
        "    if len(signal) < 2 ** level:\n",
        "        return signal\n",
        "    coeffs = pywt.wavedec(signal, wavelet, mode='symmetric', level=level)\n",
        "    threshold = np.sqrt(2 * np.log(len(signal)))\n",
        "    denoised_coeffs = [pywt.threshold(c, threshold, mode='soft') for c in coeffs]\n",
        "    return pywt.waverec(denoised_coeffs, wavelet, mode='symmetric')\n",
        "\n",
        "def median_filter(signal, kernel_size=3):\n",
        "    if len(signal) < kernel_size:\n",
        "        return signal\n",
        "    return medfilt(signal, kernel_size=kernel_size)\n",
        "\n",
        "def preprocess_data(input_data):\n",
        "    \"\"\"\n",
        "    Preprocess the data by applying denoising techniques.\n",
        "    \"\"\"\n",
        "    denoised_data = []\n",
        "    for row in input_data:\n",
        "        subword1 = np.array([row[0]])\n",
        "        subword2 = np.array([row[1]])\n",
        "\n",
        "        subword1 = wavelet_denoising(subword1)\n",
        "        subword2 = wavelet_denoising(subword2)\n",
        "\n",
        "        subword1 = median_filter(subword1) if len(subword1) >= 3 else subword1\n",
        "        subword2 = median_filter(subword2) if len(subword2) >= 3 else subword2\n",
        "\n",
        "        denoised_data.append([subword1[0] if len(subword1) > 0 else row[0],\n",
        "                              subword2[0] if len(subword2) > 0 else row[1]])\n",
        "\n",
        "    return np.array(denoised_data)\n",
        "\n",
        "\n",
        "class SOM:\n",
        "    def __init__(self, input_dim, num_neurons, learning_rate=0.5):\n",
        "        self.input_dim = input_dim\n",
        "        self.num_neurons = num_neurons\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.random.rand(num_neurons, input_dim)\n",
        "        self.weights /= np.linalg.norm(self.weights, axis=1, keepdims=True)\n",
        "    def train(self, input_data, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point in input_data:\n",
        "                distances = np.linalg.norm(self.weights - data_point, axis=1)\n",
        "                winner_index = np.argmin(distances)\n",
        "                self.weights[winner_index] += self.learning_rate * (data_point - self.weights[winner_index])\n",
        "                self.weights[winner_index] /= np.linalg.norm(self.weights[winner_index])\n",
        "    def get_winner(self, input_vector):\n",
        "        distances = np.linalg.norm(self.weights - input_vector, axis=1)\n",
        "        return np.argmin(distances)\n",
        "\n",
        "\n",
        "class MultiLayerLAMSTAR:\n",
        "    def __init__(self, input_dim, subword_dims, layers, num_neurons_per_layer, num_output_neurons):\n",
        "        self.layers = [\n",
        "            [SOM(dim, num_neurons_per_layer) for dim in subword_dims]\n",
        "            for _ in range(layers)\n",
        "        ]\n",
        "        self.output_weights = np.random.rand(num_output_neurons, len(subword_dims) * layers)\n",
        "        self.output_weights /= np.linalg.norm(self.output_weights, axis=1, keepdims=True)\n",
        "        self.learning_rate = 0.1\n",
        "\n",
        "    def train(self, input_data, labels, epochs=2000):\n",
        "        for epoch in range(epochs):\n",
        "            for data_point, label in zip(input_data, labels):\n",
        "                winners = []\n",
        "                for layer in self.layers:\n",
        "                    for i, som in enumerate(layer):\n",
        "                        winner = som.get_winner([data_point[i]])\n",
        "                        winners.append(winner)\n",
        "\n",
        "                activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "                predicted_label = np.argmax(activations)\n",
        "\n",
        "                if predicted_label == label:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                else:\n",
        "                    self.output_weights[label, winners] += self.learning_rate\n",
        "                    self.output_weights[predicted_label, winners] -= self.learning_rate\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        predictions = []\n",
        "        for data_point in input_data:\n",
        "            winners = []\n",
        "            for layer in self.layers:\n",
        "                for i, som in enumerate(layer):\n",
        "                    winner = som.get_winner([data_point[i]])\n",
        "                    winners.append(winner)\n",
        "\n",
        "            activations = np.sum(self.output_weights[:, winners], axis=1)\n",
        "            predictions.append(np.argmax(activations))\n",
        "        return predictions\n",
        "\n",
        "\n",
        "\n",
        "def build_and_train_nn(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Build and train a deep learning model for comparison.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(32, input_dim=X_train.shape[1], activation='relu'),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1, validation_split=0.2)\n",
        "    predictions = (model.predict(X_test) > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f\"Deep Learning Model Accuracy: {accuracy:.2f}\")\n",
        "    return model\n",
        "\n",
        "lamstar_input = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            subword1, subword2 = map(float, subwords.split(';'))\n",
        "            lamstar_input.append([subword1, subword2])\n",
        "            labels.append(1 if \"S\" in segment else 0)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "lamstar_input = np.array(lamstar_input)\n",
        "labels = np.array(labels)\n",
        "lamstar_input = preprocess_data(lamstar_input)\n",
        "X_train, X_test, y_train, y_test = train_test_split(lamstar_input, labels, test_size=0.2, random_state=42)\n",
        "lamstar = MultiLayerLAMSTAR(input_dim=2, subword_dims=[1, 1], layers=2, num_neurons_per_layer=10, num_output_neurons=2)\n",
        "lamstar.train(X_train, y_train, epochs=2000)\n",
        "lamstar_predictions = lamstar.predict(X_test)\n",
        "lamstar_accuracy = accuracy_score(y_test, lamstar_predictions)\n",
        "print(f\"LAMSTAR Model Accuracy: {lamstar_accuracy:.2f}\")\n",
        "nn_model = build_and_train_nn(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdbt8dxKR69F",
        "outputId": "6cab9219-a52f-482c-d301-48a9b1b50016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performance Metrics for LAMSTAR:\n",
            "----------------------------------------\n",
            "Accuracy:  0.48\n",
            "Precision: 0.48\n",
            "Recall:    1.00\n",
            "F1 Score:  0.65\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  0 475]\n",
            " [  0 445]]\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Performance Metrics for Deep Learning:\n",
            "----------------------------------------\n",
            "Accuracy:  0.61\n",
            "Precision: 0.56\n",
            "Recall:    0.88\n",
            "F1 Score:  0.69\n",
            "\n",
            "Confusion Matrix:\n",
            "[[172 303]\n",
            " [ 53 392]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "def evaluate_model_performance(model_name, y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluate and print the performance metrics for a given model.\n",
        "    :param model_name: Name of the model (e.g., \"LAMSTAR\", \"Deep Learning\")\n",
        "    :param y_true: Ground truth labels\n",
        "    :param y_pred: Predicted labels\n",
        "    \"\"\"\n",
        "    print(f\"\\nPerformance Metrics for {model_name}:\")\n",
        "    print(\"-\" * 40)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"Accuracy:  {accuracy:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall:    {recall:.2f}\")\n",
        "    print(f\"F1 Score:  {f1:.2f}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "evaluate_model_performance(\"LAMSTAR\", y_test, lamstar_predictions)\n",
        "nn_predictions = (nn_model.predict(X_test) > 0.5).astype(int).flatten()\n",
        "evaluate_model_performance(\"Deep Learning\", y_test, nn_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxOcGlRFdqBF",
        "outputId": "0f356344-3dd9-450f-831f-fc722e61450f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5759 - loss: 0.6765 - val_accuracy: 0.5584 - val_loss: 0.6779\n",
            "Epoch 2/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5975 - loss: 0.6599 - val_accuracy: 0.5584 - val_loss: 0.6813\n",
            "Epoch 3/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5995 - loss: 0.6615 - val_accuracy: 0.5584 - val_loss: 0.6836\n",
            "Epoch 4/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5900 - loss: 0.6625 - val_accuracy: 0.5584 - val_loss: 0.6820\n",
            "Epoch 5/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5932 - loss: 0.6754 - val_accuracy: 0.5584 - val_loss: 0.6971\n",
            "Epoch 6/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6079 - loss: 0.6594 - val_accuracy: 0.5584 - val_loss: 0.6843\n",
            "Epoch 7/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6164 - loss: 0.6553 - val_accuracy: 0.5584 - val_loss: 0.6867\n",
            "Epoch 8/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5966 - loss: 0.6608 - val_accuracy: 0.5584 - val_loss: 0.6872\n",
            "Epoch 9/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6174 - loss: 0.6525 - val_accuracy: 0.5584 - val_loss: 0.6847\n",
            "Epoch 10/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6188 - loss: 0.6602 - val_accuracy: 0.5584 - val_loss: 0.6895\n",
            "Epoch 11/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6107 - loss: 0.6583 - val_accuracy: 0.5584 - val_loss: 0.6787\n",
            "Epoch 12/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6221 - loss: 0.6516 - val_accuracy: 0.5584 - val_loss: 0.6798\n",
            "Epoch 13/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6125 - loss: 0.6551 - val_accuracy: 0.5584 - val_loss: 0.6800\n",
            "Epoch 14/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6226 - loss: 0.6539 - val_accuracy: 0.5584 - val_loss: 0.6758\n",
            "Epoch 15/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6019 - loss: 0.6540 - val_accuracy: 0.5584 - val_loss: 0.6837\n",
            "Epoch 16/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6208 - loss: 0.6516 - val_accuracy: 0.5584 - val_loss: 0.6775\n",
            "Epoch 17/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6168 - loss: 0.6496 - val_accuracy: 0.5584 - val_loss: 0.6803\n",
            "Epoch 18/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6167 - loss: 0.6524 - val_accuracy: 0.5584 - val_loss: 0.6782\n",
            "Epoch 19/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6165 - loss: 0.6517 - val_accuracy: 0.5584 - val_loss: 0.6818\n",
            "Epoch 20/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5989 - loss: 0.6571 - val_accuracy: 0.5584 - val_loss: 0.6828\n",
            "Epoch 21/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6093 - loss: 0.6561 - val_accuracy: 0.5584 - val_loss: 0.6828\n",
            "Epoch 22/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6132 - loss: 0.6556 - val_accuracy: 0.5584 - val_loss: 0.6869\n",
            "Epoch 23/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 0.6592 - val_accuracy: 0.5584 - val_loss: 0.6832\n",
            "Epoch 24/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6211 - loss: 0.6497 - val_accuracy: 0.5584 - val_loss: 0.6788\n",
            "Epoch 25/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6094 - loss: 0.6588 - val_accuracy: 0.5584 - val_loss: 0.6935\n",
            "Epoch 26/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5953 - loss: 0.6666 - val_accuracy: 0.5584 - val_loss: 0.6971\n",
            "Epoch 27/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6103 - loss: 0.6581 - val_accuracy: 0.5584 - val_loss: 0.6832\n",
            "Epoch 28/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6039 - loss: 0.6577 - val_accuracy: 0.5584 - val_loss: 0.6822\n",
            "Epoch 29/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5983 - loss: 0.6665 - val_accuracy: 0.5584 - val_loss: 0.6856\n",
            "Epoch 30/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6169 - loss: 0.6541 - val_accuracy: 0.5584 - val_loss: 0.6807\n",
            "Epoch 31/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6223 - loss: 0.6545 - val_accuracy: 0.5584 - val_loss: 0.6873\n",
            "Epoch 32/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6198 - loss: 0.6531 - val_accuracy: 0.5584 - val_loss: 0.6833\n",
            "Epoch 33/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6095 - loss: 0.6541 - val_accuracy: 0.5584 - val_loss: 0.6864\n",
            "Epoch 34/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6023 - loss: 0.6606 - val_accuracy: 0.5584 - val_loss: 0.6801\n",
            "Epoch 35/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6141 - loss: 0.6532 - val_accuracy: 0.5584 - val_loss: 0.6785\n",
            "Epoch 36/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6138 - loss: 0.6556 - val_accuracy: 0.5584 - val_loss: 0.6868\n",
            "Epoch 37/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6080 - loss: 0.6518 - val_accuracy: 0.5584 - val_loss: 0.6816\n",
            "Epoch 38/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6146 - loss: 0.6502 - val_accuracy: 0.5584 - val_loss: 0.6774\n",
            "Epoch 39/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6080 - loss: 0.6581 - val_accuracy: 0.5584 - val_loss: 0.6925\n",
            "Epoch 40/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6289 - loss: 0.6498 - val_accuracy: 0.5584 - val_loss: 0.6767\n",
            "Epoch 41/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6107 - loss: 0.6572 - val_accuracy: 0.5761 - val_loss: 0.6791\n",
            "Epoch 42/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6091 - loss: 0.6524 - val_accuracy: 0.5584 - val_loss: 0.6765\n",
            "Epoch 43/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6131 - loss: 0.6582 - val_accuracy: 0.5584 - val_loss: 0.6806\n",
            "Epoch 44/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5981 - loss: 0.6611 - val_accuracy: 0.5584 - val_loss: 0.6866\n",
            "Epoch 45/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6161 - loss: 0.6495 - val_accuracy: 0.5584 - val_loss: 0.6863\n",
            "Epoch 46/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6038 - loss: 0.6547 - val_accuracy: 0.5584 - val_loss: 0.6813\n",
            "Epoch 47/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6053 - loss: 0.6585 - val_accuracy: 0.5584 - val_loss: 0.6849\n",
            "Epoch 48/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6134 - loss: 0.6540 - val_accuracy: 0.5584 - val_loss: 0.6876\n",
            "Epoch 49/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6101 - loss: 0.6602 - val_accuracy: 0.5584 - val_loss: 0.6841\n",
            "Epoch 50/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6218 - loss: 0.6522 - val_accuracy: 0.5584 - val_loss: 0.6864\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "RNN Model Accuracy: 0.60\n"
          ]
        }
      ],
      "source": [
        "#RNN 50 epochs\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def preprocess_lstm_data(input_data, labels):\n",
        "    #convert subword sequences into numerical arrays\n",
        "    sequences = []\n",
        "    for row in input_data:\n",
        "        subwords = [float(x) for x in row.split(';')]\n",
        "        sequences.append(subwords)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    return np.array(sequences), labels, label_encoder\n",
        "\n",
        "input_data = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            input_data.append(subwords)\n",
        "            labels.append(label)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "input_data, labels, label_encoder = preprocess_lstm_data(input_data, labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "#LSTM model\n",
        "def build_rnn(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "#train the RNN model\n",
        "rnn_model = build_rnn((X_train.shape[1], X_train.shape[2]))\n",
        "rnn_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "y_pred = (rnn_model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"RNN Model Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "9nBCLDcVeX2M",
        "outputId": "c4732f8d-5be4-45fb-fa4d-e7c52fa6eb3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   epileptic       0.58      0.87      0.69       475\n",
            "     healthy       0.70      0.32      0.44       445\n",
            "\n",
            "    accuracy                           0.60       920\n",
            "   macro avg       0.64      0.59      0.57       920\n",
            "weighted avg       0.63      0.60      0.57       920\n",
            "\n",
            "Accuracy: 0.60\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred = (rnn_model.predict(X_test) > 0.5).astype(int).flatten()\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6v7fVOQeeEv",
        "outputId": "b752dd2d-7cbc-4950-a290-423bbe43e764"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.5356 - loss: 0.6845 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 2/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6103 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 3/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6141 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 4/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5959 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6579\n",
            "Epoch 5/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6073 - loss: 0.6673 - val_accuracy: 0.5910 - val_loss: 0.6587\n",
            "Epoch 6/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5660 - loss: 0.6754 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 7/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5965 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 8/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6013 - loss: 0.6634 - val_accuracy: 0.5910 - val_loss: 0.6602\n",
            "Epoch 9/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5962 - loss: 0.6630 - val_accuracy: 0.5910 - val_loss: 0.6593\n",
            "Epoch 10/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5987 - loss: 0.6620 - val_accuracy: 0.5910 - val_loss: 0.6579\n",
            "Epoch 11/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5915 - loss: 0.6649 - val_accuracy: 0.6114 - val_loss: 0.6583\n",
            "Epoch 12/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5941 - loss: 0.6617 - val_accuracy: 0.5910 - val_loss: 0.6586\n",
            "Epoch 13/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6018 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 14/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5797 - loss: 0.6650 - val_accuracy: 0.5910 - val_loss: 0.6627\n",
            "Epoch 15/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 0.6617 - val_accuracy: 0.5910 - val_loss: 0.6622\n",
            "Epoch 16/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6142 - loss: 0.6538 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 17/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6000 - loss: 0.6656 - val_accuracy: 0.6114 - val_loss: 0.6581\n",
            "Epoch 18/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6057 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6720\n",
            "Epoch 19/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5974 - loss: 0.6653 - val_accuracy: 0.5910 - val_loss: 0.6584\n",
            "Epoch 20/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5944 - loss: 0.6622 - val_accuracy: 0.5910 - val_loss: 0.6611\n",
            "Epoch 21/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5920 - loss: 0.6609 - val_accuracy: 0.5910 - val_loss: 0.6602\n",
            "Epoch 22/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6017 - loss: 0.6601 - val_accuracy: 0.5910 - val_loss: 0.6592\n",
            "Epoch 23/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 0.6630 - val_accuracy: 0.5910 - val_loss: 0.6599\n",
            "Epoch 24/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5971 - loss: 0.6664 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 25/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5981 - loss: 0.6623 - val_accuracy: 0.5910 - val_loss: 0.6591\n",
            "Epoch 26/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5945 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6626\n",
            "Epoch 27/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5927 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 28/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6052 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6667\n",
            "Epoch 29/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6055 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 30/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6050 - loss: 0.6575 - val_accuracy: 0.5910 - val_loss: 0.6640\n",
            "Epoch 31/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6061 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6580\n",
            "Epoch 32/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5792 - loss: 0.6668 - val_accuracy: 0.6114 - val_loss: 0.6581\n",
            "Epoch 33/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5965 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 34/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5947 - loss: 0.6595 - val_accuracy: 0.5910 - val_loss: 0.6601\n",
            "Epoch 35/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6007 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 36/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5876 - loss: 0.6681 - val_accuracy: 0.5910 - val_loss: 0.6596\n",
            "Epoch 37/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6059 - loss: 0.6544 - val_accuracy: 0.5910 - val_loss: 0.6646\n",
            "Epoch 38/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5845 - loss: 0.6701 - val_accuracy: 0.6114 - val_loss: 0.6648\n",
            "Epoch 39/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6017 - loss: 0.6629 - val_accuracy: 0.5910 - val_loss: 0.6660\n",
            "Epoch 40/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6107 - loss: 0.6527 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 41/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6032 - loss: 0.6595 - val_accuracy: 0.5910 - val_loss: 0.6595\n",
            "Epoch 42/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5961 - loss: 0.6640 - val_accuracy: 0.5910 - val_loss: 0.6707\n",
            "Epoch 43/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5906 - loss: 0.6675 - val_accuracy: 0.5910 - val_loss: 0.6634\n",
            "Epoch 44/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5903 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6590\n",
            "Epoch 45/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6103 - loss: 0.6565 - val_accuracy: 0.5910 - val_loss: 0.6646\n",
            "Epoch 46/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6036 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6622\n",
            "Epoch 47/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5855 - loss: 0.6632 - val_accuracy: 0.5910 - val_loss: 0.6581\n",
            "Epoch 48/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6245 - loss: 0.6555 - val_accuracy: 0.5910 - val_loss: 0.6584\n",
            "Epoch 49/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5934 - loss: 0.6721 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 50/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5832 - loss: 0.6670 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 51/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5854 - loss: 0.6665 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 52/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5889 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 53/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5936 - loss: 0.6679 - val_accuracy: 0.5910 - val_loss: 0.6630\n",
            "Epoch 54/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6127 - loss: 0.6560 - val_accuracy: 0.5910 - val_loss: 0.6633\n",
            "Epoch 55/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5793 - loss: 0.6730 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 56/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5885 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6579\n",
            "Epoch 57/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6134 - loss: 0.6563 - val_accuracy: 0.5910 - val_loss: 0.6582\n",
            "Epoch 58/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5878 - loss: 0.6706 - val_accuracy: 0.5910 - val_loss: 0.6600\n",
            "Epoch 59/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5888 - loss: 0.6644 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 60/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5790 - loss: 0.6712 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 61/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6119 - loss: 0.6563 - val_accuracy: 0.5910 - val_loss: 0.6617\n",
            "Epoch 62/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5919 - loss: 0.6611 - val_accuracy: 0.5910 - val_loss: 0.6597\n",
            "Epoch 63/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6003 - loss: 0.6600 - val_accuracy: 0.5910 - val_loss: 0.6613\n",
            "Epoch 64/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5858 - loss: 0.6703 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 65/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5955 - loss: 0.6666 - val_accuracy: 0.6114 - val_loss: 0.6592\n",
            "Epoch 66/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5988 - loss: 0.6592 - val_accuracy: 0.5910 - val_loss: 0.6600\n",
            "Epoch 67/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5799 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6586\n",
            "Epoch 68/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5939 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 69/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5964 - loss: 0.6620 - val_accuracy: 0.5910 - val_loss: 0.6590\n",
            "Epoch 70/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5983 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 71/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6219 - loss: 0.6544 - val_accuracy: 0.5910 - val_loss: 0.6674\n",
            "Epoch 72/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6170 - loss: 0.6540 - val_accuracy: 0.5910 - val_loss: 0.6652\n",
            "Epoch 73/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5883 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6628\n",
            "Epoch 74/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6014 - loss: 0.6653 - val_accuracy: 0.5910 - val_loss: 0.6606\n",
            "Epoch 75/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6069 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6651\n",
            "Epoch 76/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6085 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 77/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5873 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6617\n",
            "Epoch 78/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5910 - loss: 0.6687 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 79/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5948 - loss: 0.6586 - val_accuracy: 0.5910 - val_loss: 0.6600\n",
            "Epoch 80/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6233 - loss: 0.6525 - val_accuracy: 0.5910 - val_loss: 0.6632\n",
            "Epoch 81/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6189 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 82/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5988 - loss: 0.6647 - val_accuracy: 0.5910 - val_loss: 0.6618\n",
            "Epoch 83/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5901 - loss: 0.6679 - val_accuracy: 0.6114 - val_loss: 0.6583\n",
            "Epoch 84/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6123 - loss: 0.6598 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 85/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5944 - loss: 0.6613 - val_accuracy: 0.5910 - val_loss: 0.6611\n",
            "Epoch 86/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5718 - loss: 0.6710 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 87/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5909 - loss: 0.6651 - val_accuracy: 0.5910 - val_loss: 0.6599\n",
            "Epoch 88/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6015 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 89/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5958 - loss: 0.6624 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 90/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5913 - loss: 0.6655 - val_accuracy: 0.5910 - val_loss: 0.6599\n",
            "Epoch 91/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5920 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 92/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6083 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6592\n",
            "Epoch 93/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5810 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 94/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6079 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6583\n",
            "Epoch 95/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5945 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6577\n",
            "Epoch 96/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6029 - loss: 0.6648 - val_accuracy: 0.6114 - val_loss: 0.6586\n",
            "Epoch 97/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6100 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6619\n",
            "Epoch 98/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6037 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6645\n",
            "Epoch 99/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5884 - loss: 0.6686 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 100/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6092 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 101/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6024 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6581\n",
            "Epoch 102/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5902 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6592\n",
            "Epoch 103/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5914 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 104/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6048 - loss: 0.6546 - val_accuracy: 0.5910 - val_loss: 0.6630\n",
            "Epoch 105/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6178 - loss: 0.6610 - val_accuracy: 0.5910 - val_loss: 0.6600\n",
            "Epoch 106/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6029 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 107/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5941 - loss: 0.6636 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 108/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5977 - loss: 0.6600 - val_accuracy: 0.5910 - val_loss: 0.6614\n",
            "Epoch 109/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5762 - loss: 0.6725 - val_accuracy: 0.5910 - val_loss: 0.6590\n",
            "Epoch 110/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5881 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 111/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6082 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6624\n",
            "Epoch 112/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6033 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 113/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6098 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6589\n",
            "Epoch 114/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6056 - loss: 0.6560 - val_accuracy: 0.5910 - val_loss: 0.6589\n",
            "Epoch 115/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6004 - loss: 0.6651 - val_accuracy: 0.6114 - val_loss: 0.6630\n",
            "Epoch 116/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6089 - loss: 0.6520 - val_accuracy: 0.6114 - val_loss: 0.6630\n",
            "Epoch 117/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6100 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6633\n",
            "Epoch 118/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6037 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6672\n",
            "Epoch 119/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6020 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 120/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5999 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6689\n",
            "Epoch 121/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5886 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 122/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5886 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 123/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 0.6593 - val_accuracy: 0.5910 - val_loss: 0.6624\n",
            "Epoch 124/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5807 - loss: 0.6661 - val_accuracy: 0.5910 - val_loss: 0.6626\n",
            "Epoch 125/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5892 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 126/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6032 - loss: 0.6657 - val_accuracy: 0.5910 - val_loss: 0.6580\n",
            "Epoch 127/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5927 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6574\n",
            "Epoch 128/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6632\n",
            "Epoch 129/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6051 - loss: 0.6635 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 130/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6046 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 131/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5957 - loss: 0.6677 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 132/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5987 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 133/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5999 - loss: 0.6606 - val_accuracy: 0.5910 - val_loss: 0.6606\n",
            "Epoch 134/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6016 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6667\n",
            "Epoch 135/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5933 - loss: 0.6660 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 136/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5832 - loss: 0.6647 - val_accuracy: 0.5910 - val_loss: 0.6587\n",
            "Epoch 137/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5882 - loss: 0.6641 - val_accuracy: 0.5910 - val_loss: 0.6615\n",
            "Epoch 138/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5946 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6621\n",
            "Epoch 139/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6216 - loss: 0.6536 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 140/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6153 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6615\n",
            "Epoch 141/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5983 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 142/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6005 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6636\n",
            "Epoch 143/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5857 - loss: 0.6742 - val_accuracy: 0.6114 - val_loss: 0.6589\n",
            "Epoch 144/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6073 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6624\n",
            "Epoch 145/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5904 - loss: 0.6669 - val_accuracy: 0.6114 - val_loss: 0.6576\n",
            "Epoch 146/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5857 - loss: 0.6730 - val_accuracy: 0.6114 - val_loss: 0.6574\n",
            "Epoch 147/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6198 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6625\n",
            "Epoch 148/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5899 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6579\n",
            "Epoch 149/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5968 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 150/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6138 - loss: 0.6641 - val_accuracy: 0.6114 - val_loss: 0.6573\n",
            "Epoch 151/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5869 - loss: 0.6666 - val_accuracy: 0.6114 - val_loss: 0.6627\n",
            "Epoch 152/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5974 - loss: 0.6662 - val_accuracy: 0.6114 - val_loss: 0.6622\n",
            "Epoch 153/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5954 - loss: 0.6656 - val_accuracy: 0.6114 - val_loss: 0.6615\n",
            "Epoch 154/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5943 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6577\n",
            "Epoch 155/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6069 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 156/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6090 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6650\n",
            "Epoch 157/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5845 - loss: 0.6701 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 158/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5937 - loss: 0.6684 - val_accuracy: 0.6114 - val_loss: 0.6652\n",
            "Epoch 159/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5951 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 160/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6019 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6589\n",
            "Epoch 161/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5826 - loss: 0.6690 - val_accuracy: 0.6114 - val_loss: 0.6592\n",
            "Epoch 162/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6045 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6586\n",
            "Epoch 163/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5997 - loss: 0.6515 - val_accuracy: 0.6114 - val_loss: 0.6636\n",
            "Epoch 164/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5897 - loss: 0.6700 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 165/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6065 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6588\n",
            "Epoch 166/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6092 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6592\n",
            "Epoch 167/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5934 - loss: 0.6667 - val_accuracy: 0.6114 - val_loss: 0.6571\n",
            "Epoch 168/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 169/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5955 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 170/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5969 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6586\n",
            "Epoch 171/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6140 - loss: 0.6641 - val_accuracy: 0.5910 - val_loss: 0.6600\n",
            "Epoch 172/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5906 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 173/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6188 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6626\n",
            "Epoch 174/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5905 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6643\n",
            "Epoch 175/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6072 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6616\n",
            "Epoch 176/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5809 - loss: 0.6714 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 177/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6019 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 178/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5799 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 179/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5947 - loss: 0.6626 - val_accuracy: 0.5910 - val_loss: 0.6612\n",
            "Epoch 180/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6011 - loss: 0.6627 - val_accuracy: 0.5910 - val_loss: 0.6642\n",
            "Epoch 181/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5993 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6631\n",
            "Epoch 182/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5859 - loss: 0.6689 - val_accuracy: 0.6114 - val_loss: 0.6637\n",
            "Epoch 183/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5822 - loss: 0.6687 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 184/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6055 - loss: 0.6506 - val_accuracy: 0.6114 - val_loss: 0.6627\n",
            "Epoch 185/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6071 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6624\n",
            "Epoch 186/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5857 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 187/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5757 - loss: 0.6702 - val_accuracy: 0.6114 - val_loss: 0.6616\n",
            "Epoch 188/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.6508 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 189/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6016 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 190/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5982 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6615\n",
            "Epoch 191/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6106 - loss: 0.6596 - val_accuracy: 0.5910 - val_loss: 0.6620\n",
            "Epoch 192/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5836 - loss: 0.6685 - val_accuracy: 0.6114 - val_loss: 0.6589\n",
            "Epoch 193/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6099 - loss: 0.6515 - val_accuracy: 0.6114 - val_loss: 0.6624\n",
            "Epoch 194/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6089 - loss: 0.6522 - val_accuracy: 0.6114 - val_loss: 0.6624\n",
            "Epoch 195/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5941 - loss: 0.6582 - val_accuracy: 0.5910 - val_loss: 0.6618\n",
            "Epoch 196/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5890 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6618\n",
            "Epoch 197/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6143 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6614\n",
            "Epoch 198/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6071 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 199/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6059 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 200/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5973 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6636\n",
            "Epoch 201/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5901 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 202/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5877 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 203/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6129 - loss: 0.6562 - val_accuracy: 0.6114 - val_loss: 0.6617\n",
            "Epoch 204/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5896 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 205/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5778 - loss: 0.6708 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 206/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6019 - loss: 0.6696 - val_accuracy: 0.5910 - val_loss: 0.6580\n",
            "Epoch 207/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6162 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 208/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5765 - loss: 0.6699 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 209/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6138 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 210/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6125 - loss: 0.6578 - val_accuracy: 0.5910 - val_loss: 0.6597\n",
            "Epoch 211/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5909 - loss: 0.6660 - val_accuracy: 0.6114 - val_loss: 0.6638\n",
            "Epoch 212/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5998 - loss: 0.6639 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 213/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6107 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6646\n",
            "Epoch 214/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5926 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6578\n",
            "Epoch 215/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5947 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6626\n",
            "Epoch 216/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5937 - loss: 0.6672 - val_accuracy: 0.5910 - val_loss: 0.6608\n",
            "Epoch 217/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5971 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6622\n",
            "Epoch 218/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5993 - loss: 0.6577 - val_accuracy: 0.5910 - val_loss: 0.6629\n",
            "Epoch 219/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5976 - loss: 0.6578 - val_accuracy: 0.5910 - val_loss: 0.6625\n",
            "Epoch 220/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5921 - loss: 0.6656 - val_accuracy: 0.5910 - val_loss: 0.6606\n",
            "Epoch 221/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6162 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 222/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5971 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6617\n",
            "Epoch 223/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5978 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6623\n",
            "Epoch 224/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5966 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 225/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5777 - loss: 0.6729 - val_accuracy: 0.6114 - val_loss: 0.6620\n",
            "Epoch 226/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6032 - loss: 0.6624 - val_accuracy: 0.5910 - val_loss: 0.6614\n",
            "Epoch 227/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6099 - loss: 0.6576 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 228/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5825 - loss: 0.6668 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 229/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5984 - loss: 0.6616 - val_accuracy: 0.5910 - val_loss: 0.6613\n",
            "Epoch 230/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6043 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 231/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5894 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 232/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6106 - loss: 0.6533 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 233/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5825 - loss: 0.6684 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 234/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6000 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 235/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6046 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 236/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5902 - loss: 0.6679 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 237/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5878 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 238/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5997 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 239/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6067 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 240/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6009 - loss: 0.6589 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 241/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6185 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 242/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6182 - loss: 0.6479 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 243/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6029 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 244/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5975 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 245/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6030 - loss: 0.6595 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 246/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5879 - loss: 0.6658 - val_accuracy: 0.5910 - val_loss: 0.6599\n",
            "Epoch 247/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5976 - loss: 0.6655 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 248/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 249/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5951 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6592\n",
            "Epoch 250/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6128 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 251/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6053 - loss: 0.6601 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 252/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6171 - loss: 0.6499 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 253/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6019 - loss: 0.6614 - val_accuracy: 0.5910 - val_loss: 0.6599\n",
            "Epoch 254/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5909 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6592\n",
            "Epoch 255/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5837 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 256/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5904 - loss: 0.6634 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 257/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5978 - loss: 0.6528 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 258/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5936 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 259/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6100 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 260/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6122 - loss: 0.6543 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 261/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6233 - loss: 0.6519 - val_accuracy: 0.5910 - val_loss: 0.6597\n",
            "Epoch 262/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6146 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 263/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6022 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 264/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5995 - loss: 0.6590 - val_accuracy: 0.5910 - val_loss: 0.6607\n",
            "Epoch 265/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5975 - loss: 0.6572 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 266/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6040 - loss: 0.6561 - val_accuracy: 0.5910 - val_loss: 0.6612\n",
            "Epoch 267/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5971 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6621\n",
            "Epoch 268/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5767 - loss: 0.6651 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 269/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6034 - loss: 0.6633 - val_accuracy: 0.5910 - val_loss: 0.6602\n",
            "Epoch 270/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.6599 - val_accuracy: 0.5910 - val_loss: 0.6609\n",
            "Epoch 271/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5983 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 272/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5914 - loss: 0.6649 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 273/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5995 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 274/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5909 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 275/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 276/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6123 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 277/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5957 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 278/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6042 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 279/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5977 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 280/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 0.6543 - val_accuracy: 0.5910 - val_loss: 0.6600\n",
            "Epoch 281/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5936 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 282/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6170 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 283/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5781 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 284/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5905 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 285/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5787 - loss: 0.6691 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 286/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6019 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6622\n",
            "Epoch 287/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6055 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 288/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5989 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 289/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6007 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 290/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6074 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 291/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6109 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 292/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5820 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 293/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5930 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 294/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 295/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5843 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 296/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6131 - loss: 0.6513 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 297/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6045 - loss: 0.6600 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 298/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5928 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 299/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 300/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6035 - loss: 0.6521 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 301/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6077 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 302/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5932 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 303/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5965 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 304/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5821 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 305/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5836 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 306/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5987 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 307/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6079 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 308/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5997 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 309/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5985 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 310/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5978 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 311/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6033 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 312/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5894 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 313/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6059 - loss: 0.6529 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 314/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6136 - loss: 0.6536 - val_accuracy: 0.5910 - val_loss: 0.6610\n",
            "Epoch 315/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5916 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 316/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5878 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 317/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5944 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 318/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6064 - loss: 0.6553 - val_accuracy: 0.5910 - val_loss: 0.6607\n",
            "Epoch 319/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5865 - loss: 0.6632 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 320/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6011 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 321/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5868 - loss: 0.6596 - val_accuracy: 0.5910 - val_loss: 0.6607\n",
            "Epoch 322/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5944 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 323/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5883 - loss: 0.6556 - val_accuracy: 0.5910 - val_loss: 0.6609\n",
            "Epoch 324/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 325/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 0.6553 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 326/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 327/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6141 - loss: 0.6560 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 328/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6077 - loss: 0.6511 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 329/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5859 - loss: 0.6684 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 330/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6177 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 331/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6059 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 332/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5940 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 333/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6079 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 334/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6061 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 335/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6139 - loss: 0.6543 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 336/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6042 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 337/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6085 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 338/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5950 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 339/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5853 - loss: 0.6653 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 340/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5985 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 341/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.6663 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 342/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6047 - loss: 0.6572 - val_accuracy: 0.5910 - val_loss: 0.6606\n",
            "Epoch 343/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6075 - loss: 0.6535 - val_accuracy: 0.5910 - val_loss: 0.6611\n",
            "Epoch 344/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6120 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 345/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6169 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 346/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6005 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 347/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5952 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 348/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5871 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 349/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5981 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 350/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6119 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 351/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5957 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 352/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 353/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 354/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5942 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 355/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5980 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 356/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5881 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 357/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6068 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 358/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6001 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 359/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5935 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 360/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5960 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 361/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5985 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 362/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5930 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 363/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5893 - loss: 0.6658 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 364/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5956 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 365/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5927 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 366/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5932 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 367/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5848 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 368/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5966 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 369/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5899 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 370/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5930 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 371/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6131 - loss: 0.6482 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 372/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5964 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 373/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6130 - loss: 0.6495 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 374/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5927 - loss: 0.6603 - val_accuracy: 0.5910 - val_loss: 0.6610\n",
            "Epoch 375/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 376/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6018 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 377/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5957 - loss: 0.6648 - val_accuracy: 0.6114 - val_loss: 0.6581\n",
            "Epoch 378/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6040 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 379/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5959 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 380/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5999 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 381/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5972 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 382/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6020 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 383/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5866 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 384/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5916 - loss: 0.6653 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 385/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5814 - loss: 0.6694 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 386/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5976 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 387/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6061 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 388/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6072 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 389/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5916 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 390/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6110 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 391/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6038 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 392/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6123 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 393/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6020 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 394/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5673 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6615\n",
            "Epoch 395/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5937 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6617\n",
            "Epoch 396/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6006 - loss: 0.6597 - val_accuracy: 0.5910 - val_loss: 0.6614\n",
            "Epoch 397/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5853 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 398/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6094 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 399/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5988 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 400/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6015 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 401/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5957 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 402/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6019 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 403/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5912 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 404/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5992 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 405/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6081 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 406/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5894 - loss: 0.6668 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 407/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5946 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 408/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6128 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 409/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5892 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 410/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6001 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 411/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5828 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 412/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5936 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 413/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6040 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 414/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5965 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 415/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6010 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 416/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5937 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 417/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6010 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 418/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5922 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 419/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5813 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 420/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5736 - loss: 0.6693 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 421/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5852 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 422/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6127 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 423/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5980 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 424/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6010 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 425/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5990 - loss: 0.6641 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 426/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6004 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 427/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6077 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 428/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5875 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 429/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6131 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 430/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6001 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 431/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5964 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 432/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6026 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 433/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5905 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 434/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5868 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 435/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6057 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 436/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6005 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 437/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6011 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 438/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6015 - loss: 0.6611 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 439/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6128 - loss: 0.6592 - val_accuracy: 0.5910 - val_loss: 0.6608\n",
            "Epoch 440/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5943 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 441/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6107 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 442/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5901 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 443/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5867 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 444/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6147 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 445/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6001 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 446/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5980 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 447/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5899 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 448/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5941 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 449/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5960 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 450/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5898 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 451/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6017 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 452/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5833 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 453/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 454/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5967 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 455/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 456/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6008 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 457/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6070 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 458/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5983 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 459/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5996 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 460/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6162 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 461/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5910 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 462/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6260 - loss: 0.6468 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 463/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6173 - loss: 0.6488 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 464/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5895 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 465/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6023 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 466/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5958 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 467/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6037 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 468/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5960 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 469/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6025 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 470/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5977 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 471/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6249 - loss: 0.6472 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 472/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6021 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 473/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6072 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 474/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5875 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 475/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5961 - loss: 0.6541 - val_accuracy: 0.5910 - val_loss: 0.6611\n",
            "Epoch 476/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 0.6501 - val_accuracy: 0.5910 - val_loss: 0.6606\n",
            "Epoch 477/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5973 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 478/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5968 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 479/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6077 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 480/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5931 - loss: 0.6649 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 481/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5812 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 482/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5928 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 483/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5980 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 484/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5984 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 485/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5900 - loss: 0.6693 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 486/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6117 - loss: 0.6528 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 487/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5941 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 488/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5961 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 489/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5920 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 490/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5996 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 491/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5960 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 492/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6112 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 493/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5941 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 494/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5916 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 495/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5965 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 496/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5860 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 497/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5822 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 498/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6001 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 499/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6087 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 500/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6027 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "RNN Model Accuracy: 0.61\n"
          ]
        }
      ],
      "source": [
        "#RNN 500 epochs\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def preprocess_lstm_data(input_data, labels):\n",
        "    #convert subword sequences into numerical arrays\n",
        "    sequences = []\n",
        "    for row in input_data:\n",
        "        subwords = [float(x) for x in row.split(';')]\n",
        "        sequences.append(subwords)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    return np.array(sequences), labels, label_encoder\n",
        "\n",
        "input_data = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            input_data.append(subwords)\n",
        "            labels.append(label)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "input_data, labels, label_encoder = preprocess_lstm_data(input_data, labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_data, labels, test_size=0.2, random_state=60)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "#LSTM model\n",
        "def build_rnn(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "rnn_model = build_rnn((X_train.shape[1], X_train.shape[2]))\n",
        "rnn_model.fit(X_train, y_train, epochs=500, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "y_pred = (rnn_model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"RNN Model Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXKFovQhiTEB",
        "outputId": "c7d8482f-3774-42d3-f83b-51d5b6758ae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5614 - loss: 0.6876 - val_accuracy: 0.6114 - val_loss: 0.6588\n",
            "Epoch 2/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5917 - loss: 0.6691 - val_accuracy: 0.5910 - val_loss: 0.6614\n",
            "Epoch 3/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5963 - loss: 0.6630 - val_accuracy: 0.5910 - val_loss: 0.6587\n",
            "Epoch 4/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6050 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6619\n",
            "Epoch 5/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5994 - loss: 0.6669 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 6/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6048 - loss: 0.6583 - val_accuracy: 0.5910 - val_loss: 0.6597\n",
            "Epoch 7/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6731\n",
            "Epoch 8/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5907 - loss: 0.6735 - val_accuracy: 0.5910 - val_loss: 0.6582\n",
            "Epoch 9/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6073 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 10/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5994 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 11/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6016 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6721\n",
            "Epoch 12/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6051 - loss: 0.6637 - val_accuracy: 0.5910 - val_loss: 0.6608\n",
            "Epoch 13/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5811 - loss: 0.6718 - val_accuracy: 0.5910 - val_loss: 0.6585\n",
            "Epoch 14/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6637 - val_accuracy: 0.5910 - val_loss: 0.6578\n",
            "Epoch 15/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5964 - loss: 0.6598 - val_accuracy: 0.5910 - val_loss: 0.6695\n",
            "Epoch 16/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5873 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6687\n",
            "Epoch 17/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5893 - loss: 0.6669 - val_accuracy: 0.6114 - val_loss: 0.6583\n",
            "Epoch 18/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6152 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 19/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5913 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 20/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5881 - loss: 0.6552 - val_accuracy: 0.5910 - val_loss: 0.6754\n",
            "Epoch 21/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 0.6663 - val_accuracy: 0.5910 - val_loss: 0.6591\n",
            "Epoch 22/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5893 - loss: 0.6704 - val_accuracy: 0.5910 - val_loss: 0.6588\n",
            "Epoch 23/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6010 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 24/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6059 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 25/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6034 - loss: 0.6620 - val_accuracy: 0.5910 - val_loss: 0.6593\n",
            "Epoch 26/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5966 - loss: 0.6592 - val_accuracy: 0.5910 - val_loss: 0.6602\n",
            "Epoch 27/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6003 - loss: 0.6625 - val_accuracy: 0.5910 - val_loss: 0.6601\n",
            "Epoch 28/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5820 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 29/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5850 - loss: 0.6647 - val_accuracy: 0.5910 - val_loss: 0.6681\n",
            "Epoch 30/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5958 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6579\n",
            "Epoch 31/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 0.6591 - val_accuracy: 0.5910 - val_loss: 0.6602\n",
            "Epoch 32/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5970 - loss: 0.6621 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 33/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6132 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 34/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5866 - loss: 0.6707 - val_accuracy: 0.5910 - val_loss: 0.6590\n",
            "Epoch 35/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5956 - loss: 0.6614 - val_accuracy: 0.5910 - val_loss: 0.6590\n",
            "Epoch 36/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5933 - loss: 0.6753 - val_accuracy: 0.6114 - val_loss: 0.6589\n",
            "Epoch 37/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6045 - loss: 0.6627 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 38/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5971 - loss: 0.6627 - val_accuracy: 0.5910 - val_loss: 0.6591\n",
            "Epoch 39/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5937 - loss: 0.6646 - val_accuracy: 0.5910 - val_loss: 0.6694\n",
            "Epoch 40/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6060 - loss: 0.6593 - val_accuracy: 0.5910 - val_loss: 0.6613\n",
            "Epoch 41/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5860 - loss: 0.6668 - val_accuracy: 0.5910 - val_loss: 0.6596\n",
            "Epoch 42/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5971 - loss: 0.6639 - val_accuracy: 0.5910 - val_loss: 0.6582\n",
            "Epoch 43/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5883 - loss: 0.6637 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 44/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5993 - loss: 0.6675 - val_accuracy: 0.6114 - val_loss: 0.6588\n",
            "Epoch 45/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5803 - loss: 0.6692 - val_accuracy: 0.5910 - val_loss: 0.6591\n",
            "Epoch 46/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6142 - loss: 0.6611 - val_accuracy: 0.5910 - val_loss: 0.6594\n",
            "Epoch 47/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5930 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 48/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5964 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 49/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5927 - loss: 0.6717 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 50/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5954 - loss: 0.6603 - val_accuracy: 0.5910 - val_loss: 0.6619\n",
            "Epoch 51/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6061 - loss: 0.6605 - val_accuracy: 0.5910 - val_loss: 0.6602\n",
            "Epoch 52/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5978 - loss: 0.6670 - val_accuracy: 0.6114 - val_loss: 0.6718\n",
            "Epoch 53/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6004 - loss: 0.6648 - val_accuracy: 0.5910 - val_loss: 0.6592\n",
            "Epoch 54/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 55/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5842 - loss: 0.6698 - val_accuracy: 0.5910 - val_loss: 0.6588\n",
            "Epoch 56/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5771 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6648\n",
            "Epoch 57/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6067 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 58/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5965 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6578\n",
            "Epoch 59/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5935 - loss: 0.6688 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 60/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5821 - loss: 0.6670 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 61/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6088 - loss: 0.6557 - val_accuracy: 0.5910 - val_loss: 0.6592\n",
            "Epoch 62/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5942 - loss: 0.6635 - val_accuracy: 0.5910 - val_loss: 0.6583\n",
            "Epoch 63/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6103 - loss: 0.6580 - val_accuracy: 0.5910 - val_loss: 0.6592\n",
            "Epoch 64/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5988 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 65/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6113 - loss: 0.6569 - val_accuracy: 0.5910 - val_loss: 0.6589\n",
            "Epoch 66/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6050 - loss: 0.6543 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 67/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5993 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 68/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 0.6653 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 69/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5810 - loss: 0.6660 - val_accuracy: 0.5910 - val_loss: 0.6587\n",
            "Epoch 70/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6004 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6588\n",
            "Epoch 71/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5904 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 72/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5976 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6640\n",
            "Epoch 73/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6007 - loss: 0.6634 - val_accuracy: 0.5910 - val_loss: 0.6585\n",
            "Epoch 74/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5891 - loss: 0.6574 - val_accuracy: 0.5910 - val_loss: 0.6592\n",
            "Epoch 75/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5976 - loss: 0.6651 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 76/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6026 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6624\n",
            "Epoch 77/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6037 - loss: 0.6637 - val_accuracy: 0.5910 - val_loss: 0.6613\n",
            "Epoch 78/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5825 - loss: 0.6708 - val_accuracy: 0.5910 - val_loss: 0.6580\n",
            "Epoch 79/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6159 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 80/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5955 - loss: 0.6644 - val_accuracy: 0.5910 - val_loss: 0.6588\n",
            "Epoch 81/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5985 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 82/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6083 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 83/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6040 - loss: 0.6652 - val_accuracy: 0.5910 - val_loss: 0.6596\n",
            "Epoch 84/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5942 - loss: 0.6618 - val_accuracy: 0.5910 - val_loss: 0.6592\n",
            "Epoch 85/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5853 - loss: 0.6658 - val_accuracy: 0.5910 - val_loss: 0.6644\n",
            "Epoch 86/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6038 - loss: 0.6588 - val_accuracy: 0.5910 - val_loss: 0.6650\n",
            "Epoch 87/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5882 - loss: 0.6673 - val_accuracy: 0.5910 - val_loss: 0.6654\n",
            "Epoch 88/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5890 - loss: 0.6677 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 89/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5983 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 90/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6122 - loss: 0.6503 - val_accuracy: 0.6114 - val_loss: 0.6625\n",
            "Epoch 91/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6006 - loss: 0.6653 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 92/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5814 - loss: 0.6710 - val_accuracy: 0.6114 - val_loss: 0.6579\n",
            "Epoch 93/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5925 - loss: 0.6669 - val_accuracy: 0.6114 - val_loss: 0.6588\n",
            "Epoch 94/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 95/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6087 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6590\n",
            "Epoch 96/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5879 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 97/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5852 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 98/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6033 - loss: 0.6611 - val_accuracy: 0.5910 - val_loss: 0.6619\n",
            "Epoch 99/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5983 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6614\n",
            "Epoch 100/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5911 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6585\n",
            "Epoch 101/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 0.6627 - val_accuracy: 0.5910 - val_loss: 0.6588\n",
            "Epoch 102/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5849 - loss: 0.6744 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 103/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6042 - loss: 0.6550 - val_accuracy: 0.5910 - val_loss: 0.6595\n",
            "Epoch 104/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6029 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6626\n",
            "Epoch 105/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5992 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6586\n",
            "Epoch 106/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5902 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6645\n",
            "Epoch 107/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6580\n",
            "Epoch 108/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5931 - loss: 0.6660 - val_accuracy: 0.6114 - val_loss: 0.6585\n",
            "Epoch 109/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6039 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6583\n",
            "Epoch 110/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5998 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6589\n",
            "Epoch 111/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5868 - loss: 0.6691 - val_accuracy: 0.5910 - val_loss: 0.6601\n",
            "Epoch 112/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6025 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6616\n",
            "Epoch 113/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5991 - loss: 0.6635 - val_accuracy: 0.5910 - val_loss: 0.6621\n",
            "Epoch 114/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5892 - loss: 0.6715 - val_accuracy: 0.6114 - val_loss: 0.6585\n",
            "Epoch 115/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5865 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 116/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5919 - loss: 0.6679 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 117/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6149 - loss: 0.6612 - val_accuracy: 0.5910 - val_loss: 0.6585\n",
            "Epoch 118/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5934 - loss: 0.6655 - val_accuracy: 0.6114 - val_loss: 0.6581\n",
            "Epoch 119/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6029 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 120/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5998 - loss: 0.6630 - val_accuracy: 0.5910 - val_loss: 0.6667\n",
            "Epoch 121/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5915 - loss: 0.6709 - val_accuracy: 0.5910 - val_loss: 0.6638\n",
            "Epoch 122/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5994 - loss: 0.6655 - val_accuracy: 0.6114 - val_loss: 0.6680\n",
            "Epoch 123/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5911 - loss: 0.6677 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 124/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5746 - loss: 0.6744 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 125/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6079 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6625\n",
            "Epoch 126/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6005 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6590\n",
            "Epoch 127/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5851 - loss: 0.6676 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 128/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6129 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6635\n",
            "Epoch 129/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5970 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 130/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5918 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 131/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6004 - loss: 0.6670 - val_accuracy: 0.6114 - val_loss: 0.6583\n",
            "Epoch 132/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5955 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 133/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5854 - loss: 0.6666 - val_accuracy: 0.6114 - val_loss: 0.6628\n",
            "Epoch 134/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6095 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6657\n",
            "Epoch 135/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6021 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6681\n",
            "Epoch 136/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5834 - loss: 0.6678 - val_accuracy: 0.6114 - val_loss: 0.6621\n",
            "Epoch 137/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6030 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6585\n",
            "Epoch 138/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5917 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6701\n",
            "Epoch 139/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6098 - loss: 0.6601 - val_accuracy: 0.5910 - val_loss: 0.6598\n",
            "Epoch 140/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5937 - loss: 0.6616 - val_accuracy: 0.5910 - val_loss: 0.6619\n",
            "Epoch 141/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5896 - loss: 0.6647 - val_accuracy: 0.5910 - val_loss: 0.6628\n",
            "Epoch 142/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5978 - loss: 0.6630 - val_accuracy: 0.5910 - val_loss: 0.6599\n",
            "Epoch 143/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5971 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6697\n",
            "Epoch 144/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6155 - loss: 0.6597 - val_accuracy: 0.5910 - val_loss: 0.6599\n",
            "Epoch 145/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6041 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6580\n",
            "Epoch 146/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6036 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6621\n",
            "Epoch 147/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6006 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6615\n",
            "Epoch 148/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6191 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6620\n",
            "Epoch 149/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6068 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 150/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 151/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5880 - loss: 0.6700 - val_accuracy: 0.6114 - val_loss: 0.6588\n",
            "Epoch 152/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6077 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 153/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6078 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6615\n",
            "Epoch 154/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6007 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 155/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6037 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6621\n",
            "Epoch 156/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6019 - loss: 0.6586 - val_accuracy: 0.5910 - val_loss: 0.6605\n",
            "Epoch 157/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5970 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 158/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5912 - loss: 0.6707 - val_accuracy: 0.6114 - val_loss: 0.6637\n",
            "Epoch 159/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6018 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6633\n",
            "Epoch 160/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5857 - loss: 0.6648 - val_accuracy: 0.5910 - val_loss: 0.6591\n",
            "Epoch 161/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 0.6669 - val_accuracy: 0.6114 - val_loss: 0.6588\n",
            "Epoch 162/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6026 - loss: 0.6594 - val_accuracy: 0.5910 - val_loss: 0.6611\n",
            "Epoch 163/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5984 - loss: 0.6647 - val_accuracy: 0.5910 - val_loss: 0.6600\n",
            "Epoch 164/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5853 - loss: 0.6718 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 165/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6116 - loss: 0.6561 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 166/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5918 - loss: 0.6724 - val_accuracy: 0.6114 - val_loss: 0.6583\n",
            "Epoch 167/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5993 - loss: 0.6662 - val_accuracy: 0.5910 - val_loss: 0.6582\n",
            "Epoch 168/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5912 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 169/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5798 - loss: 0.6746 - val_accuracy: 0.6114 - val_loss: 0.6581\n",
            "Epoch 170/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5916 - loss: 0.6724 - val_accuracy: 0.6114 - val_loss: 0.6583\n",
            "Epoch 171/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6002 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 172/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5987 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 173/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5955 - loss: 0.6671 - val_accuracy: 0.6114 - val_loss: 0.6580\n",
            "Epoch 174/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5912 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6573\n",
            "Epoch 175/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6089 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 176/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6133 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 177/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5876 - loss: 0.6692 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 178/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5906 - loss: 0.6645 - val_accuracy: 0.6114 - val_loss: 0.6616\n",
            "Epoch 179/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6068 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 180/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5925 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6617\n",
            "Epoch 181/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5977 - loss: 0.6679 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 182/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6066 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6626\n",
            "Epoch 183/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6075 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 184/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5930 - loss: 0.6651 - val_accuracy: 0.6114 - val_loss: 0.6588\n",
            "Epoch 185/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5993 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 186/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5924 - loss: 0.6675 - val_accuracy: 0.6114 - val_loss: 0.6574\n",
            "Epoch 187/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5903 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 188/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6020 - loss: 0.6639 - val_accuracy: 0.5910 - val_loss: 0.6612\n",
            "Epoch 189/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5961 - loss: 0.6682 - val_accuracy: 0.6114 - val_loss: 0.6583\n",
            "Epoch 190/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6010 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 191/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5996 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6589\n",
            "Epoch 192/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5956 - loss: 0.6700 - val_accuracy: 0.6114 - val_loss: 0.6578\n",
            "Epoch 193/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5751 - loss: 0.6687 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 194/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5922 - loss: 0.6672 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 195/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 196/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5956 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 197/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5941 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6623\n",
            "Epoch 198/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5858 - loss: 0.6695 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 199/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5950 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 200/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5935 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 201/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5913 - loss: 0.6562 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 202/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5839 - loss: 0.6751 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 203/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5962 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6619\n",
            "Epoch 204/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5939 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6631\n",
            "Epoch 205/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6277 - loss: 0.6472 - val_accuracy: 0.5910 - val_loss: 0.6616\n",
            "Epoch 206/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6126 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6592\n",
            "Epoch 207/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6121 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 208/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5946 - loss: 0.6699 - val_accuracy: 0.6114 - val_loss: 0.6638\n",
            "Epoch 209/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5811 - loss: 0.6667 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 210/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5976 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6618\n",
            "Epoch 211/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6051 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 212/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6049 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6587\n",
            "Epoch 213/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6590\n",
            "Epoch 214/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5989 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 215/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6203 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6624\n",
            "Epoch 216/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6023 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 217/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5902 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6615\n",
            "Epoch 218/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5986 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 219/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5915 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6645\n",
            "Epoch 220/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5868 - loss: 0.6703 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 221/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6064 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 222/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6232 - loss: 0.6505 - val_accuracy: 0.6114 - val_loss: 0.6621\n",
            "Epoch 223/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5837 - loss: 0.6689 - val_accuracy: 0.6114 - val_loss: 0.6582\n",
            "Epoch 224/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5949 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 225/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5951 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 226/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6259 - loss: 0.6501 - val_accuracy: 0.6114 - val_loss: 0.6624\n",
            "Epoch 227/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5806 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 228/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5902 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 229/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5841 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6616\n",
            "Epoch 230/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5988 - loss: 0.6644 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 231/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5977 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6616\n",
            "Epoch 232/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5824 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6620\n",
            "Epoch 233/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6037 - loss: 0.6638 - val_accuracy: 0.5910 - val_loss: 0.6616\n",
            "Epoch 234/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5923 - loss: 0.6587 - val_accuracy: 0.5910 - val_loss: 0.6617\n",
            "Epoch 235/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6155 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6617\n",
            "Epoch 236/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5922 - loss: 0.6648 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 237/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6066 - loss: 0.6485 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 238/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6010 - loss: 0.6619 - val_accuracy: 0.5910 - val_loss: 0.6616\n",
            "Epoch 239/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6025 - loss: 0.6590 - val_accuracy: 0.5910 - val_loss: 0.6610\n",
            "Epoch 240/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5955 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 241/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6172 - loss: 0.6448 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 242/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5909 - loss: 0.6631 - val_accuracy: 0.5910 - val_loss: 0.6611\n",
            "Epoch 243/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6080 - loss: 0.6599 - val_accuracy: 0.5910 - val_loss: 0.6607\n",
            "Epoch 244/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6102 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 245/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6063 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 246/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6097 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6621\n",
            "Epoch 247/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5916 - loss: 0.6642 - val_accuracy: 0.5910 - val_loss: 0.6596\n",
            "Epoch 248/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5965 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 249/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6056 - loss: 0.6588 - val_accuracy: 0.5910 - val_loss: 0.6608\n",
            "Epoch 250/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6032 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 251/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6007 - loss: 0.6632 - val_accuracy: 0.5910 - val_loss: 0.6617\n",
            "Epoch 252/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5995 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 253/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6129 - loss: 0.6549 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 254/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5986 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 255/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5937 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 256/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6053 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 257/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5825 - loss: 0.6693 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 258/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5855 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 259/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6069 - loss: 0.6640 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 260/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6094 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 261/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6203 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 262/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5933 - loss: 0.6602 - val_accuracy: 0.5910 - val_loss: 0.6612\n",
            "Epoch 263/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6035 - loss: 0.6561 - val_accuracy: 0.5910 - val_loss: 0.6608\n",
            "Epoch 264/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6001 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 265/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5981 - loss: 0.6533 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 266/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6019 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 267/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5956 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 268/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5903 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 269/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5912 - loss: 0.6642 - val_accuracy: 0.5910 - val_loss: 0.6606\n",
            "Epoch 270/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5909 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 271/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5916 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 272/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6016 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 273/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6071 - loss: 0.6508 - val_accuracy: 0.6114 - val_loss: 0.6635\n",
            "Epoch 274/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5884 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 275/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5893 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6631\n",
            "Epoch 276/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5987 - loss: 0.6620 - val_accuracy: 0.5910 - val_loss: 0.6583\n",
            "Epoch 277/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5710 - loss: 0.6672 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 278/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6114 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 279/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5845 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 280/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5877 - loss: 0.6677 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 281/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6130 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 282/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5879 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 283/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5849 - loss: 0.6680 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 284/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6157 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 285/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5936 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 286/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5946 - loss: 0.6661 - val_accuracy: 0.5910 - val_loss: 0.6595\n",
            "Epoch 287/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5747 - loss: 0.6733 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 288/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5936 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 289/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5919 - loss: 0.6662 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 290/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5942 - loss: 0.6614 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 291/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6117 - loss: 0.6562 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 292/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6069 - loss: 0.6543 - val_accuracy: 0.5910 - val_loss: 0.6599\n",
            "Epoch 293/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6032 - loss: 0.6533 - val_accuracy: 0.5910 - val_loss: 0.6608\n",
            "Epoch 294/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 0.6581 - val_accuracy: 0.5910 - val_loss: 0.6608\n",
            "Epoch 295/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5869 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 296/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5989 - loss: 0.6597 - val_accuracy: 0.5910 - val_loss: 0.6600\n",
            "Epoch 297/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6109 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 298/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6101 - loss: 0.6562 - val_accuracy: 0.6114 - val_loss: 0.6617\n",
            "Epoch 299/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6060 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 300/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6020 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 301/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6100 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 302/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5886 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 303/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5940 - loss: 0.6651 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 304/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5915 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 305/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5867 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 306/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5807 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 307/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5882 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 308/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5896 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 309/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5955 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 310/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5901 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 311/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5990 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 312/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5731 - loss: 0.6705 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 313/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5990 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 314/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5975 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 315/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5919 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 316/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5883 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 317/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5947 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 318/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6024 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 319/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5984 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 320/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5857 - loss: 0.6681 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 321/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5858 - loss: 0.6683 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 322/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5785 - loss: 0.6679 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 323/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6014 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 324/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5936 - loss: 0.6659 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 325/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6136 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 326/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5857 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 327/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5881 - loss: 0.6683 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 328/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5911 - loss: 0.6678 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 329/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5792 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 330/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5921 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 331/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 332/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6067 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 333/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5985 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 334/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5899 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 335/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6101 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 336/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6129 - loss: 0.6510 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 337/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5937 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 338/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6146 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 339/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6126 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 340/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6141 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 341/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6013 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 342/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5971 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 343/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6248 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 344/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 345/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6116 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 346/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6040 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 347/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6086 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 348/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5843 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 349/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5957 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 350/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5999 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 351/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6045 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 352/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5988 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 353/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6043 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 354/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6075 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 355/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5987 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 356/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5828 - loss: 0.6679 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 357/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6141 - loss: 0.6529 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 358/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6039 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 359/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5929 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 360/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6065 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 361/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5904 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 362/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6086 - loss: 0.6562 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 363/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6183 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 364/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5915 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 365/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6144 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 366/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6004 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 367/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6063 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 368/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6089 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 369/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6021 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 370/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5960 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 371/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5956 - loss: 0.6520 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 372/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5829 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 373/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5970 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 374/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5782 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 375/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5984 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 376/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6110 - loss: 0.6486 - val_accuracy: 0.5910 - val_loss: 0.6603\n",
            "Epoch 377/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5971 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 378/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6057 - loss: 0.6498 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 379/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5935 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 380/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5810 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 381/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5945 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 382/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5874 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 383/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6037 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 384/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6113 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 385/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6141 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 386/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5845 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 387/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5969 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 388/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5998 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 389/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5841 - loss: 0.6648 - val_accuracy: 0.6114 - val_loss: 0.6631\n",
            "Epoch 390/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5975 - loss: 0.6705 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 391/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5970 - loss: 0.6662 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 392/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5922 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 393/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5971 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 394/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5956 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 395/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5926 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 396/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6045 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6591\n",
            "Epoch 397/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5972 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 398/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 399/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6020 - loss: 0.6549 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 400/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5807 - loss: 0.6692 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 401/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5993 - loss: 0.6644 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 402/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5947 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 403/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5952 - loss: 0.6649 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 404/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5836 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 405/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5898 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 406/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5934 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 407/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5983 - loss: 0.6508 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 408/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6152 - loss: 0.6556 - val_accuracy: 0.5910 - val_loss: 0.6607\n",
            "Epoch 409/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5814 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 410/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6176 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 411/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6033 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 412/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6036 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 413/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6093 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 414/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5996 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 415/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5958 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 416/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6122 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 417/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6060 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 418/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 419/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6108 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 420/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5962 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 421/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5864 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 422/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6131 - loss: 0.6517 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 423/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6178 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 424/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6032 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 425/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6163 - loss: 0.6520 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 426/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6121 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 427/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5868 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 428/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6016 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 429/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 430/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6017 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 431/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5975 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 432/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5861 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 433/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5921 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 434/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5849 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 435/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6117 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 436/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6051 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 437/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5879 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 438/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5948 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 439/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 440/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 441/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5954 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 442/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6052 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 443/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5960 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 444/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5925 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 445/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6054 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 446/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6106 - loss: 0.6507 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 447/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5987 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6614\n",
            "Epoch 448/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 449/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6019 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 450/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5839 - loss: 0.6676 - val_accuracy: 0.6114 - val_loss: 0.6614\n",
            "Epoch 451/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6034 - loss: 0.6529 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 452/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5983 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 453/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6051 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 454/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6049 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 455/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6014 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 456/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5984 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 457/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6155 - loss: 0.6533 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 458/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5912 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 459/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5885 - loss: 0.6665 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 460/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6035 - loss: 0.6593 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 461/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5939 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 462/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5893 - loss: 0.6693 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 463/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5952 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 464/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5959 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 465/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5820 - loss: 0.6655 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 466/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6134 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 467/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6048 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 468/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5823 - loss: 0.6648 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 469/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5999 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 470/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6116 - loss: 0.6511 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 471/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6089 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 472/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5993 - loss: 0.6648 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 473/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5844 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 474/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 475/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5974 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 476/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6157 - loss: 0.6507 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 477/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5883 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 478/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6012 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 479/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5918 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 480/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5877 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 481/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5936 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 482/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6006 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 483/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5928 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 484/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6071 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 485/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6155 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 486/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6004 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 487/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5923 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 488/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5852 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 489/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5983 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 490/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6081 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 491/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5981 - loss: 0.6507 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 492/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5870 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 493/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6045 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 494/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6038 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 495/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5925 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 496/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5896 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 497/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6037 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 498/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5894 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 499/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6039 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 500/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6136 - loss: 0.6486 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 501/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5833 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 502/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6096 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 503/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5891 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 504/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6012 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 505/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 0.6645 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 506/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6029 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 507/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5986 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 508/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5931 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 509/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6024 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 510/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 511/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5919 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 512/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5897 - loss: 0.6664 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 513/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5934 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 514/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6095 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 515/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6021 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 516/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5968 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 517/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6004 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 518/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6072 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 519/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5976 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 520/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6136 - loss: 0.6518 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 521/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6058 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 522/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6039 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 523/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6054 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 524/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6045 - loss: 0.6515 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 525/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5992 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 526/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5926 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 527/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6011 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 528/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5979 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 529/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5916 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 530/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5852 - loss: 0.6662 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 531/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6043 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 532/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6241 - loss: 0.6496 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 533/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5880 - loss: 0.6641 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 534/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5939 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 535/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6107 - loss: 0.6516 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 536/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5942 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 537/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6012 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 538/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6061 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 539/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5819 - loss: 0.6676 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 540/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5909 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 541/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5844 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 542/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5816 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 543/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5952 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 544/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5878 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 545/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6065 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 546/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5902 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 547/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6016 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 548/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6014 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 549/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6003 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 550/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6066 - loss: 0.6536 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 551/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5877 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 552/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6064 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 553/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5923 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 554/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5856 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 555/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5871 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 556/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6084 - loss: 0.6517 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 557/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5872 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 558/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6011 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 559/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6014 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 560/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5983 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 561/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5983 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 562/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5881 - loss: 0.6659 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 563/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6064 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 564/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5783 - loss: 0.6662 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 565/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5994 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 566/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6225 - loss: 0.6501 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 567/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6034 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 568/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6163 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 569/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5945 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 570/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6034 - loss: 0.6562 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 571/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5928 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 572/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6024 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 573/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5923 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 574/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5946 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 575/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5970 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 576/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5934 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 577/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6074 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 578/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6137 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 579/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5929 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 580/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5971 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 581/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6095 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 582/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5890 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 583/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6018 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 584/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5919 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 585/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6011 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 586/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5916 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 587/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5941 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 588/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6031 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 589/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6143 - loss: 0.6533 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 590/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6010 - loss: 0.6519 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 591/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5902 - loss: 0.6686 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 592/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6078 - loss: 0.6524 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 593/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5929 - loss: 0.6644 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 594/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5934 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 595/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6052 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 596/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6085 - loss: 0.6500 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 597/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5876 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 598/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6023 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 599/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6013 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 600/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5924 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 601/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5961 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 602/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5984 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 603/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5993 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 604/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5918 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 605/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5932 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 606/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6093 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 607/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6089 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 608/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6098 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 609/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6033 - loss: 0.6476 - val_accuracy: 0.6114 - val_loss: 0.6614\n",
            "Epoch 610/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6119 - loss: 0.6528 - val_accuracy: 0.6114 - val_loss: 0.6614\n",
            "Epoch 611/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6058 - loss: 0.6536 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 612/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6065 - loss: 0.6520 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 613/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6014 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 614/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6005 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 615/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6012 - loss: 0.6562 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 616/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5974 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 617/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5812 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 618/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6036 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 619/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6056 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 620/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6079 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 621/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5757 - loss: 0.6685 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 622/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6109 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 623/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5959 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 624/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5829 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 625/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6071 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 626/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6090 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 627/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5846 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 628/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6069 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 629/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6081 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 630/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6046 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 631/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6080 - loss: 0.6481 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 632/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6062 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 633/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5967 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 634/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6089 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 635/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6003 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 636/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6183 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 637/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5881 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 638/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6128 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 639/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5999 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 640/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6072 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 641/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5939 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 642/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5957 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 643/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5868 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 644/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6150 - loss: 0.6574 - val_accuracy: 0.5910 - val_loss: 0.6615\n",
            "Epoch 645/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6166 - loss: 0.6489 - val_accuracy: 0.6114 - val_loss: 0.6612\n",
            "Epoch 646/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5963 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6611\n",
            "Epoch 647/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6225 - loss: 0.6469 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 648/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5943 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 649/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6004 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 650/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6088 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 651/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6119 - loss: 0.6517 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 652/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5913 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 653/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5915 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 654/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5990 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 655/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5922 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 656/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6126 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 657/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5802 - loss: 0.6682 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 658/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5933 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 659/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5867 - loss: 0.6682 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 660/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5997 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 661/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5958 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 662/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5992 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 663/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5947 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 664/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6181 - loss: 0.6479 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 665/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5983 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 666/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6165 - loss: 0.6473 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 667/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5975 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 668/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6124 - loss: 0.6525 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 669/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6013 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 670/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5943 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 671/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5907 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 672/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5803 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 673/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6034 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 674/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5897 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 675/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5925 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 676/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5958 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 677/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6074 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 678/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5912 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 679/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5922 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 680/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6075 - loss: 0.6481 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 681/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6095 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 682/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6143 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 683/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6045 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 684/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5961 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 685/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6254 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 686/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5930 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 687/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6036 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6584\n",
            "Epoch 688/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5890 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 689/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6024 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 690/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5893 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 691/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5952 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 692/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6156 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 693/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 694/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5847 - loss: 0.6663 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 695/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5920 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 696/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5888 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 697/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6100 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 698/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5891 - loss: 0.6704 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 699/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5942 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 700/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 701/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6082 - loss: 0.6498 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 702/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 703/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5994 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 704/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5953 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 705/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5799 - loss: 0.6707 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 706/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6107 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 707/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6049 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 708/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5904 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 709/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6083 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 710/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5952 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 711/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5924 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 712/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6139 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 713/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5964 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 714/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6062 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 715/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5978 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 716/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6057 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 717/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5868 - loss: 0.6670 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 718/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6110 - loss: 0.6529 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 719/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5953 - loss: 0.6653 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 720/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5825 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 721/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6057 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 722/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6101 - loss: 0.6536 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 723/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5973 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 724/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5912 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 725/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5956 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 726/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6063 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 727/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6034 - loss: 0.6497 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 728/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6005 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6614\n",
            "Epoch 729/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6054 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 730/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5919 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 731/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5806 - loss: 0.6687 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 732/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5900 - loss: 0.6641 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 733/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5866 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 734/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6149 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 735/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6027 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 736/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5953 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 737/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6035 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 738/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5990 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 739/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5970 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 740/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5922 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 741/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5962 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 742/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5878 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 743/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6015 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 744/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5833 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 745/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6083 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 746/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6037 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 747/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6018 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 748/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5899 - loss: 0.6645 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 749/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5898 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 750/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5991 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 751/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6056 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 752/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5891 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 753/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5963 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 754/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6067 - loss: 0.6487 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 755/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6151 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 756/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5986 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 757/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5930 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 758/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6107 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 759/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6033 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 760/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5969 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 761/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5954 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 762/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5914 - loss: 0.6645 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 763/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5950 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 764/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5876 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 765/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5926 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 766/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6052 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 767/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5981 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 768/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5973 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 769/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5878 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 770/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5957 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 771/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6106 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 772/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6048 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 773/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5872 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 774/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5941 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 775/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5862 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 776/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5917 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 777/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5859 - loss: 0.6687 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 778/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5793 - loss: 0.6697 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 779/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5865 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 780/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5961 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 781/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6076 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 782/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5973 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 783/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6013 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 784/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6211 - loss: 0.6506 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 785/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5904 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 786/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5984 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 787/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6037 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 788/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5865 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 789/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6023 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 790/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5894 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 791/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5953 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 792/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5998 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 793/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6118 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 794/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6000 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 795/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5963 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 796/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6036 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 797/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5868 - loss: 0.6695 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 798/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5900 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 799/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6051 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 800/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6067 - loss: 0.6529 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 801/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6008 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 802/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6010 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 803/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5970 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 804/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6034 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 805/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6031 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 806/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6067 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 807/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6028 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 808/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6171 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 809/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6201 - loss: 0.6493 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 810/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6073 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 811/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6007 - loss: 0.6502 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 812/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6042 - loss: 0.6517 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 813/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6009 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 814/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6128 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 815/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5952 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 816/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5863 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 817/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6119 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 818/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5963 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 819/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5976 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 820/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5929 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 821/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5982 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 822/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6018 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 823/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 824/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 825/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5741 - loss: 0.6664 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 826/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6101 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 827/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5904 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 828/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6115 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 829/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5914 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 830/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6039 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 831/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5918 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 832/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6031 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 833/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5785 - loss: 0.6745 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 834/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6011 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 835/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5981 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 836/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5920 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 837/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6031 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 838/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5928 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 839/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5827 - loss: 0.6685 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 840/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5934 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 841/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5833 - loss: 0.6678 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 842/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5905 - loss: 0.6686 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 843/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5828 - loss: 0.6662 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 844/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6050 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 845/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5986 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 846/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5983 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 847/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5798 - loss: 0.6703 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 848/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5926 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 849/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6162 - loss: 0.6499 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 850/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5789 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 851/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6009 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 852/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6031 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 853/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6019 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 854/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6066 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 855/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6123 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 856/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6142 - loss: 0.6497 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 857/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6077 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 858/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6054 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 859/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6009 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 860/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5877 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 861/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5993 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 862/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5992 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 863/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6112 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 864/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5992 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 865/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5783 - loss: 0.6681 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 866/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5853 - loss: 0.6664 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 867/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6043 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 868/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5846 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 869/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6039 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 870/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6109 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 871/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5922 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 872/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5908 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 873/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5943 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 874/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5965 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 875/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6026 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 876/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6074 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 877/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6123 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 878/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5990 - loss: 0.6528 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 879/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6040 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 880/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6207 - loss: 0.6481 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 881/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5871 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 882/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6103 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 883/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6065 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 884/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5995 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 885/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6081 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 886/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6240 - loss: 0.6471 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 887/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6040 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 888/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6071 - loss: 0.6521 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 889/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6040 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 890/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6104 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 891/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6017 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 892/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5969 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 893/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5991 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 894/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6106 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 895/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5960 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 896/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6000 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 897/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6109 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 898/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5875 - loss: 0.6663 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 899/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5936 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 900/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5793 - loss: 0.6709 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 901/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6031 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 902/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6020 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 903/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5942 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 904/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6001 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 905/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6134 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 906/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6142 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 907/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5976 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 908/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5915 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 909/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6013 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 910/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5825 - loss: 0.6651 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 911/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6091 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 912/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5971 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 913/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 914/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5902 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 915/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5899 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 916/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6066 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 917/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5949 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 918/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6004 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 919/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6007 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 920/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6102 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6613\n",
            "Epoch 921/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5791 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 922/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5824 - loss: 0.6685 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 923/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5887 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 924/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5894 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 925/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6025 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 926/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5966 - loss: 0.6654 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 927/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5951 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 928/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6034 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 929/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5977 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 930/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6072 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 931/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6123 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 932/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6064 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 933/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6045 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 934/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6170 - loss: 0.6512 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 935/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6005 - loss: 0.6532 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 936/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5959 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 937/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5924 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 938/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6115 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 939/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5969 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 940/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6017 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 941/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5839 - loss: 0.6649 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 942/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5869 - loss: 0.6644 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 943/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5979 - loss: 0.6655 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 944/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6047 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 945/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5949 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 946/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5913 - loss: 0.6684 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 947/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5995 - loss: 0.6562 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 948/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5879 - loss: 0.6666 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 949/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5959 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 950/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5872 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 951/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5927 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 952/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6104 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 953/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5884 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 954/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6180 - loss: 0.6467 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 955/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5927 - loss: 0.6641 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 956/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5966 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 957/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5953 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 958/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6074 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 959/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5814 - loss: 0.6659 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 960/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6098 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 961/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6116 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 962/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5880 - loss: 0.6687 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 963/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5982 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 964/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5802 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 965/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5870 - loss: 0.6665 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 966/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6015 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 967/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6039 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6593\n",
            "Epoch 968/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6006 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6595\n",
            "Epoch 969/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6048 - loss: 0.6522 - val_accuracy: 0.6114 - val_loss: 0.6594\n",
            "Epoch 970/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5923 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 971/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5855 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 972/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5982 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 973/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5966 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 974/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5985 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 975/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6088 - loss: 0.6521 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 976/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5967 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 977/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5976 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 978/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5882 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 979/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6119 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 980/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5955 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 981/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6075 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 982/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6026 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 983/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6083 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 984/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6025 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 985/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6126 - loss: 0.6532 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 986/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5952 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 987/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5984 - loss: 0.6608 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 988/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5979 - loss: 0.6576 - val_accuracy: 0.5910 - val_loss: 0.6604\n",
            "Epoch 989/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5974 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 990/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5911 - loss: 0.6672 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 991/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5817 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 992/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 0.6521 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 993/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6087 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 994/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5945 - loss: 0.6680 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 995/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6006 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 996/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 997/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5801 - loss: 0.6675 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 998/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5927 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 999/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6022 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1000/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6101 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1001/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5992 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1002/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5816 - loss: 0.6697 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1003/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6022 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1004/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5990 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1005/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5949 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1006/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5867 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1007/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6037 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1008/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5913 - loss: 0.6684 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1009/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6034 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1010/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5976 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1011/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5937 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1012/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6093 - loss: 0.6507 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1013/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6016 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1014/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5963 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1015/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5963 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1016/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5999 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1017/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5976 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1018/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5855 - loss: 0.6660 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1019/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6216 - loss: 0.6521 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1020/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6106 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1021/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6194 - loss: 0.6494 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1022/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5995 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1023/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5939 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1024/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5880 - loss: 0.6679 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1025/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5934 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1026/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6054 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1027/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5871 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1028/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6037 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1029/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6047 - loss: 0.6512 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1030/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5855 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1031/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5969 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1032/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6111 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1033/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6028 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1034/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5996 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1035/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5927 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1036/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6133 - loss: 0.6520 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1037/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6072 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1038/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5990 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1039/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6036 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1040/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6042 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1041/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5968 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1042/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6158 - loss: 0.6515 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1043/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6011 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1044/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5904 - loss: 0.6699 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1045/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5676 - loss: 0.6727 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1046/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5982 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1047/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6042 - loss: 0.6522 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1048/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6073 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1049/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6046 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1050/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5967 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1051/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5856 - loss: 0.6648 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1052/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6122 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1053/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6086 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1054/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5862 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1055/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5928 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1056/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5981 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1057/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5878 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1058/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5871 - loss: 0.6644 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1059/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5896 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1060/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5877 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1061/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6096 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1062/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6024 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1063/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6058 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1064/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6027 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1065/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6081 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1066/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5868 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1067/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5955 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1068/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5882 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1069/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6001 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1070/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6115 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1071/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5899 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1072/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6025 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1073/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5952 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1074/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6037 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1075/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5957 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1076/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6054 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1077/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5922 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1078/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5861 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1079/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5838 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1080/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5985 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1081/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5989 - loss: 0.6498 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1082/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6001 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1083/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5985 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1084/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6001 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1085/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6029 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1086/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5930 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1087/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5971 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1088/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6126 - loss: 0.6522 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1089/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6001 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1090/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5951 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1091/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5954 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1092/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6202 - loss: 0.6487 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1093/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6018 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1094/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5928 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1095/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6038 - loss: 0.6469 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1096/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5945 - loss: 0.6656 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1097/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6266 - loss: 0.6492 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1098/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6193 - loss: 0.6544 - val_accuracy: 0.5910 - val_loss: 0.6612\n",
            "Epoch 1099/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5972 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1100/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5929 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1101/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6037 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1102/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6066 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1103/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5958 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1104/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6101 - loss: 0.6493 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1105/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1106/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6078 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1107/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6046 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1108/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6069 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1109/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5924 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1110/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5895 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1111/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6087 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1112/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5954 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1113/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5909 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1114/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5879 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1115/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5902 - loss: 0.6659 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1116/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6046 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1117/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6066 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1118/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6071 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1119/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6131 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1120/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5973 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1121/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5899 - loss: 0.6689 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1122/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5999 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1123/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6034 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1124/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5969 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1125/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6125 - loss: 0.6516 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1126/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5925 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1127/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5945 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1128/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6022 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1129/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6072 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1130/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5893 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1131/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5874 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1132/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1133/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5758 - loss: 0.6706 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1134/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6004 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1135/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5980 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1136/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6005 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1137/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5911 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1138/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6022 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1139/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6040 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1140/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5941 - loss: 0.6644 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1141/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6013 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1142/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6106 - loss: 0.6505 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1143/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5972 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1144/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6656 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1145/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6009 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1146/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6037 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1147/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6037 - loss: 0.6505 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1148/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5947 - loss: 0.6648 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1149/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5900 - loss: 0.6644 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1150/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6020 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1151/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6037 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1152/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5939 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1153/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6039 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1154/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5951 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1155/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5879 - loss: 0.6644 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1156/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5904 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1157/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5937 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1158/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5922 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1159/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5952 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1160/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5979 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1161/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1162/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6124 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1163/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6134 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1164/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5988 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1165/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5936 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1166/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5998 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1167/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6073 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1168/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5853 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1169/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5984 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1170/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5904 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1171/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6110 - loss: 0.6529 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1172/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6044 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1173/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6151 - loss: 0.6481 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1174/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6145 - loss: 0.6493 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1175/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6185 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1176/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5983 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1177/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5977 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1178/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6044 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1179/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5854 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1180/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6027 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1181/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6132 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1182/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6016 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1183/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5995 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1184/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6084 - loss: 0.6481 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1185/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6017 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1186/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6066 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1187/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6086 - loss: 0.6525 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1188/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6115 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1189/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6059 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1190/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6022 - loss: 0.6532 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1191/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5993 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1192/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5979 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1193/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6004 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1194/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6057 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1195/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5895 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1196/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5972 - loss: 0.6660 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1197/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6072 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1198/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6116 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1199/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6005 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1200/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5976 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1201/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5884 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1202/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6116 - loss: 0.6504 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1203/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5980 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1204/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6015 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1205/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6027 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1206/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5831 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1207/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6044 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1208/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5931 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1209/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6036 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1210/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6049 - loss: 0.6506 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1211/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1212/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5940 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1213/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5755 - loss: 0.6674 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1214/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6062 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1215/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5875 - loss: 0.6648 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1216/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6161 - loss: 0.6519 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1217/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6038 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1218/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6107 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1219/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6052 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1220/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5978 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1221/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5899 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1222/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5909 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1223/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6082 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1224/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6014 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1225/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5988 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1226/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5863 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1227/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6048 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1228/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6073 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1229/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6054 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1230/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6049 - loss: 0.6505 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1231/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6003 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1232/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5994 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1233/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5971 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1234/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6131 - loss: 0.6482 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1235/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1236/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6058 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1237/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6068 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1238/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5919 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1239/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5882 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1240/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6037 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1241/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5976 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1242/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6135 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1243/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6171 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1244/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6007 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1245/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5863 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1246/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6039 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1247/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5839 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1248/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6090 - loss: 0.6521 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1249/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6060 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1250/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5948 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1251/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6084 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1252/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5798 - loss: 0.6672 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1253/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6005 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1254/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6089 - loss: 0.6515 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1255/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6074 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1256/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5795 - loss: 0.6686 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1257/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5741 - loss: 0.6693 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1258/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5940 - loss: 0.6630 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1259/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5900 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1260/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6178 - loss: 0.6475 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1261/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5943 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1262/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5961 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1263/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6083 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1264/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6054 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1265/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5891 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1266/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5913 - loss: 0.6663 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1267/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5854 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1268/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6056 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1269/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5906 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1270/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6033 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1271/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6065 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1272/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6019 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1273/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5867 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1274/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5866 - loss: 0.6666 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1275/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5950 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1276/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5927 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1277/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6060 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1278/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5925 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1279/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5891 - loss: 0.6645 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1280/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5947 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1281/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5871 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1282/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5909 - loss: 0.6659 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1283/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5986 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1284/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6192 - loss: 0.6495 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1285/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6154 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1286/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5873 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1287/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6066 - loss: 0.6516 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1288/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6024 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1289/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5998 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1290/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5756 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1291/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6090 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1292/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5959 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1293/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5981 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1294/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5969 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1295/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6100 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1296/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6095 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1297/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5988 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1298/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6014 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1299/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5949 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1300/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5974 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1301/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6094 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1302/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5856 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1303/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5788 - loss: 0.6677 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1304/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6072 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1305/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6231 - loss: 0.6492 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1306/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6090 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1307/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5855 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1308/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6083 - loss: 0.6533 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1309/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5940 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1310/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5981 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1311/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5823 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1312/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6152 - loss: 0.6512 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1313/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5961 - loss: 0.6520 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1314/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5926 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1315/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6078 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1316/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6086 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1317/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6168 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 1318/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6165 - loss: 0.6510 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1319/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6011 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1320/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5965 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1321/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6172 - loss: 0.6466 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1322/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6269 - loss: 0.6450 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1323/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6013 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1324/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5843 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1325/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5911 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1326/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5941 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1327/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6146 - loss: 0.6515 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1328/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6045 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1329/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5943 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1330/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5998 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1331/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5960 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1332/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6075 - loss: 0.6536 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1333/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6032 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1334/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6100 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1335/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5991 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1336/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6097 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1337/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6071 - loss: 0.6510 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1338/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5886 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1339/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6182 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1340/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5891 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1341/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6109 - loss: 0.6505 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1342/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5988 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1343/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6024 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1344/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6065 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1345/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5992 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1346/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6052 - loss: 0.6511 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1347/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6152 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1348/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5911 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1349/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5963 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1350/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6024 - loss: 0.6520 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1351/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6025 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1352/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5977 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1353/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6067 - loss: 0.6525 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1354/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5952 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1355/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5937 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1356/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6018 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1357/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6069 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1358/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6112 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1359/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6051 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1360/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6055 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1361/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6107 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1362/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5973 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1363/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5875 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 1364/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5856 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1365/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5834 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1366/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6117 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1367/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6149 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1368/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1369/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6108 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1370/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6048 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1371/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5999 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1372/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5988 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1373/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5965 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1374/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6167 - loss: 0.6532 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1375/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5955 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1376/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6027 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1377/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5929 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1378/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5935 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1379/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5916 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1380/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6049 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1381/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5994 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1382/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5925 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1383/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5976 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 1384/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5921 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 1385/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6116 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1386/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6019 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1387/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6066 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1388/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5998 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1389/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5971 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1390/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6139 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1391/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6143 - loss: 0.6518 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1392/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6068 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1393/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5959 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1394/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1395/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6098 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1396/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6079 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1397/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6000 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1398/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5906 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1399/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6014 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1400/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5970 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1401/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6070 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1402/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5985 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1403/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6116 - loss: 0.6525 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1404/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6101 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1405/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6068 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1406/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6095 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 1407/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5998 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1408/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6022 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 1409/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6056 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1410/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5977 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1411/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5964 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1412/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6008 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1413/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6001 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1414/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6102 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1415/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5863 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1416/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5952 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1417/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6028 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1418/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5937 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1419/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5973 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1420/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6051 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1421/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5845 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1422/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5911 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1423/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5990 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1424/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5973 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1425/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6078 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1426/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5921 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1427/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5966 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1428/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5952 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1429/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5852 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1430/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6036 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1431/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6036 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1432/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6045 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1433/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6143 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1434/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6081 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1435/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5952 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1436/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5961 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1437/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5871 - loss: 0.6644 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1438/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6019 - loss: 0.6520 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1439/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5976 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1440/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6008 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1441/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6037 - loss: 0.6521 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1442/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1443/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5799 - loss: 0.6724 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1444/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6011 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1445/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5989 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1446/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5901 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1447/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5935 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1448/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5871 - loss: 0.6677 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1449/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6007 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1450/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5982 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1451/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5935 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1452/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6004 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1453/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6113 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1454/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5965 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1455/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6033 - loss: 0.6492 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1456/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5802 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1457/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6059 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1458/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5979 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1459/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5905 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1460/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6003 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1461/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5998 - loss: 0.6536 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1462/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5992 - loss: 0.6504 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1463/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6203 - loss: 0.6468 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1464/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5978 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1465/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5863 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1466/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5927 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1467/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6028 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1468/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5781 - loss: 0.6674 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1469/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6198 - loss: 0.6506 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1470/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5990 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1471/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5917 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1472/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6124 - loss: 0.6470 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1473/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6120 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1474/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6008 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6610\n",
            "Epoch 1475/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5913 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1476/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6025 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1477/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6093 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1478/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5999 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1479/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5964 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1480/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5960 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1481/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6113 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1482/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6076 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1483/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6033 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1484/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6042 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1485/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5987 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1486/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5945 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1487/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5761 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1488/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5907 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1489/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6037 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1490/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5996 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1491/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5977 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1492/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6016 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1493/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6045 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1494/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5978 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1495/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5925 - loss: 0.6688 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1496/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5908 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1497/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6018 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1498/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6081 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1499/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5996 - loss: 0.6499 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1500/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6058 - loss: 0.6510 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1501/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6003 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1502/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6086 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1503/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6016 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1504/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6145 - loss: 0.6499 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1505/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6083 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1506/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6038 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1507/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6031 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1508/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6008 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1509/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5814 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1510/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5740 - loss: 0.6670 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1511/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6213 - loss: 0.6481 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1512/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5820 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1513/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5885 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1514/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5884 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1515/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5976 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1516/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5919 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1517/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5978 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1518/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6086 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1519/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6048 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1520/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6021 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1521/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6175 - loss: 0.6509 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1522/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5863 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1523/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5839 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1524/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6060 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 1525/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6165 - loss: 0.6484 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1526/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5931 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 1527/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5992 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1528/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5847 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1529/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6090 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1530/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5942 - loss: 0.6664 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1531/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5982 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1532/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6076 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1533/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6155 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1534/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5963 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1535/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5963 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1536/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5937 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1537/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6015 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1538/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5977 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1539/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5931 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1540/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5776 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1541/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5952 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1542/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5924 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1543/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5958 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1544/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5862 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1545/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5990 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1546/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6017 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1547/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6114 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1548/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6075 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1549/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6106 - loss: 0.6502 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1550/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6163 - loss: 0.6465 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1551/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5877 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1552/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5878 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1553/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5947 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1554/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5989 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1555/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5970 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1556/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5995 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1557/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6023 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1558/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5934 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1559/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6060 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1560/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5971 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1561/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5847 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1562/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6021 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1563/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5910 - loss: 0.6676 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1564/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6014 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1565/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5857 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1566/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5913 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1567/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5872 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1568/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5863 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1569/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6127 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1570/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5909 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1571/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6096 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1572/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6117 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1573/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1574/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5858 - loss: 0.6645 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1575/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6075 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1576/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5912 - loss: 0.6632 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1577/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5901 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1578/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5937 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1579/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6013 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1580/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5976 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1581/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6045 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1582/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1583/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5855 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1584/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5989 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1585/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6203 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1586/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6043 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1587/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5989 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1588/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6165 - loss: 0.6462 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1589/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6052 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1590/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5953 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1591/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5983 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1592/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6073 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1593/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6039 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1594/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6011 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1595/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5978 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1596/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6013 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1597/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6083 - loss: 0.6522 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1598/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5987 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1599/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5861 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1600/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6012 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1601/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5923 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1602/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5943 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1603/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6026 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1604/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5959 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1605/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5875 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1606/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6128 - loss: 0.6480 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1607/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6066 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1608/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6113 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1609/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5974 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1610/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5972 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1611/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5830 - loss: 0.6670 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1612/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5997 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1613/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6035 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1614/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5918 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1615/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5964 - loss: 0.6525 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1616/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5806 - loss: 0.6649 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1617/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6153 - loss: 0.6512 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1618/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5816 - loss: 0.6676 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1619/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5979 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1620/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6057 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1621/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5967 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1622/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5956 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1623/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5957 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1624/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6061 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1625/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5928 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1626/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6027 - loss: 0.6517 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1627/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5916 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1628/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5988 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1629/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6046 - loss: 0.6528 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1630/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6004 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1631/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5983 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1632/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5864 - loss: 0.6658 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1633/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5925 - loss: 0.6645 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1634/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5877 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1635/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6048 - loss: 0.6532 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1636/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5985 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1637/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6014 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1638/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6046 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1639/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6117 - loss: 0.6493 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1640/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6135 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1641/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5989 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1642/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5886 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1643/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5939 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1644/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6153 - loss: 0.6468 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1645/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5877 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1646/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5850 - loss: 0.6665 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1647/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5789 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1648/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5885 - loss: 0.6642 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1649/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6086 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1650/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5973 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1651/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6047 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1652/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5942 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1653/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5825 - loss: 0.6662 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1654/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5949 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1655/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6149 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1656/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1657/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5992 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1658/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6055 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1659/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5862 - loss: 0.6653 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1660/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6003 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1661/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6028 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1662/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6102 - loss: 0.6498 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1663/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5912 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1664/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6131 - loss: 0.6501 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1665/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6052 - loss: 0.6671 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1666/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5896 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1667/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6003 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1668/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5808 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1669/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5994 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1670/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6167 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1671/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6117 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1672/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5885 - loss: 0.6651 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1673/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5922 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1674/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5997 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1675/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5963 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1676/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6046 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1677/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5961 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1678/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6028 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1679/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6026 - loss: 0.6562 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1680/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5996 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1681/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5980 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1682/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6039 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1683/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5996 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1684/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5952 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1685/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1686/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5913 - loss: 0.6665 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1687/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6012 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1688/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6049 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1689/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5958 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1690/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5926 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1691/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5906 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1692/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5896 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1693/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5974 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1694/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6154 - loss: 0.6471 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1695/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5996 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1696/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6019 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1697/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5711 - loss: 0.6719 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1698/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5986 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1699/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6009 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1700/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6019 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1701/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5993 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1702/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5699 - loss: 0.6702 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1703/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6079 - loss: 0.6510 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1704/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6025 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1705/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6026 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1706/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6087 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1707/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5912 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1708/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6083 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1709/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5981 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1710/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5937 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1711/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6032 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1712/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5955 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1713/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1714/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6140 - loss: 0.6517 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1715/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6072 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1716/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5931 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1717/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6129 - loss: 0.6534 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1718/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6191 - loss: 0.6506 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1719/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6011 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1720/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6005 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1721/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5975 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1722/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5989 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1723/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5982 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1724/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5934 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1725/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1726/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6139 - loss: 0.6511 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1727/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6033 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1728/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6016 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1729/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6031 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1730/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5964 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1731/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5950 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1732/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5912 - loss: 0.6661 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1733/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6062 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1734/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6042 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1735/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6014 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1736/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5978 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1737/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5988 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1738/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5956 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1739/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6038 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1740/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5894 - loss: 0.6629 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1741/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6015 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1742/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6055 - loss: 0.6509 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1743/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6201 - loss: 0.6512 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1744/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5927 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1745/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6060 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1746/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5957 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1747/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5959 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1748/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6072 - loss: 0.6517 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1749/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6009 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1750/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6000 - loss: 0.6518 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1751/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5996 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1752/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6021 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1753/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5994 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1754/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6077 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1755/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5950 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1756/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6101 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1757/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6081 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1758/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5996 - loss: 0.6628 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1759/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5972 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1760/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5944 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1761/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5938 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1762/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5951 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1763/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5876 - loss: 0.6655 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1764/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6052 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1765/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6086 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1766/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5972 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1767/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6169 - loss: 0.6505 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1768/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5932 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1769/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6007 - loss: 0.6536 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1770/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5980 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1771/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6012 - loss: 0.6509 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1772/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5972 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1773/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6167 - loss: 0.6507 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1774/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5978 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1775/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5997 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1776/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6164 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1777/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5951 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1778/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6132 - loss: 0.6528 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1779/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6065 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1780/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6054 - loss: 0.6521 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1781/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6094 - loss: 0.6483 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1782/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5905 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1783/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5938 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1784/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6022 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1785/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5835 - loss: 0.6705 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1786/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5965 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1787/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5917 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1788/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5980 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1789/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6030 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1790/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5890 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1791/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5994 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1792/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5993 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1793/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6008 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1794/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5802 - loss: 0.6655 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1795/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6063 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1796/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6047 - loss: 0.6512 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1797/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5938 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1798/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6055 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1799/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6113 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1800/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6103 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1801/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6055 - loss: 0.6499 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1802/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5965 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1803/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6010 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1804/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5988 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1805/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5953 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1806/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5896 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1807/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5929 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1808/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5892 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1809/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6166 - loss: 0.6464 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1810/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5887 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1811/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1812/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6018 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1813/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6167 - loss: 0.6519 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1814/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5975 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1815/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5983 - loss: 0.6655 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1816/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6028 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1817/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5909 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1818/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5965 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1819/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6085 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1820/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5956 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1821/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6042 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1822/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5893 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1823/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5935 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1824/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6060 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1825/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5939 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1826/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5896 - loss: 0.6649 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1827/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6003 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1828/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5993 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1829/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6025 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1830/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6032 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1831/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5831 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1832/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6083 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1833/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6000 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1834/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6003 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1835/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5770 - loss: 0.6653 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 1836/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6063 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1837/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6046 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1838/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6038 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1839/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6000 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1840/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5967 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1841/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5760 - loss: 0.6693 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1842/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5994 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1843/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5991 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1844/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5975 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1845/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5936 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1846/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6005 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1847/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5856 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1848/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6098 - loss: 0.6516 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1849/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6025 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1850/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5936 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1851/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6003 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1852/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5877 - loss: 0.6682 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1853/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6035 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1854/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6183 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1855/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6058 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1856/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5968 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1857/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6156 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1858/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5940 - loss: 0.6601 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1859/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6016 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1860/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5775 - loss: 0.6627 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1861/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6129 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1862/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5894 - loss: 0.6657 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1863/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6097 - loss: 0.6479 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1864/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5970 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1865/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5983 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1866/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5953 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1867/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6241 - loss: 0.6491 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1868/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5909 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1869/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5940 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1870/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5870 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1871/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6032 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1872/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5957 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1873/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6038 - loss: 0.6487 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1874/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5958 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1875/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6053 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1876/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5928 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1877/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6013 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1878/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6050 - loss: 0.6532 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1879/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6044 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1880/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6026 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1881/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6055 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1882/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5931 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1883/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6031 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1884/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6010 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1885/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5938 - loss: 0.6660 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1886/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5953 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1887/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5949 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1888/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6058 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1889/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5905 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1890/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6042 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1891/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6070 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1892/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6019 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1893/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6067 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1894/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6094 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1895/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5939 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1896/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5999 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1897/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6025 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 1898/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6101 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 1899/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5998 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1900/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5975 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1901/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6022 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1902/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6074 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1903/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5950 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1904/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6129 - loss: 0.6531 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1905/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6148 - loss: 0.6518 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1906/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6086 - loss: 0.6503 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1907/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5928 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1908/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5887 - loss: 0.6646 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1909/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6186 - loss: 0.6466 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1910/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5864 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 1911/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5944 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1912/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6034 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1913/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5965 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1914/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6053 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1915/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5972 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1916/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5996 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1917/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6011 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1918/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5853 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1919/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6241 - loss: 0.6452 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1920/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5983 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1921/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6046 - loss: 0.6533 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1922/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6100 - loss: 0.6598 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1923/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5894 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1924/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5979 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1925/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5996 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1926/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6042 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1927/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5976 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1928/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5866 - loss: 0.6611 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1929/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5945 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1930/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6064 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1931/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6045 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1932/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5901 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1933/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5885 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1934/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6075 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1935/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5988 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1936/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5922 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1937/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6045 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1938/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5989 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1939/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6016 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1940/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6055 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1941/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5969 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1942/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6131 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1943/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5894 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1944/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5959 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1945/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5971 - loss: 0.6583 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1946/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6045 - loss: 0.6515 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1947/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6094 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1948/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5973 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1949/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6148 - loss: 0.6467 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1950/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5886 - loss: 0.6618 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1951/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5891 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1952/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6053 - loss: 0.6538 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1953/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6041 - loss: 0.6500 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1954/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5942 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1955/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5909 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1956/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6006 - loss: 0.6609 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1957/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6029 - loss: 0.6559 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1958/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6136 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1959/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6058 - loss: 0.6529 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1960/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6135 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1961/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5885 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1962/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5991 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1963/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6043 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1964/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6007 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1965/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6096 - loss: 0.6519 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 1966/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6130 - loss: 0.6498 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1967/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6117 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1968/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5974 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1969/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5930 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1970/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6164 - loss: 0.6504 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1971/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6027 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1972/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5903 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1973/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5883 - loss: 0.6625 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1974/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5896 - loss: 0.6579 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1975/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5929 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1976/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5959 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1977/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6044 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 1978/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6093 - loss: 0.6524 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1979/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5986 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1980/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6053 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1981/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1982/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5944 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1983/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5996 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1984/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6084 - loss: 0.6537 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1985/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5978 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1986/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6028 - loss: 0.6515 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1987/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6101 - loss: 0.6518 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1988/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5888 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1989/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5930 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1990/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5976 - loss: 0.6643 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 1991/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6124 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1992/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5910 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1993/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5996 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1994/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6051 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 1995/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6133 - loss: 0.6517 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 1996/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6116 - loss: 0.6526 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1997/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5922 - loss: 0.6638 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 1998/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5982 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 1999/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6020 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2000/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6086 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2001/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6010 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2002/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6052 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2003/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6048 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2004/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5802 - loss: 0.6680 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2005/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5962 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2006/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5964 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2007/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6055 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2008/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5947 - loss: 0.6634 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2009/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6141 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2010/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5932 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2011/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6041 - loss: 0.6551 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2012/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6008 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2013/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6070 - loss: 0.6482 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2014/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6055 - loss: 0.6520 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2015/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5858 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2016/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5971 - loss: 0.6635 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2017/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5910 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2018/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6126 - loss: 0.6607 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2019/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6128 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2020/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5962 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2021/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5974 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2022/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6078 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2023/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6020 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2024/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5804 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2025/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5932 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2026/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6144 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2027/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5980 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2028/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6185 - loss: 0.6492 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2029/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5874 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2030/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5977 - loss: 0.6556 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2031/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5936 - loss: 0.6603 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2032/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5994 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2033/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5994 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2034/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5975 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2035/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6104 - loss: 0.6506 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2036/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6123 - loss: 0.6514 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2037/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5906 - loss: 0.6674 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2038/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6139 - loss: 0.6489 - val_accuracy: 0.6114 - val_loss: 0.6608\n",
            "Epoch 2039/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6167 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2040/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6041 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2041/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5963 - loss: 0.6620 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2042/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6007 - loss: 0.6569 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2043/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5943 - loss: 0.6595 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2044/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6053 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2045/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6020 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2046/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5959 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2047/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5890 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2048/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6071 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2049/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5989 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2050/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6200 - loss: 0.6501 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2051/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5905 - loss: 0.6615 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2052/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6000 - loss: 0.6571 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2053/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5921 - loss: 0.6575 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2054/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5891 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2055/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5956 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2056/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5964 - loss: 0.6650 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2057/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6040 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2058/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5996 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2059/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5871 - loss: 0.6637 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2060/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5998 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2061/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6082 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2062/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5995 - loss: 0.6587 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2063/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6059 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2064/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6065 - loss: 0.6608 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2065/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6105 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2066/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6002 - loss: 0.6581 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2067/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6054 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2068/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6045 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2069/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5940 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2070/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5980 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2071/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6088 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2072/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6039 - loss: 0.6541 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2073/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5977 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2074/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6042 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2075/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6030 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2076/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5933 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2077/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5954 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 2078/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6026 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2079/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6172 - loss: 0.6464 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2080/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6103 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2081/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5994 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2082/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6039 - loss: 0.6522 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2083/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6019 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2084/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5826 - loss: 0.6677 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2085/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5934 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2086/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5968 - loss: 0.6580 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2087/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6121 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2088/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5934 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2089/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6088 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2090/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6066 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2091/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6098 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2092/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6086 - loss: 0.6557 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2093/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5957 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2094/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6041 - loss: 0.6599 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2095/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5801 - loss: 0.6676 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2096/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6108 - loss: 0.6619 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2097/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6015 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2098/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5831 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2099/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5917 - loss: 0.6597 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2100/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6030 - loss: 0.6536 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2101/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6055 - loss: 0.6499 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2102/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6017 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2103/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6092 - loss: 0.6509 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2104/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5982 - loss: 0.6584 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2105/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6054 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2106/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5999 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2107/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5986 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2108/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5914 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2109/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5981 - loss: 0.6550 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2110/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6066 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2111/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6166 - loss: 0.6510 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2112/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6138 - loss: 0.6507 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2113/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5919 - loss: 0.6652 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2114/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5984 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2115/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5854 - loss: 0.6671 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2116/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5963 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2117/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5986 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2118/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5930 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2119/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5977 - loss: 0.6591 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2120/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6061 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 2121/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5983 - loss: 0.6616 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2122/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6133 - loss: 0.6479 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 2123/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6053 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 2124/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5953 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6597\n",
            "Epoch 2125/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5913 - loss: 0.6640 - val_accuracy: 0.6114 - val_loss: 0.6596\n",
            "Epoch 2126/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6050 - loss: 0.6539 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 2127/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6046 - loss: 0.6549 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 2128/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6058 - loss: 0.6568 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 2129/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6039 - loss: 0.6593 - val_accuracy: 0.6114 - val_loss: 0.6599\n",
            "Epoch 2130/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5922 - loss: 0.6645 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 2131/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6104 - loss: 0.6576 - val_accuracy: 0.6114 - val_loss: 0.6598\n",
            "Epoch 2132/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6013 - loss: 0.6530 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2133/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6025 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2134/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5950 - loss: 0.6565 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2135/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5922 - loss: 0.6602 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2136/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5978 - loss: 0.6566 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2137/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5996 - loss: 0.6664 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2138/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6134 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2139/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6042 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2140/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6012 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2141/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6034 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2142/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5921 - loss: 0.6631 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2143/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5953 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2144/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6019 - loss: 0.6547 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2145/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6007 - loss: 0.6555 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2146/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6088 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2147/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6004 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2148/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5963 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2149/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6095 - loss: 0.6552 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2150/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5939 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2151/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 2152/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6087 - loss: 0.6558 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2153/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6024 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2154/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6093 - loss: 0.6527 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2155/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6136 - loss: 0.6497 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2156/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5998 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2157/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5894 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2158/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2159/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5920 - loss: 0.6621 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2160/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6126 - loss: 0.6511 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2161/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6045 - loss: 0.6535 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2162/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6013 - loss: 0.6578 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2163/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6066 - loss: 0.6525 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2164/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6095 - loss: 0.6554 - val_accuracy: 0.6114 - val_loss: 0.6609\n",
            "Epoch 2165/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5950 - loss: 0.6633 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2166/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5976 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 2167/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5969 - loss: 0.6600 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2168/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6016 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2169/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6079 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2170/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6135 - loss: 0.6517 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2171/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5990 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6606\n",
            "Epoch 2172/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5891 - loss: 0.6714 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 2173/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6007 - loss: 0.6543 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2174/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6137 - loss: 0.6553 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2175/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6191 - loss: 0.6492 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2176/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6026 - loss: 0.6588 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2177/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5980 - loss: 0.6636 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2178/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5949 - loss: 0.6574 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2179/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6047 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2180/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6094 - loss: 0.6509 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2181/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6088 - loss: 0.6563 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2182/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6012 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2183/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5956 - loss: 0.6606 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2184/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6027 - loss: 0.6532 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2185/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5905 - loss: 0.6623 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2186/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6045 - loss: 0.6548 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2187/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6062 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2188/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 0.6641 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2189/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5989 - loss: 0.6564 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2190/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6003 - loss: 0.6586 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2191/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5991 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2192/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6074 - loss: 0.6546 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2193/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5914 - loss: 0.6605 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2194/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6056 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2195/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5960 - loss: 0.6561 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2196/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5945 - loss: 0.6617 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2197/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6123 - loss: 0.6582 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2198/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6021 - loss: 0.6567 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2199/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6053 - loss: 0.6585 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2200/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6002 - loss: 0.6592 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2201/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5874 - loss: 0.6645 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2202/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5997 - loss: 0.6545 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2203/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6012 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2204/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5936 - loss: 0.6624 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2205/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5963 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2206/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5903 - loss: 0.6668 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2207/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6050 - loss: 0.6540 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2208/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5972 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2209/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6079 - loss: 0.6525 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2210/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5911 - loss: 0.6614 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2211/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6112 - loss: 0.6560 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2212/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6122 - loss: 0.6570 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2213/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6212 - loss: 0.6463 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2214/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5802 - loss: 0.6673 - val_accuracy: 0.6114 - val_loss: 0.6600\n",
            "Epoch 2215/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5970 - loss: 0.6612 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2216/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6077 - loss: 0.6501 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2217/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5944 - loss: 0.6604 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2218/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5952 - loss: 0.6626 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2219/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5850 - loss: 0.6670 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2220/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5873 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6607\n",
            "Epoch 2221/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5994 - loss: 0.6511 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2222/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6027 - loss: 0.6577 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2223/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6004 - loss: 0.6572 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2224/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6589 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2225/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6089 - loss: 0.6490 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2226/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6121 - loss: 0.6516 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2227/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6079 - loss: 0.6523 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2228/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5981 - loss: 0.6613 - val_accuracy: 0.6114 - val_loss: 0.6601\n",
            "Epoch 2229/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6010 - loss: 0.6594 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2230/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6126 - loss: 0.6502 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2231/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5936 - loss: 0.6610 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2232/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5998 - loss: 0.6590 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2233/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6015 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6605\n",
            "Epoch 2234/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6068 - loss: 0.6542 - val_accuracy: 0.6114 - val_loss: 0.6603\n",
            "Epoch 2235/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5965 - loss: 0.6596 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2236/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6184 - loss: 0.6532 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2237/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5888 - loss: 0.6639 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2238/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5884 - loss: 0.6622 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2239/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6004 - loss: 0.6573 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2240/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6075 - loss: 0.6544 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2241/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5969 - loss: 0.6647 - val_accuracy: 0.6114 - val_loss: 0.6602\n",
            "Epoch 2242/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5937 - loss: 0.6653 - val_accuracy: 0.6114 - val_loss: 0.6604\n",
            "Epoch 2243/5000\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6050 - loss: 0.6587"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1cc47efa2061>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Train the RNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mrnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    343\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     )\n\u001b[0;32m--> 345\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    346\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   function = trace_function(\n\u001b[0m\u001b[1;32m    133\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolymorphic_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m   )\n\u001b[1;32m    212\u001b[0m   \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mis_pure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mis_pure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMPLEMENTS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#RNN 5000 epochs\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def preprocess_lstm_data(input_data, labels):\n",
        "    sequences = []\n",
        "    for row in input_data:\n",
        "        subwords = [float(x) for x in row.split(';')]\n",
        "        sequences.append(subwords)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    return np.array(sequences), labels, label_encoder\n",
        "\n",
        "input_data = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            input_data.append(subwords)\n",
        "            labels.append(label)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "input_data, labels, label_encoder = preprocess_lstm_data(input_data, labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_data, labels, test_size=0.2, random_state=60)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "#LSTM model\n",
        "def build_rnn(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "rnn_model = build_rnn((X_train.shape[1], X_train.shape[2]))\n",
        "rnn_model.fit(X_train, y_train, epochs=5000, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "y_pred = (rnn_model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"RNN Model Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN 30 epochs\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def preprocess_cnn_data(input_data, labels):\n",
        "    sequences = []\n",
        "    for row in input_data:\n",
        "        try:\n",
        "            subwords = [float(x) for x in row.split(';') if x.strip()]\n",
        "            sequences.append(subwords)\n",
        "        except ValueError:\n",
        "            print(f\"Skipping invalid sequence: {row}\")\n",
        "\n",
        "    #ensure consistent sequence length by padding\n",
        "    max_len = max(len(seq) for seq in sequences) if sequences else 0\n",
        "    if max_len == 0:\n",
        "        raise ValueError(\"All sequences are empty. Check input data formatting.\")\n",
        "    sequences = [seq + [0] * (max_len - len(seq)) for seq in sequences]\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    return np.array(sequences), labels, label_encoder\n",
        "\n",
        "input_data = []\n",
        "labels = []\n",
        "\n",
        "with open('lamstar_input_labeled.txt', 'r') as file:\n",
        "    next(file)\n",
        "    for line in file:\n",
        "        try:\n",
        "            segment, subwords, label = line.strip().split('\\t')\n",
        "            input_data.append(subwords)\n",
        "            labels.append(label)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid line skipped: {line.strip()}\")\n",
        "\n",
        "input_data, labels, label_encoder = preprocess_cnn_data(input_data, labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(32, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Conv1D(16, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(8, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model = build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "cnn_model.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "y_pred = (cnn_model.predict(X_test) > 0.5).astype(int).flatten()\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "GK8nJUO91rlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "57955201-33d5-48f9-deaf-3726cfe335f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'lamstar_input_labeled.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-253bb158fc32>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lamstar_input_labeled.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lamstar_input_labeled.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN 50 epochs\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def load_data(file_path):\n",
        "    input_data = []\n",
        "    labels = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        next(file)\n",
        "        for line in file:\n",
        "            try:\n",
        "                segment, subwords, label = line.strip().split('\\t')\n",
        "                subword1, subword2 = map(float, subwords.split(';'))\n",
        "                input_data.append([subword1, subword2])\n",
        "                labels.append(label)\n",
        "            except ValueError:\n",
        "                print(f\"Invalid line skipped: {line.strip()}\")\n",
        "    return np.array(input_data), np.array(labels)\n",
        "\n",
        "file_path = 'lamstar_input_labeled.txt'\n",
        "input_data, labels = load_data(file_path)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "categorical_labels = to_categorical(encoded_labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    input_data, categorical_labels, test_size=0.2, random_state=60\n",
        ")\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n",
        "#CNN model\n",
        "def build_cnn(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv1D(32, kernel_size=1, activation='relu')(inputs)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "cnn_model = build_cnn(X_train.shape[1:], num_classes=categorical_labels.shape[1])\n",
        "cnn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, accuracy = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"CNN Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T13SSYhzZz8I",
        "outputId": "d7ba0bfc-d89e-429f-d61f-1b48d7c52ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5565 - loss: 13.2274 - val_accuracy: 0.5829 - val_loss: 3.6360\n",
            "Epoch 2/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5956 - loss: 5.7707 - val_accuracy: 0.5829 - val_loss: 4.0917\n",
            "Epoch 3/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5627 - loss: 5.0714 - val_accuracy: 0.5829 - val_loss: 1.3610\n",
            "Epoch 4/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5700 - loss: 1.6350 - val_accuracy: 0.5829 - val_loss: 1.0800\n",
            "Epoch 5/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5950 - loss: 0.8269 - val_accuracy: 0.5489 - val_loss: 0.6841\n",
            "Epoch 6/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5711 - loss: 0.6705 - val_accuracy: 0.5489 - val_loss: 0.6832\n",
            "Epoch 7/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5693 - loss: 0.6738 - val_accuracy: 0.5829 - val_loss: 0.6769\n",
            "Epoch 8/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5753 - loss: 0.6585 - val_accuracy: 0.5000 - val_loss: 0.6922\n",
            "Epoch 9/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5607 - loss: 0.6730 - val_accuracy: 0.5829 - val_loss: 0.6741\n",
            "Epoch 10/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5836 - loss: 0.6707 - val_accuracy: 0.5788 - val_loss: 0.6721\n",
            "Epoch 11/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6078 - loss: 0.6662 - val_accuracy: 0.5788 - val_loss: 0.6697\n",
            "Epoch 12/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6141 - loss: 0.6743 - val_accuracy: 0.5788 - val_loss: 0.6689\n",
            "Epoch 13/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.6702 - val_accuracy: 0.5788 - val_loss: 0.6693\n",
            "Epoch 14/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5908 - loss: 0.6672 - val_accuracy: 0.5788 - val_loss: 0.6678\n",
            "Epoch 15/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6079 - loss: 0.6654 - val_accuracy: 0.5788 - val_loss: 0.6735\n",
            "Epoch 16/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5868 - loss: 0.6616 - val_accuracy: 0.5788 - val_loss: 0.6715\n",
            "Epoch 17/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6096 - loss: 0.6663 - val_accuracy: 0.5788 - val_loss: 0.6673\n",
            "Epoch 18/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5999 - loss: 0.6688 - val_accuracy: 0.5788 - val_loss: 0.6663\n",
            "Epoch 19/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 0.6680 - val_accuracy: 0.5788 - val_loss: 0.6671\n",
            "Epoch 20/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6188 - loss: 0.6685 - val_accuracy: 0.5788 - val_loss: 0.6659\n",
            "Epoch 21/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5997 - loss: 0.6644 - val_accuracy: 0.5788 - val_loss: 0.6666\n",
            "Epoch 22/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5848 - loss: 0.6628 - val_accuracy: 0.5788 - val_loss: 0.6693\n",
            "Epoch 23/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 0.6691 - val_accuracy: 0.5788 - val_loss: 0.6661\n",
            "Epoch 24/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 0.6663 - val_accuracy: 0.5788 - val_loss: 0.6735\n",
            "Epoch 25/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 0.6662 - val_accuracy: 0.5788 - val_loss: 0.6745\n",
            "Epoch 26/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5910 - loss: 0.6747 - val_accuracy: 0.5788 - val_loss: 0.6739\n",
            "Epoch 27/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: 0.6709 - val_accuracy: 0.5829 - val_loss: 0.6736\n",
            "Epoch 28/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5981 - loss: 0.6666 - val_accuracy: 0.5788 - val_loss: 0.6733\n",
            "Epoch 29/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6006 - loss: 0.6638 - val_accuracy: 0.5788 - val_loss: 0.6742\n",
            "Epoch 30/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5959 - loss: 0.6647 - val_accuracy: 0.5788 - val_loss: 0.6733\n",
            "Epoch 31/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.6692 - val_accuracy: 0.5788 - val_loss: 0.6669\n",
            "Epoch 32/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5688 - loss: 0.7175 - val_accuracy: 0.5788 - val_loss: 0.6751\n",
            "Epoch 33/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5998 - loss: 0.6678 - val_accuracy: 0.5788 - val_loss: 0.6747\n",
            "Epoch 34/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6007 - loss: 0.6690 - val_accuracy: 0.5788 - val_loss: 0.6748\n",
            "Epoch 35/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 0.6777 - val_accuracy: 0.5788 - val_loss: 0.6740\n",
            "Epoch 36/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 0.6661 - val_accuracy: 0.5788 - val_loss: 0.6748\n",
            "Epoch 37/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.6715 - val_accuracy: 0.5788 - val_loss: 0.6741\n",
            "Epoch 38/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 0.6634 - val_accuracy: 0.5788 - val_loss: 0.6734\n",
            "Epoch 39/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5882 - loss: 0.6720 - val_accuracy: 0.5788 - val_loss: 0.6737\n",
            "Epoch 40/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5712 - loss: 0.7562 - val_accuracy: 0.5788 - val_loss: 0.6750\n",
            "Epoch 41/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.6692 - val_accuracy: 0.5788 - val_loss: 0.6743\n",
            "Epoch 42/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5775 - loss: 0.6739 - val_accuracy: 0.5788 - val_loss: 0.6748\n",
            "Epoch 43/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5918 - loss: 0.6724 - val_accuracy: 0.5788 - val_loss: 0.6746\n",
            "Epoch 44/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.6695 - val_accuracy: 0.5788 - val_loss: 0.6764\n",
            "Epoch 45/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5768 - loss: 0.6747 - val_accuracy: 0.5788 - val_loss: 0.6741\n",
            "Epoch 46/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5726 - loss: 0.6795 - val_accuracy: 0.5788 - val_loss: 0.6746\n",
            "Epoch 47/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 0.6743 - val_accuracy: 0.5788 - val_loss: 0.6741\n",
            "Epoch 48/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6034 - loss: 0.6675 - val_accuracy: 0.5788 - val_loss: 0.6758\n",
            "Epoch 49/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5874 - loss: 0.6687 - val_accuracy: 0.5788 - val_loss: 0.6763\n",
            "Epoch 50/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5887 - loss: 0.6721 - val_accuracy: 0.5788 - val_loss: 0.6775\n",
            "CNN Model Accuracy: 0.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"CNN Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "y_pred_probs = cnn_model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "class_report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYVaD92ofG-t",
        "outputId": "e15d6ed2-af48-4edd-af60-af2f558e511e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Model Accuracy: 0.62\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "\n",
            "Confusion Matrix:\n",
            "[[261 184]\n",
            " [169 306]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   epileptic       0.61      0.59      0.60       445\n",
            "     healthy       0.62      0.64      0.63       475\n",
            "\n",
            "    accuracy                           0.62       920\n",
            "   macro avg       0.62      0.62      0.62       920\n",
            "weighted avg       0.62      0.62      0.62       920\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN 500 epochs\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def load_data(file_path):\n",
        "    input_data = []\n",
        "    labels = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        next(file)\n",
        "        for line in file:\n",
        "            try:\n",
        "                segment, subwords, label = line.strip().split('\\t')\n",
        "                subword1, subword2 = map(float, subwords.split(';'))\n",
        "                input_data.append([subword1, subword2])\n",
        "                labels.append(label)\n",
        "            except ValueError:\n",
        "                print(f\"Invalid line skipped: {line.strip()}\")\n",
        "    return np.array(input_data), np.array(labels)\n",
        "\n",
        "file_path = 'lamstar_input_labeled.txt'\n",
        "input_data, labels = load_data(file_path)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "categorical_labels = to_categorical(encoded_labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    input_data, categorical_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n",
        "def build_cnn(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv1D(32, kernel_size=1, activation='relu')(inputs)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "cnn_model = build_cnn(X_train.shape[1:], num_classes=categorical_labels.shape[1])\n",
        "cnn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=500,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, accuracy = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"CNN Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "y_pred_probs = cnn_model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "class_report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXcCclyTho86",
        "outputId": "fbd690ce-672c-4719-824c-44aeb97edd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5018 - loss: 30.7444 - val_accuracy: 0.5924 - val_loss: 2.5560\n",
            "Epoch 2/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5826 - loss: 7.8859 - val_accuracy: 0.5978 - val_loss: 1.8893\n",
            "Epoch 3/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5770 - loss: 6.5093 - val_accuracy: 0.5978 - val_loss: 2.0265\n",
            "Epoch 4/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5861 - loss: 4.9560 - val_accuracy: 0.5978 - val_loss: 1.0774\n",
            "Epoch 5/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 1.8692 - val_accuracy: 0.5978 - val_loss: 0.7831\n",
            "Epoch 6/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5868 - loss: 1.2166 - val_accuracy: 0.5978 - val_loss: 0.7187\n",
            "Epoch 7/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5756 - loss: 0.8092 - val_accuracy: 0.5842 - val_loss: 0.6607\n",
            "Epoch 8/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5529 - loss: 0.6840 - val_accuracy: 0.5842 - val_loss: 0.6739\n",
            "Epoch 9/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5607 - loss: 0.6840 - val_accuracy: 0.5842 - val_loss: 0.6596\n",
            "Epoch 10/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5884 - loss: 0.6828 - val_accuracy: 0.5978 - val_loss: 0.6635\n",
            "Epoch 11/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5912 - loss: 0.6824 - val_accuracy: 0.5978 - val_loss: 0.6656\n",
            "Epoch 12/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5919 - loss: 0.6762 - val_accuracy: 0.5978 - val_loss: 0.6622\n",
            "Epoch 13/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6015 - loss: 0.6743 - val_accuracy: 0.5924 - val_loss: 0.6676\n",
            "Epoch 14/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5794 - loss: 0.6830 - val_accuracy: 0.5924 - val_loss: 0.6618\n",
            "Epoch 15/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5670 - loss: 0.6769 - val_accuracy: 0.5978 - val_loss: 0.6643\n",
            "Epoch 16/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5807 - loss: 0.6758 - val_accuracy: 0.5978 - val_loss: 0.6678\n",
            "Epoch 17/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 0.6726 - val_accuracy: 0.5978 - val_loss: 0.6605\n",
            "Epoch 18/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5831 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6634\n",
            "Epoch 19/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.6679 - val_accuracy: 0.5924 - val_loss: 0.6630\n",
            "Epoch 20/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5824 - loss: 0.6725 - val_accuracy: 0.5978 - val_loss: 0.6614\n",
            "Epoch 21/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5886 - loss: 0.6660 - val_accuracy: 0.5924 - val_loss: 0.6627\n",
            "Epoch 22/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 0.6682 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 23/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5720 - loss: 0.6751 - val_accuracy: 0.5924 - val_loss: 0.6601\n",
            "Epoch 24/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5835 - loss: 0.6731 - val_accuracy: 0.5924 - val_loss: 0.6637\n",
            "Epoch 25/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5749 - loss: 0.6731 - val_accuracy: 0.5978 - val_loss: 0.6710\n",
            "Epoch 26/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5623 - loss: 0.6806 - val_accuracy: 0.5978 - val_loss: 0.6606\n",
            "Epoch 27/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5716 - loss: 0.6827 - val_accuracy: 0.5978 - val_loss: 0.6689\n",
            "Epoch 28/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5920 - loss: 0.6722 - val_accuracy: 0.5978 - val_loss: 0.6651\n",
            "Epoch 29/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 0.6736 - val_accuracy: 0.5924 - val_loss: 0.6591\n",
            "Epoch 30/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5678 - loss: 0.6741 - val_accuracy: 0.5978 - val_loss: 0.6643\n",
            "Epoch 31/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5835 - loss: 0.6684 - val_accuracy: 0.5978 - val_loss: 0.6634\n",
            "Epoch 32/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 0.6716 - val_accuracy: 0.5978 - val_loss: 0.6600\n",
            "Epoch 33/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5867 - loss: 0.6663 - val_accuracy: 0.5978 - val_loss: 0.6596\n",
            "Epoch 34/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5864 - loss: 0.6720 - val_accuracy: 0.5924 - val_loss: 0.6638\n",
            "Epoch 35/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5761 - loss: 0.6680 - val_accuracy: 0.5924 - val_loss: 0.6614\n",
            "Epoch 36/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5905 - loss: 0.6701 - val_accuracy: 0.5978 - val_loss: 0.6694\n",
            "Epoch 37/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5810 - loss: 0.6706 - val_accuracy: 0.5924 - val_loss: 0.6703\n",
            "Epoch 38/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5781 - loss: 0.6759 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 39/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5886 - loss: 0.6737 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 40/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5712 - loss: 0.6765 - val_accuracy: 0.5978 - val_loss: 0.6684\n",
            "Epoch 41/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5742 - loss: 0.6731 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 42/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5675 - loss: 0.6737 - val_accuracy: 0.5978 - val_loss: 0.6681\n",
            "Epoch 43/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5786 - loss: 0.6734 - val_accuracy: 0.5924 - val_loss: 0.6564\n",
            "Epoch 44/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5722 - loss: 0.7096 - val_accuracy: 0.5924 - val_loss: 0.6731\n",
            "Epoch 45/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 0.6754 - val_accuracy: 0.5924 - val_loss: 0.6728\n",
            "Epoch 46/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5910 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6751\n",
            "Epoch 47/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5955 - loss: 0.6741 - val_accuracy: 0.5924 - val_loss: 0.6717\n",
            "Epoch 48/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5792 - loss: 0.6751 - val_accuracy: 0.5924 - val_loss: 0.6712\n",
            "Epoch 49/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5837 - loss: 0.6764 - val_accuracy: 0.5924 - val_loss: 0.6715\n",
            "Epoch 50/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5746 - loss: 0.6778 - val_accuracy: 0.5924 - val_loss: 0.6700\n",
            "Epoch 51/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5684 - loss: 0.6779 - val_accuracy: 0.5924 - val_loss: 0.6714\n",
            "Epoch 52/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.7471 - val_accuracy: 0.5924 - val_loss: 0.6738\n",
            "Epoch 53/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.6733 - val_accuracy: 0.5924 - val_loss: 0.6728\n",
            "Epoch 54/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5794 - loss: 0.6774 - val_accuracy: 0.5924 - val_loss: 0.6720\n",
            "Epoch 55/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5770 - loss: 0.6757 - val_accuracy: 0.5924 - val_loss: 0.6713\n",
            "Epoch 56/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5736 - loss: 0.6802 - val_accuracy: 0.5924 - val_loss: 0.6718\n",
            "Epoch 57/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6012 - loss: 0.6705 - val_accuracy: 0.5924 - val_loss: 0.6713\n",
            "Epoch 58/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5828 - loss: 0.6739 - val_accuracy: 0.5924 - val_loss: 0.6732\n",
            "Epoch 59/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5763 - loss: 0.6780 - val_accuracy: 0.5924 - val_loss: 0.6725\n",
            "Epoch 60/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5655 - loss: 0.6822 - val_accuracy: 0.5924 - val_loss: 0.6717\n",
            "Epoch 61/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5699 - loss: 0.6796 - val_accuracy: 0.5924 - val_loss: 0.6716\n",
            "Epoch 62/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5707 - loss: 0.6836 - val_accuracy: 0.5924 - val_loss: 0.6719\n",
            "Epoch 63/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5802 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6712\n",
            "Epoch 64/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5599 - loss: 0.6869 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 65/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5828 - loss: 0.6787 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 66/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5910 - loss: 0.6758 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 67/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5902 - loss: 0.6739 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 68/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 0.6716 - val_accuracy: 0.5924 - val_loss: 0.6722\n",
            "Epoch 69/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5751 - loss: 0.6797 - val_accuracy: 0.5924 - val_loss: 0.6707\n",
            "Epoch 70/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5771 - loss: 0.6828 - val_accuracy: 0.5924 - val_loss: 0.6713\n",
            "Epoch 71/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.6761 - val_accuracy: 0.5924 - val_loss: 0.6703\n",
            "Epoch 72/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5712 - loss: 0.6833 - val_accuracy: 0.5924 - val_loss: 0.6717\n",
            "Epoch 73/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5724 - loss: 0.6786 - val_accuracy: 0.5924 - val_loss: 0.6717\n",
            "Epoch 74/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5780 - loss: 0.6761 - val_accuracy: 0.5924 - val_loss: 0.6711\n",
            "Epoch 75/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5887 - loss: 0.6756 - val_accuracy: 0.5924 - val_loss: 0.6732\n",
            "Epoch 76/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5795 - loss: 0.6762 - val_accuracy: 0.5924 - val_loss: 0.6727\n",
            "Epoch 77/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5630 - loss: 0.6805 - val_accuracy: 0.5924 - val_loss: 0.6703\n",
            "Epoch 78/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5733 - loss: 0.6815 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 79/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5871 - loss: 0.6734 - val_accuracy: 0.5924 - val_loss: 0.6729\n",
            "Epoch 80/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5752 - loss: 0.6776 - val_accuracy: 0.5924 - val_loss: 0.6714\n",
            "Epoch 81/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5756 - loss: 0.6818 - val_accuracy: 0.5924 - val_loss: 0.6718\n",
            "Epoch 82/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5811 - loss: 0.6747 - val_accuracy: 0.5924 - val_loss: 0.6718\n",
            "Epoch 83/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5846 - loss: 0.6743 - val_accuracy: 0.5924 - val_loss: 0.6707\n",
            "Epoch 84/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 0.6776 - val_accuracy: 0.5924 - val_loss: 0.6716\n",
            "Epoch 85/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.6759 - val_accuracy: 0.5924 - val_loss: 0.6726\n",
            "Epoch 86/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 0.6751 - val_accuracy: 0.5924 - val_loss: 0.6745\n",
            "Epoch 87/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5704 - loss: 0.6801 - val_accuracy: 0.5924 - val_loss: 0.6739\n",
            "Epoch 88/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.7015 - val_accuracy: 0.5924 - val_loss: 0.6751\n",
            "Epoch 89/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5719 - loss: 0.6822 - val_accuracy: 0.5924 - val_loss: 0.6741\n",
            "Epoch 90/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.6726 - val_accuracy: 0.5924 - val_loss: 0.6731\n",
            "Epoch 91/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5864 - loss: 0.6724 - val_accuracy: 0.5924 - val_loss: 0.6745\n",
            "Epoch 92/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5660 - loss: 0.6818 - val_accuracy: 0.5924 - val_loss: 0.6726\n",
            "Epoch 93/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5719 - loss: 0.6839 - val_accuracy: 0.5924 - val_loss: 0.6724\n",
            "Epoch 94/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5695 - loss: 0.6802 - val_accuracy: 0.5924 - val_loss: 0.6724\n",
            "Epoch 95/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5734 - loss: 0.6788 - val_accuracy: 0.5924 - val_loss: 0.6722\n",
            "Epoch 96/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5823 - loss: 0.6753 - val_accuracy: 0.5924 - val_loss: 0.6718\n",
            "Epoch 97/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5795 - loss: 0.6782 - val_accuracy: 0.5924 - val_loss: 0.6734\n",
            "Epoch 98/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5959 - loss: 0.6726 - val_accuracy: 0.5924 - val_loss: 0.6726\n",
            "Epoch 99/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5825 - loss: 0.6735 - val_accuracy: 0.5924 - val_loss: 0.6718\n",
            "Epoch 100/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5695 - loss: 0.6817 - val_accuracy: 0.5924 - val_loss: 0.6711\n",
            "Epoch 101/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5565 - loss: 0.6866 - val_accuracy: 0.5924 - val_loss: 0.6735\n",
            "Epoch 102/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5762 - loss: 0.6774 - val_accuracy: 0.5924 - val_loss: 0.6720\n",
            "Epoch 103/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5893 - loss: 0.6761 - val_accuracy: 0.5924 - val_loss: 0.6707\n",
            "Epoch 104/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5908 - loss: 0.6745 - val_accuracy: 0.5924 - val_loss: 0.6709\n",
            "Epoch 105/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: 0.6690 - val_accuracy: 0.5924 - val_loss: 0.6714\n",
            "Epoch 106/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5694 - loss: 0.6804 - val_accuracy: 0.5924 - val_loss: 0.6706\n",
            "Epoch 107/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5869 - loss: 0.6744 - val_accuracy: 0.5924 - val_loss: 0.6723\n",
            "Epoch 108/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 0.6777 - val_accuracy: 0.5924 - val_loss: 0.6711\n",
            "Epoch 109/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5844 - loss: 0.6783 - val_accuracy: 0.5924 - val_loss: 0.6724\n",
            "Epoch 110/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5831 - loss: 0.6737 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 111/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5812 - loss: 0.6802 - val_accuracy: 0.5924 - val_loss: 0.6709\n",
            "Epoch 112/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5893 - loss: 0.6754 - val_accuracy: 0.5924 - val_loss: 0.6709\n",
            "Epoch 113/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5956 - loss: 0.6735 - val_accuracy: 0.5924 - val_loss: 0.6724\n",
            "Epoch 114/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5846 - loss: 0.6780 - val_accuracy: 0.5924 - val_loss: 0.6718\n",
            "Epoch 115/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5835 - loss: 0.6739 - val_accuracy: 0.5924 - val_loss: 0.6720\n",
            "Epoch 116/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5860 - loss: 0.6734 - val_accuracy: 0.5924 - val_loss: 0.6723\n",
            "Epoch 117/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5782 - loss: 0.6789 - val_accuracy: 0.5924 - val_loss: 0.6712\n",
            "Epoch 118/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5750 - loss: 0.6763 - val_accuracy: 0.5924 - val_loss: 0.6707\n",
            "Epoch 119/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5810 - loss: 0.6785 - val_accuracy: 0.5924 - val_loss: 0.6712\n",
            "Epoch 120/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 0.6753 - val_accuracy: 0.5924 - val_loss: 0.6709\n",
            "Epoch 121/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5832 - loss: 0.6749 - val_accuracy: 0.5924 - val_loss: 0.6709\n",
            "Epoch 122/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5769 - loss: 0.6786 - val_accuracy: 0.5924 - val_loss: 0.6717\n",
            "Epoch 123/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5810 - loss: 0.6752 - val_accuracy: 0.5924 - val_loss: 0.6707\n",
            "Epoch 124/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5933 - loss: 0.6752 - val_accuracy: 0.5924 - val_loss: 0.6720\n",
            "Epoch 125/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5812 - loss: 0.6776 - val_accuracy: 0.5924 - val_loss: 0.6720\n",
            "Epoch 126/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5616 - loss: 0.6808 - val_accuracy: 0.5924 - val_loss: 0.6712\n",
            "Epoch 127/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5840 - loss: 0.6786 - val_accuracy: 0.5924 - val_loss: 0.6719\n",
            "Epoch 128/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5716 - loss: 0.6779 - val_accuracy: 0.5924 - val_loss: 0.6725\n",
            "Epoch 129/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5941 - loss: 0.6749 - val_accuracy: 0.5924 - val_loss: 0.6718\n",
            "Epoch 130/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 0.6791 - val_accuracy: 0.5924 - val_loss: 0.6707\n",
            "Epoch 131/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.6806 - val_accuracy: 0.5924 - val_loss: 0.6726\n",
            "Epoch 132/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5821 - loss: 0.6738 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 133/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5756 - loss: 0.6780 - val_accuracy: 0.5924 - val_loss: 0.6707\n",
            "Epoch 134/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5826 - loss: 0.6754 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 135/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5894 - loss: 0.6756 - val_accuracy: 0.5924 - val_loss: 0.6704\n",
            "Epoch 136/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5895 - loss: 0.6737 - val_accuracy: 0.5924 - val_loss: 0.6707\n",
            "Epoch 137/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5744 - loss: 0.6810 - val_accuracy: 0.5924 - val_loss: 0.6700\n",
            "Epoch 138/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 0.6728 - val_accuracy: 0.5924 - val_loss: 0.6706\n",
            "Epoch 139/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5828 - loss: 0.6785 - val_accuracy: 0.5924 - val_loss: 0.6710\n",
            "Epoch 140/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.6709 - val_accuracy: 0.5924 - val_loss: 0.6722\n",
            "Epoch 141/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5998 - loss: 0.6705 - val_accuracy: 0.5924 - val_loss: 0.6699\n",
            "Epoch 142/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6018 - loss: 0.6670 - val_accuracy: 0.5924 - val_loss: 0.6726\n",
            "Epoch 143/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5785 - loss: 0.6766 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 144/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5846 - loss: 0.6814 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 145/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 0.6696 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 146/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6111 - loss: 0.6668 - val_accuracy: 0.5924 - val_loss: 0.6708\n",
            "Epoch 147/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 0.6727 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 148/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5742 - loss: 0.6790 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 149/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.6720 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 150/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.6695 - val_accuracy: 0.5924 - val_loss: 0.6720\n",
            "Epoch 151/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.6683 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 152/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6011 - loss: 0.6685 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 153/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5764 - loss: 0.6730 - val_accuracy: 0.5924 - val_loss: 0.6683\n",
            "Epoch 154/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5991 - loss: 0.6713 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 155/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5687 - loss: 0.6786 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 156/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5830 - loss: 0.6769 - val_accuracy: 0.5924 - val_loss: 0.6709\n",
            "Epoch 157/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5694 - loss: 0.6753 - val_accuracy: 0.5978 - val_loss: 0.6683\n",
            "Epoch 158/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6042 - loss: 0.6713 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 159/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5777 - loss: 0.6797 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 160/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5811 - loss: 0.6747 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 161/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5907 - loss: 0.6760 - val_accuracy: 0.5924 - val_loss: 0.6721\n",
            "Epoch 162/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 0.6767 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 163/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.6729 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 164/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5759 - loss: 0.6755 - val_accuracy: 0.5978 - val_loss: 0.6687\n",
            "Epoch 165/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5760 - loss: 0.6793 - val_accuracy: 0.5924 - val_loss: 0.6719\n",
            "Epoch 166/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5906 - loss: 0.6722 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 167/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5966 - loss: 0.6713 - val_accuracy: 0.5924 - val_loss: 0.6698\n",
            "Epoch 168/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5671 - loss: 0.6778 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 169/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5994 - loss: 0.6760 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 170/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5743 - loss: 0.6774 - val_accuracy: 0.5924 - val_loss: 0.6683\n",
            "Epoch 171/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 0.6793 - val_accuracy: 0.5924 - val_loss: 0.6711\n",
            "Epoch 172/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5817 - loss: 0.6758 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 173/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 0.6724 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 174/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5868 - loss: 0.6727 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 175/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5768 - loss: 0.6746 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 176/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.6692 - val_accuracy: 0.5924 - val_loss: 0.6698\n",
            "Epoch 177/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5707 - loss: 0.6786 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 178/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5951 - loss: 0.6729 - val_accuracy: 0.5924 - val_loss: 0.6699\n",
            "Epoch 179/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5825 - loss: 0.6803 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 180/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.6858 - val_accuracy: 0.5924 - val_loss: 0.6725\n",
            "Epoch 181/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5885 - loss: 0.6723 - val_accuracy: 0.5924 - val_loss: 0.6718\n",
            "Epoch 182/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5825 - loss: 0.6741 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 183/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5860 - loss: 0.6738 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 184/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5833 - loss: 0.6763 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 185/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5888 - loss: 0.6709 - val_accuracy: 0.5924 - val_loss: 0.6706\n",
            "Epoch 186/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5782 - loss: 0.6768 - val_accuracy: 0.5924 - val_loss: 0.6703\n",
            "Epoch 187/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5763 - loss: 0.6756 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 188/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5986 - loss: 0.6687 - val_accuracy: 0.5924 - val_loss: 0.6706\n",
            "Epoch 189/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 0.6713 - val_accuracy: 0.5924 - val_loss: 0.6704\n",
            "Epoch 190/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5721 - loss: 0.6785 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 191/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5831 - loss: 0.6752 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 192/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5875 - loss: 0.6735 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 193/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 0.6773 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 194/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5834 - loss: 0.6745 - val_accuracy: 0.5924 - val_loss: 0.6706\n",
            "Epoch 195/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.6688 - val_accuracy: 0.5924 - val_loss: 0.6703\n",
            "Epoch 196/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5779 - loss: 0.6764 - val_accuracy: 0.5924 - val_loss: 0.6703\n",
            "Epoch 197/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5707 - loss: 0.6745 - val_accuracy: 0.5924 - val_loss: 0.6741\n",
            "Epoch 198/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5842 - loss: 0.6719 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 199/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5784 - loss: 0.6793 - val_accuracy: 0.5924 - val_loss: 0.6704\n",
            "Epoch 200/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5852 - loss: 0.6773 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 201/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5823 - loss: 0.6764 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 202/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5764 - loss: 0.6799 - val_accuracy: 0.5924 - val_loss: 0.6699\n",
            "Epoch 203/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5747 - loss: 0.6796 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 204/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5868 - loss: 0.6745 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 205/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5767 - loss: 0.6729 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 206/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 0.6707 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 207/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5777 - loss: 0.6763 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 208/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5711 - loss: 0.6782 - val_accuracy: 0.5924 - val_loss: 0.6703\n",
            "Epoch 209/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5836 - loss: 0.6724 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 210/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 0.6757 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 211/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.6711 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 212/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5846 - loss: 0.6751 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 213/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.6730 - val_accuracy: 0.5924 - val_loss: 0.6706\n",
            "Epoch 214/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5775 - loss: 0.6765 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 215/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5827 - loss: 0.6734 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 216/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.6700 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 217/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5755 - loss: 0.6776 - val_accuracy: 0.5245 - val_loss: 1.1285\n",
            "Epoch 218/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5634 - loss: 0.7781 - val_accuracy: 0.5924 - val_loss: 0.6708\n",
            "Epoch 219/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5683 - loss: 0.6767 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 220/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5831 - loss: 0.6757 - val_accuracy: 0.5924 - val_loss: 0.6699\n",
            "Epoch 221/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 0.6728 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 222/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 0.6746 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 223/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5721 - loss: 0.6815 - val_accuracy: 0.5924 - val_loss: 0.6715\n",
            "Epoch 224/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5610 - loss: 0.6805 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 225/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5996 - loss: 0.6711 - val_accuracy: 0.5924 - val_loss: 0.6718\n",
            "Epoch 226/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5691 - loss: 0.6783 - val_accuracy: 0.5924 - val_loss: 0.6703\n",
            "Epoch 227/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5701 - loss: 0.6848 - val_accuracy: 0.5924 - val_loss: 0.6712\n",
            "Epoch 228/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5995 - loss: 0.6700 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 229/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5735 - loss: 0.6754 - val_accuracy: 0.5924 - val_loss: 0.6716\n",
            "Epoch 230/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 0.6756 - val_accuracy: 0.5924 - val_loss: 0.6698\n",
            "Epoch 231/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5712 - loss: 0.6798 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 232/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5725 - loss: 0.6766 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 233/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5795 - loss: 0.6736 - val_accuracy: 0.5978 - val_loss: 0.6687\n",
            "Epoch 234/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5863 - loss: 0.6773 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 235/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.6659 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 236/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5794 - loss: 0.6767 - val_accuracy: 0.5924 - val_loss: 0.6698\n",
            "Epoch 237/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5710 - loss: 0.6802 - val_accuracy: 0.5924 - val_loss: 0.6700\n",
            "Epoch 238/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5881 - loss: 0.6714 - val_accuracy: 0.5924 - val_loss: 0.6700\n",
            "Epoch 239/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5796 - loss: 0.6745 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 240/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5981 - loss: 0.6715 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 241/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5899 - loss: 0.6704 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 242/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5906 - loss: 0.6738 - val_accuracy: 0.5924 - val_loss: 0.6683\n",
            "Epoch 243/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5859 - loss: 0.6758 - val_accuracy: 0.5924 - val_loss: 0.6699\n",
            "Epoch 244/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5756 - loss: 0.6743 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 245/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5935 - loss: 0.6697 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 246/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 0.6754 - val_accuracy: 0.5978 - val_loss: 0.6680\n",
            "Epoch 247/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5594 - loss: 0.6936 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 248/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6113 - loss: 0.6686 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 249/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5780 - loss: 0.6779 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 250/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5838 - loss: 0.6757 - val_accuracy: 0.5978 - val_loss: 0.6687\n",
            "Epoch 251/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5723 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 252/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5825 - loss: 0.6741 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 253/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5937 - loss: 0.6744 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 254/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5668 - loss: 0.6821 - val_accuracy: 0.5978 - val_loss: 0.6681\n",
            "Epoch 255/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5949 - loss: 0.6726 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 256/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5760 - loss: 0.6748 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 257/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5854 - loss: 0.6749 - val_accuracy: 0.5924 - val_loss: 0.6708\n",
            "Epoch 258/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5880 - loss: 0.6715 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 259/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5847 - loss: 0.6707 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 260/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5790 - loss: 0.6759 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 261/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5828 - loss: 0.6765 - val_accuracy: 0.5924 - val_loss: 0.6708\n",
            "Epoch 262/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5748 - loss: 0.6767 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 263/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5846 - loss: 0.6748 - val_accuracy: 0.5978 - val_loss: 0.6683\n",
            "Epoch 264/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5762 - loss: 0.6774 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 265/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5824 - loss: 0.6760 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 266/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5827 - loss: 0.6750 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 267/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.6768 - val_accuracy: 0.5978 - val_loss: 0.6686\n",
            "Epoch 268/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5800 - loss: 0.6785 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 269/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.6666 - val_accuracy: 0.5978 - val_loss: 0.6692\n",
            "Epoch 270/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5924 - loss: 0.6722 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 271/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5814 - loss: 0.6775 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 272/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5826 - loss: 0.6761 - val_accuracy: 0.5924 - val_loss: 0.6700\n",
            "Epoch 273/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5855 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 274/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5782 - loss: 0.6743 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 275/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5839 - loss: 0.6781 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 276/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5791 - loss: 0.6793 - val_accuracy: 0.5924 - val_loss: 0.6710\n",
            "Epoch 277/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5555 - loss: 0.6778 - val_accuracy: 0.5978 - val_loss: 0.6686\n",
            "Epoch 278/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5813 - loss: 0.6757 - val_accuracy: 0.5924 - val_loss: 0.6683\n",
            "Epoch 279/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5810 - loss: 0.6769 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 280/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5970 - loss: 0.6720 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 281/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 0.6776 - val_accuracy: 0.5924 - val_loss: 0.6703\n",
            "Epoch 282/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5776 - loss: 0.6759 - val_accuracy: 0.5924 - val_loss: 0.6687\n",
            "Epoch 283/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6011 - loss: 0.6682 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 284/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 0.6709 - val_accuracy: 0.5924 - val_loss: 0.6687\n",
            "Epoch 285/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 0.6765 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 286/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5871 - loss: 0.6721 - val_accuracy: 0.5924 - val_loss: 0.6704\n",
            "Epoch 287/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6031 - loss: 0.6676 - val_accuracy: 0.5978 - val_loss: 0.6679\n",
            "Epoch 288/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5845 - loss: 0.6752 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 289/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5567 - loss: 0.6857 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 290/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5902 - loss: 0.6759 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 291/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5947 - loss: 0.6844 - val_accuracy: 0.5924 - val_loss: 0.6706\n",
            "Epoch 292/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5814 - loss: 0.6757 - val_accuracy: 0.5924 - val_loss: 0.6687\n",
            "Epoch 293/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5847 - loss: 0.6756 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 294/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5733 - loss: 0.6777 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 295/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5821 - loss: 0.6768 - val_accuracy: 0.5978 - val_loss: 0.6679\n",
            "Epoch 296/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5988 - loss: 0.6703 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 297/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5695 - loss: 0.6783 - val_accuracy: 0.5924 - val_loss: 0.6678\n",
            "Epoch 298/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5725 - loss: 0.6765 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 299/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6003 - loss: 0.6740 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 300/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5956 - loss: 0.6687 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 301/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5770 - loss: 0.6770 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 302/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.6703 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 303/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5771 - loss: 0.6799 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 304/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5925 - loss: 0.6736 - val_accuracy: 0.5924 - val_loss: 0.6692\n",
            "Epoch 305/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.6675 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 306/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5671 - loss: 0.6839 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 307/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5972 - loss: 0.6689 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 308/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.6678 - val_accuracy: 0.5924 - val_loss: 0.6687\n",
            "Epoch 309/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5847 - loss: 0.6764 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 310/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5862 - loss: 0.6744 - val_accuracy: 0.5924 - val_loss: 0.6699\n",
            "Epoch 311/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5849 - loss: 0.6708 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 312/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5819 - loss: 0.6773 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 313/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5735 - loss: 0.6737 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 314/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5949 - loss: 0.6717 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 315/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5635 - loss: 0.6795 - val_accuracy: 0.5924 - val_loss: 0.6692\n",
            "Epoch 316/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5817 - loss: 0.6756 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 317/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5818 - loss: 0.6710 - val_accuracy: 0.5924 - val_loss: 0.6692\n",
            "Epoch 318/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5778 - loss: 0.6780 - val_accuracy: 0.5924 - val_loss: 0.6700\n",
            "Epoch 319/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5875 - loss: 0.6741 - val_accuracy: 0.5978 - val_loss: 0.6680\n",
            "Epoch 320/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6003 - loss: 0.6720 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 321/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5782 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 322/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5869 - loss: 0.6713 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 323/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5713 - loss: 0.6764 - val_accuracy: 0.5924 - val_loss: 0.6683\n",
            "Epoch 324/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5716 - loss: 0.6806 - val_accuracy: 0.5924 - val_loss: 0.6704\n",
            "Epoch 325/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5911 - loss: 0.6747 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 326/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 0.6820 - val_accuracy: 0.5924 - val_loss: 0.6701\n",
            "Epoch 327/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5813 - loss: 0.6777 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 328/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5647 - loss: 0.6813 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 329/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5885 - loss: 0.6715 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 330/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6043 - loss: 0.6644 - val_accuracy: 0.5924 - val_loss: 0.6680\n",
            "Epoch 331/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5889 - loss: 0.6706 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 332/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5830 - loss: 0.6744 - val_accuracy: 0.5978 - val_loss: 0.6676\n",
            "Epoch 333/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5768 - loss: 0.6771 - val_accuracy: 0.5978 - val_loss: 0.6682\n",
            "Epoch 334/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5822 - loss: 0.6772 - val_accuracy: 0.5924 - val_loss: 0.6682\n",
            "Epoch 335/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5700 - loss: 0.6787 - val_accuracy: 0.5924 - val_loss: 0.6678\n",
            "Epoch 336/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5822 - loss: 0.6726 - val_accuracy: 0.5978 - val_loss: 0.6684\n",
            "Epoch 337/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5864 - loss: 0.6731 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 338/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5982 - loss: 0.6720 - val_accuracy: 0.5924 - val_loss: 0.6705\n",
            "Epoch 339/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5963 - loss: 0.6706 - val_accuracy: 0.5924 - val_loss: 0.6711\n",
            "Epoch 340/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 0.6760 - val_accuracy: 0.5924 - val_loss: 0.6699\n",
            "Epoch 341/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5689 - loss: 0.6778 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 342/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5819 - loss: 0.6788 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 343/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5861 - loss: 0.6788 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 344/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5775 - loss: 0.6811 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 345/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6069 - loss: 0.6691 - val_accuracy: 0.5924 - val_loss: 0.6713\n",
            "Epoch 346/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5928 - loss: 0.6733 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 347/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5807 - loss: 0.6768 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 348/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5792 - loss: 0.6769 - val_accuracy: 0.5924 - val_loss: 0.6702\n",
            "Epoch 349/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.6672 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 350/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6035 - loss: 0.6702 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 351/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5972 - loss: 0.6656 - val_accuracy: 0.5924 - val_loss: 0.6695\n",
            "Epoch 352/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5775 - loss: 0.6774 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 353/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5988 - loss: 0.6714 - val_accuracy: 0.5924 - val_loss: 0.6682\n",
            "Epoch 354/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5832 - loss: 0.6762 - val_accuracy: 0.5978 - val_loss: 0.6680\n",
            "Epoch 355/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5948 - loss: 0.6680 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 356/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5855 - loss: 0.6700 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 357/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5740 - loss: 0.6799 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 358/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5860 - loss: 0.6770 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 359/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5875 - loss: 0.6749 - val_accuracy: 0.5924 - val_loss: 0.6683\n",
            "Epoch 360/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5760 - loss: 0.6778 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 361/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5850 - loss: 0.6777 - val_accuracy: 0.5924 - val_loss: 0.6699\n",
            "Epoch 362/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5865 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 363/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.6677 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 364/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5727 - loss: 0.6763 - val_accuracy: 0.5978 - val_loss: 0.6678\n",
            "Epoch 365/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 0.6726 - val_accuracy: 0.5924 - val_loss: 0.6692\n",
            "Epoch 366/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5656 - loss: 0.6817 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 367/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5801 - loss: 0.6774 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 368/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 0.6777 - val_accuracy: 0.5924 - val_loss: 0.6698\n",
            "Epoch 369/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5709 - loss: 0.6793 - val_accuracy: 0.5924 - val_loss: 0.6678\n",
            "Epoch 370/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5724 - loss: 0.6808 - val_accuracy: 0.5978 - val_loss: 0.6686\n",
            "Epoch 371/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5982 - loss: 0.6763 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 372/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5801 - loss: 0.6813 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 373/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.6638 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 374/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5820 - loss: 0.6751 - val_accuracy: 0.5924 - val_loss: 0.6687\n",
            "Epoch 375/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5811 - loss: 0.6739 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 376/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5823 - loss: 0.6733 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 377/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5920 - loss: 0.6729 - val_accuracy: 0.5924 - val_loss: 0.6704\n",
            "Epoch 378/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5754 - loss: 0.6757 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 379/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5996 - loss: 0.6683 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 380/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5845 - loss: 0.6764 - val_accuracy: 0.5924 - val_loss: 0.6590\n",
            "Epoch 381/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5825 - loss: 0.6718 - val_accuracy: 0.5924 - val_loss: 0.6699\n",
            "Epoch 382/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5842 - loss: 0.6723 - val_accuracy: 0.5924 - val_loss: 0.6680\n",
            "Epoch 383/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5805 - loss: 0.6714 - val_accuracy: 0.5978 - val_loss: 0.6682\n",
            "Epoch 384/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 0.6684 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 385/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5823 - loss: 0.6728 - val_accuracy: 0.5978 - val_loss: 0.6679\n",
            "Epoch 386/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5713 - loss: 0.6828 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 387/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5764 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6683\n",
            "Epoch 388/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5885 - loss: 0.6761 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 389/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5874 - loss: 0.6717 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 390/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5969 - loss: 0.6703 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 391/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5963 - loss: 0.6692 - val_accuracy: 0.5978 - val_loss: 0.6681\n",
            "Epoch 392/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5859 - loss: 0.6686 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 393/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5909 - loss: 0.6732 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 394/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5599 - loss: 0.6789 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 395/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5753 - loss: 0.6727 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 396/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6021 - loss: 0.6712 - val_accuracy: 0.5924 - val_loss: 0.6692\n",
            "Epoch 397/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5772 - loss: 0.6752 - val_accuracy: 0.5978 - val_loss: 0.6679\n",
            "Epoch 398/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5862 - loss: 0.6754 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 399/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5899 - loss: 0.6726 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 400/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5873 - loss: 0.6737 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 401/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5864 - loss: 0.6696 - val_accuracy: 0.5924 - val_loss: 0.6700\n",
            "Epoch 402/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 0.6727 - val_accuracy: 0.5924 - val_loss: 0.6680\n",
            "Epoch 403/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5782 - loss: 0.6765 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 404/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5657 - loss: 0.6784 - val_accuracy: 0.5924 - val_loss: 0.6692\n",
            "Epoch 405/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5885 - loss: 0.6760 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 406/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5905 - loss: 0.6720 - val_accuracy: 0.5924 - val_loss: 0.6680\n",
            "Epoch 407/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5794 - loss: 0.6763 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 408/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5995 - loss: 0.6680 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 409/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5770 - loss: 0.6755 - val_accuracy: 0.5924 - val_loss: 0.6689\n",
            "Epoch 410/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6025 - loss: 0.6732 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 411/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5800 - loss: 0.6734 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 412/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5809 - loss: 0.6758 - val_accuracy: 0.5978 - val_loss: 0.6683\n",
            "Epoch 413/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.6698 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 414/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5926 - loss: 0.6741 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 415/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.6636 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 416/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5682 - loss: 0.6752 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 417/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.6665 - val_accuracy: 0.5978 - val_loss: 0.6684\n",
            "Epoch 418/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.6703 - val_accuracy: 0.5924 - val_loss: 0.6691\n",
            "Epoch 419/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5946 - loss: 0.6675 - val_accuracy: 0.5924 - val_loss: 0.6683\n",
            "Epoch 420/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5643 - loss: 0.6784 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 421/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5735 - loss: 0.6753 - val_accuracy: 0.5978 - val_loss: 0.6680\n",
            "Epoch 422/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5942 - loss: 0.6759 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 423/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5901 - loss: 0.6709 - val_accuracy: 0.5924 - val_loss: 0.6677\n",
            "Epoch 424/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5890 - loss: 0.6733 - val_accuracy: 0.5924 - val_loss: 0.6693\n",
            "Epoch 425/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6045 - loss: 0.6682 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 426/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5584 - loss: 0.8586 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 427/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5943 - loss: 0.6702 - val_accuracy: 0.5924 - val_loss: 0.6678\n",
            "Epoch 428/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.6704 - val_accuracy: 0.5924 - val_loss: 0.6680\n",
            "Epoch 429/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6027 - loss: 0.6660 - val_accuracy: 0.5924 - val_loss: 0.6678\n",
            "Epoch 430/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.6702 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 431/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.6719 - val_accuracy: 0.5924 - val_loss: 0.6682\n",
            "Epoch 432/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5707 - loss: 0.6795 - val_accuracy: 0.5924 - val_loss: 0.6678\n",
            "Epoch 433/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5831 - loss: 0.6733 - val_accuracy: 0.5924 - val_loss: 0.6674\n",
            "Epoch 434/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5617 - loss: 0.6840 - val_accuracy: 0.5978 - val_loss: 0.6671\n",
            "Epoch 435/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5954 - loss: 0.6685 - val_accuracy: 0.5924 - val_loss: 0.6677\n",
            "Epoch 436/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.6690 - val_accuracy: 0.5924 - val_loss: 0.6681\n",
            "Epoch 437/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5963 - loss: 0.6690 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 438/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6111 - loss: 0.6614 - val_accuracy: 0.5924 - val_loss: 0.6673\n",
            "Epoch 439/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5874 - loss: 0.6714 - val_accuracy: 0.5978 - val_loss: 0.6671\n",
            "Epoch 440/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 0.6653 - val_accuracy: 0.5924 - val_loss: 0.6677\n",
            "Epoch 441/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6082 - loss: 0.6655 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 442/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5908 - loss: 0.6697 - val_accuracy: 0.5924 - val_loss: 0.6682\n",
            "Epoch 443/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5810 - loss: 0.6727 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 444/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5645 - loss: 0.6823 - val_accuracy: 0.5978 - val_loss: 0.6674\n",
            "Epoch 445/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6007 - loss: 0.6659 - val_accuracy: 0.5924 - val_loss: 0.6697\n",
            "Epoch 446/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5941 - loss: 0.6681 - val_accuracy: 0.5924 - val_loss: 0.6696\n",
            "Epoch 447/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 0.6680 - val_accuracy: 0.5924 - val_loss: 0.6694\n",
            "Epoch 448/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5652 - loss: 0.6794 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 449/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6015 - loss: 0.6683 - val_accuracy: 0.5924 - val_loss: 0.6677\n",
            "Epoch 450/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5709 - loss: 0.6790 - val_accuracy: 0.5924 - val_loss: 0.6677\n",
            "Epoch 451/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5747 - loss: 0.6736 - val_accuracy: 0.5924 - val_loss: 0.6676\n",
            "Epoch 452/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 0.6717 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 453/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6081 - loss: 0.6710 - val_accuracy: 0.5978 - val_loss: 0.6682\n",
            "Epoch 454/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5923 - loss: 0.6719 - val_accuracy: 0.5978 - val_loss: 0.6675\n",
            "Epoch 455/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5934 - loss: 0.6692 - val_accuracy: 0.5924 - val_loss: 0.6688\n",
            "Epoch 456/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5736 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6671\n",
            "Epoch 457/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.6664 - val_accuracy: 0.5924 - val_loss: 0.6675\n",
            "Epoch 458/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5852 - loss: 0.6711 - val_accuracy: 0.5924 - val_loss: 0.6676\n",
            "Epoch 459/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5969 - loss: 0.6662 - val_accuracy: 0.5978 - val_loss: 0.6671\n",
            "Epoch 460/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5756 - loss: 0.6768 - val_accuracy: 0.5924 - val_loss: 0.6674\n",
            "Epoch 461/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5710 - loss: 0.6723 - val_accuracy: 0.5924 - val_loss: 0.6680\n",
            "Epoch 462/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5888 - loss: 0.6722 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 463/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5881 - loss: 0.6704 - val_accuracy: 0.5924 - val_loss: 0.6682\n",
            "Epoch 464/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5731 - loss: 0.6742 - val_accuracy: 0.5978 - val_loss: 0.6680\n",
            "Epoch 465/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6005 - loss: 0.6699 - val_accuracy: 0.5978 - val_loss: 0.6672\n",
            "Epoch 466/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5775 - loss: 0.6761 - val_accuracy: 0.5924 - val_loss: 0.6675\n",
            "Epoch 467/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5732 - loss: 0.6771 - val_accuracy: 0.5924 - val_loss: 0.6678\n",
            "Epoch 468/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5878 - loss: 0.6718 - val_accuracy: 0.5924 - val_loss: 0.6672\n",
            "Epoch 469/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6002 - loss: 0.6696 - val_accuracy: 0.5924 - val_loss: 0.6690\n",
            "Epoch 470/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5803 - loss: 0.6731 - val_accuracy: 0.5924 - val_loss: 0.6673\n",
            "Epoch 471/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5799 - loss: 0.6729 - val_accuracy: 0.5978 - val_loss: 0.6679\n",
            "Epoch 472/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5921 - loss: 0.6707 - val_accuracy: 0.5978 - val_loss: 0.6671\n",
            "Epoch 473/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 0.6663 - val_accuracy: 0.5978 - val_loss: 0.6673\n",
            "Epoch 474/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5806 - loss: 0.6705 - val_accuracy: 0.5978 - val_loss: 0.6670\n",
            "Epoch 475/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.6660 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 476/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5774 - loss: 0.6757 - val_accuracy: 0.5924 - val_loss: 0.6677\n",
            "Epoch 477/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 0.6665 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 478/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5761 - loss: 0.6734 - val_accuracy: 0.5978 - val_loss: 0.6672\n",
            "Epoch 479/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5951 - loss: 0.6704 - val_accuracy: 0.5978 - val_loss: 0.6673\n",
            "Epoch 480/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5794 - loss: 0.6737 - val_accuracy: 0.5924 - val_loss: 0.6684\n",
            "Epoch 481/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5789 - loss: 0.6783 - val_accuracy: 0.5924 - val_loss: 0.6674\n",
            "Epoch 482/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5799 - loss: 0.6772 - val_accuracy: 0.5924 - val_loss: 0.6675\n",
            "Epoch 483/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 0.6709 - val_accuracy: 0.5924 - val_loss: 0.6676\n",
            "Epoch 484/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5817 - loss: 0.6703 - val_accuracy: 0.5978 - val_loss: 0.6674\n",
            "Epoch 485/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5878 - loss: 0.6735 - val_accuracy: 0.5924 - val_loss: 0.6682\n",
            "Epoch 486/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5798 - loss: 0.6731 - val_accuracy: 0.5924 - val_loss: 0.6677\n",
            "Epoch 487/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.6657 - val_accuracy: 0.5978 - val_loss: 0.6671\n",
            "Epoch 488/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5784 - loss: 0.6784 - val_accuracy: 0.5924 - val_loss: 0.6680\n",
            "Epoch 489/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5977 - loss: 0.6688 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 490/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 0.6744 - val_accuracy: 0.5924 - val_loss: 0.6686\n",
            "Epoch 491/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6014 - loss: 0.6667 - val_accuracy: 0.5924 - val_loss: 0.6685\n",
            "Epoch 492/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5724 - loss: 0.6753 - val_accuracy: 0.5924 - val_loss: 0.6679\n",
            "Epoch 493/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5911 - loss: 0.6706 - val_accuracy: 0.5924 - val_loss: 0.6678\n",
            "Epoch 494/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5760 - loss: 0.6825 - val_accuracy: 0.5924 - val_loss: 0.6676\n",
            "Epoch 495/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5810 - loss: 0.6716 - val_accuracy: 0.5924 - val_loss: 0.6677\n",
            "Epoch 496/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5933 - loss: 0.6724 - val_accuracy: 0.5924 - val_loss: 0.6678\n",
            "Epoch 497/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 0.6705 - val_accuracy: 0.5978 - val_loss: 0.6673\n",
            "Epoch 498/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5947 - loss: 0.6728 - val_accuracy: 0.5924 - val_loss: 0.6672\n",
            "Epoch 499/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6065 - loss: 0.6651 - val_accuracy: 0.5924 - val_loss: 0.6675\n",
            "Epoch 500/500\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5917 - loss: 0.6676 - val_accuracy: 0.5924 - val_loss: 0.6673\n",
            "CNN Model Accuracy: 0.62\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[261 184]\n",
            " [169 306]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   epileptic       0.61      0.59      0.60       445\n",
            "     healthy       0.62      0.64      0.63       475\n",
            "\n",
            "    accuracy                           0.62       920\n",
            "   macro avg       0.62      0.62      0.62       920\n",
            "weighted avg       0.62      0.62      0.62       920\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "overall_accuracy = accuracy\n",
        "print(f\"\\nAccuracy: {overall_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cI3d0L4Y1M_N",
        "outputId": "51d917a5-e0e9-44a4-9fa1-f9e23f0d7b35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9f70a937a6dc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Confusion matrix visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Blues'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion Matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}